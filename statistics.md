Statistics
==========
* [**21세기 통계학을 배우는 방법**](http://statkclee.github.io/window-of-statistics/)
* [통계는 숫자가 아니라 경험이 살린다](http://ppss.kr/archives/37791)
* [Sample your data!](http://www.chrisgoldammer.com/posts/sampling.html)
* [층화 추출(stratified sampling)](http://blog.daum.net/iamwhoi/5740153)
  * qc 기준으로 층화 샘플링 하는 경우
    * (query, query count) pair 생성 후 qc로 sort
    * n개 구간으로 분리 후, k개씩 random choice
    * 구간의 전체 개수가 k보다 작은 경우
      * 추출 기간 증가
      * 구간 개수 축소
* [MCMC sampling for dummies](http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/)
  * [쉽게 쓰여진 MCMC](http://blog.naver.com/rupy400/220775812498)
* [Importance sampling 방법](http://blog.naver.com/kwonpub/221143316307])
* [Sampling Techniques](https://towardsdatascience.com/sampling-techniques-a4e34111d808)
* [Understanding Variance, Co-Variance, and Correlation](http://www.countbayesie.com/blog/2015/2/21/variance-co-variance-and-correlation)
* [13 Great Articles and Tutorials about Correlation](http://www.datasciencecentral.com/profiles/blogs/13-great-articles-and-tutorials-about-correlation)
* [SERIAL CORRELATION IN TIME SERIES ANALYSIS](https://www.quantstart.com/articles/Serial-Correlation-in-Time-Series-Analysis)
* [What is Correlation?](https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-correlation.html)
* [uniform random float](http://mumble.net/~campbell/2014/04/28/uniform-random-float)
* [A Decentralized Lie Detector](http://www.augur.net/blog/a-decentralized-lie-detector)
* [이정희 그리고 생일 역설](http://ppss.kr/archives/37856)
* [Expectation and Variance from High School to Grad School](http://www.countbayesie.com/blog/2015/3/19/expectation-and-variance-from-high-school-to-grad-school)
* [Kernel Density Estimation(커널밀도추정)에 대한 이해](http://darkpgmr.tistory.com/147)
* [The Price is Right Again](http://www.amstat.org/publications/jse/v20n2/burks.pdf)
* [Naive Bayesian, HMM, Maximum Entropy Model, CRF](https://github.com/dsindex/blog/wiki/%5Bstatistics%5D-Naive-Bayesian,-HMM,-Maximum-Entropy-Model,-CRF)
* [Maximum Likelihood and Maximum Entropy](https://github.com/dsindex/blog/wiki/%5Bstatistics%5D-Maximum-Likelihood-and-Maximum-Entropy)
* [손실함수 Binary Cross Entropy](https://curt-park.github.io/2018-09-19/loss-cross-entropy/)
* [bcho.tistory.com/category/빅데이타/통계학이론](http://bcho.tistory.com/category/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%83%80/%ED%86%B5%EA%B3%84%ED%95%99%20%EC%9D%B4%EB%A1%A0)
* P값; '영가설이 참이라고 가정할 때, 관찰된(또는 그보다 더 극단적인) 결과가 일어날 확률'로 정의
* [Statistics: P values are just the tip of the iceberg](http://www.nature.com/news/statistics-p-values-are-just-the-tip-of-the-iceberg-1.17412?WT.ec_id=NATURE-20150430)
* [p-value...  상관계수와 독립](https://brunch.co.kr/@headwaters/15)
* [P-value](http://terms.naver.com/entry.nhn?cid=58944&tkTocId=931470&categoryId=58970&tkListId=785221&docId=3580638&tkFrom=tlist&tkSort&mobile)
* [“p값 개선하자”…과학자들, 연구가설 검정 ‘문턱값’ 강화 제안](http://scienceon.hani.co.kr/540289)
* [미국 통계학회, P값의 오용(誤用)을 경고하는 성명서 발표](http://www.ibric.org/myboard/read.php?Board=news&id=270293)
* [Plot for distribution of common statistics and p-value](http://rpubs.com/cardiomoon/329065)
* [P-value, 유의확률 | Hong's Data science](https://jihongl.github.io/2017/09/12/P-value/)
* [Why We Need a Statistical Revolution](http://www.stats.org/super-learning-and-the-revolution-in-knowledge/)
* [Mean Shift Clustering](http://spin.atomicobject.com/2015/05/26/mean-shift-clustering/)
* [Pattern Recognition](http://iskim3068.tistory.com/m/post?categoryId=473315)
* [The Extent and Consequences of P-Hacking in Science](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002106)
* [Exact computation of sums and means](https://radfordneal.wordpress.com/2015/05/21/exact-computation-of-sums-and-means/)
* [Why squared error?](http://www.benkuhn.net/squared)
* [How to lie with statistics](https://janav.wordpress.com/2014/01/03/how-to-lie-with-statistics/)
  * [통계로 거짓말 하는 방법](http://ppss.kr/archives/47334)
* [정규분포](http://navercast.naver.com/contents.nhn?rid=22&contents_id=2490)
* [가우시안 분포(Gaussian Distribution) = 정규 분포(Normal Distribution)](https://nbviewer.jupyter.org/github/likejazz/likejazz.github.io/blob/master/public/notebooks/gaussian-distribution.ipynb)
* [Gaussian Distributions are Soap Bubbles](http://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/)
* [Gaussian Processes](http://efavdb.com/gaussian-processes/)
* [**Industrial Gaussian Process Regression Introduction - 본 자료는 ICMLA Tutorial로 진행된 Gaussian Process Regression 내용을 정리**](https://github.com/LeeDoYup/ML_Implementations/blob/master/GP/1_GP_basics_KOR.ipynb)
* [Gaussian Process Regression Example in Sklearn Document](https://gist.github.com/jskDr/d57a0395b40c270696565d64f19a2456)
* [Gaussian processing](https://www.slideshare.net/ssuser06e0c5/gaussian-processing)
* [A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/)
* [Evaluating Splatoon's Ranking System](http://www.evanmiller.org/evaluating-splatoons-ranking-system.html)
* [Understanding the t-distribution and its normal approximation](http://rpsychologist.com/d3/tdist/)
* [Statistics for Hackers by Jake VanderPlas](https://speakerdeck.com/jakevdp/statistics-for-hackers)
* [Frequentism and Bayesianism: A Python-driven Primer](http://arxiv.org/abs/1411.5018)
* [Probability, Mathematical Statistics, Stochastic Processes](http://www.math.uah.edu/stat/)
* [A Simple Introduction to Complex Stochastic Processes](https://www.datasciencecentral.com/profiles/blogs/a-simple-introduction-to-complex-stochastic-processes)
* [Probabilistic algorithms for fun and pseudorandom profit](http://www.slideshare.net/TylerTreat/probabilistic-algorithms-for-fun-and-pseudorandom-profit)
* [인지모델링 - 수리심리학 + 베이지안 인지모델링 + IT 모델링](http://psygrammer.github.io/coco/)
* [자유도의 의미](http://blog.naver.com/hancury/220625928193)
* [The Automatic Statistician - An artificial intelligence for data science](http://www.automaticstatistician.com/examples/)
* [Common Probability Distributions: The Data Scientist’s Crib Sheet](https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/)
  * 데이터 사이언스에 많이 사용되는 확률밀도함수들
    * Bernoulli
      * 동전의 앞/뒤처럼 이벤트가 0 또는 1밖에 일어나지 않는 분포
      * 동전은 확률이 0.5/0.5 겠지만 다른 경우도 있을 수 있음
    * Uniform
      * 주사위처럼 모든 결과에 대한 확률이 동일한 확률분포
    * Binomial
      * 동전을 n번 던졌을 때 p번만큼 앞면이 나올 확률은?
      * Binomial은 이렇게 0 또는 1이 나오는 이벤트(각각이 Bernoulli확률을 갖는 이벤트)에 대해 1이 발생활 횟수에 대한 확률
    * Poisson
      * 1시간에 평균 10번의 전화통화가 온다고 가정. 그렇다면 한시간에 12번 전화통화가 올 확률은? 이것이 바로 poisson(포아송) 확률
      * 이것은, 예를 들어, 60분 중 48번의 실패(0)와 12번의 성공(1)을 하면 ok. 또는, 60분이 아니라 더 잘게 쪼개서 988번의 실패와 12번의 성공을 하면 ok
      * 이처럼 시행횟수가 크고 이벤트가 일어날 확률이 작은 bionomial 분포가 바로 poisson 분포에 수렴(이 때문에 binomial의 근사로도 사용)
    * Hypergeometric
      * 까만공과 하얀공이 절반씩 있는데 그것을 여러번 뽑는다고 가정. 그럼 이것은 Binomial과 동일한가?
      * 아님. 왜냐면 공을 뽑을 때 만약 그 공을 다시 채워넣지 않는다면 남아있는 공의 확률은 바뀌기 때문
      * Binomial의 경우와 달리 replacement(다시 보충)를 허용하지 않는 것이 바로 hypergeometric 확률입니다.
    * Geometric
      * 주사위를 굴렸을 때 한번에 6이 나올 확률은? 두번만에 6이 나올 확률은? 세번만에, 네번만에...
      * 이처럼 geometric 분포는 어떤 이벤트가 일어날 때까지의 횟수에 대한 확률
      * 이벤트의 확률이 어떠하든 늘 "가장 첫번째"에 이벤트가 발생할 확률이 가장 크다
    * Negative Binomial
      * Geometric이 한번 성공할 때까지 걸리는 횟수에 대한 분포라면 negative binominal은 n번 성공할 때까지 걸리는 횟수에 대한 분포
비슷하게 안지은거야?;;)
    * Exponential
      * bionomial의 연속버전이 poisson이었다면, geometric의 연속버전이 exponential분포
      * 다시말해 "평균 5분만에 전화가 걸려온다고 할 때 다음 전화가 7분 후에 걸려올 확률은?"
    * Weibull
      * exponential이 "다음 이벤트가 성공할 때 까지의 실패구간은"에 대한 함수였다면 반대로 Weibull은 "첫 실패가 발생할 때까지 이번 이벤트가 성공할 구간"에 대한 확률
    * Gaussian (Normal)
      * 너무 유명한 확률분포
      * 특히 매우 많은 수의 동일 확률분포를 가진 샘플들의 산술평균은 그 샘플들이 어떤 분포를 따르든(binomial이든 exponential이든 아님 다른거든) 결국 Gaussian 분포로 수렴한다는 "중심극한정리"가 매우 유용하기에 매우 많은 곳에 적용 가능
    * Log-normal
      * 변수의 log 값이 Gaussian을 나타내는 분포
      * 다시말해 Gaussian을 exponential 한 함수
    * Student’s t-distribution
      * 정규분포의 mean 값에 대한 판단을 내릴 떄 사용하는 확률분포
    * Chi-squared distribution
      * Gaussian 분포를 가진 확률변수의 제곱들의 합에 대한 분포
      * 예를 들어 k자유도의 chi-squared는 k개의 독립적인 Gaussian들에 대한 합의 확률분포
* [통컨(통계컨설팅) :: 우선 확률분포 4가지(싸가지?) 만 알면 됩니다.](https://rsas.tistory.com/156)
* [(2) 통계기법 4가지 알기-t검정,ANOVA,상관분석/회귀분석, 카이제곱법 :: 통컨(통계컨설팅)](https://rsas.tistory.com/185)
* [Statistical Methods for HCI Research](http://yatani.jp/teaching/doku.php?id=hcistats:start)
* [Statistics for everyone](http://statistics4everyone.blogspot.com/2016/05/p-story-i.html)
* [변동계수](https://ko.m.wikipedia.org/wiki/%EB%B3%80%EB%8F%99%EA%B3%84%EC%88%98) 평균 + 분산값 통합 평가
* [통계학 입문 수준의 공부방법 및 추천 서적](http://posterior.egloos.com/m/9637423)
* [피셔정확검정을 통한 고객군 상품구매액평균 순위 분석](http://blog.naver.com/hancury/220797689533)
* [**실시간 데이터의 평균을 효율적으로 구하기**](https://evan-moon.github.io/2019/08/11/average-filter/)
* [math7.tistory.com/m/category/통계](http://math7.tistory.com/m/category/%ED%86%B5%EA%B3%84)
* [Three common misuses of P values](http://www.dentalhypotheses.com/article.asp?issn=2155-8213;year=2016;volume=7;issue=3;spage=73;epage=80;aulast=Kim)
* [LEARNING STATISTICS ON YOUTUBE](http://flavioazevedo.com/stats-and-r-blog/2016/9/13/learning-r-on-youtube)
* [만화로 쉽게 보는 통계분석 - 확률의 공리 편 -](http://cafe.daum.net/Statistics.sniper)
* [딥러닝 예제로 보는 개발자를 위한 통계 최재걸](http://www.slideshare.net/deview/216-67609104)
* [정확한 처리 효과 분석을 위한 성향점수분석(PSA)](http://freesearch.pe.kr/archives/4377)
* [STAT 501](https://onlinecourses.science.psu.edu/stat501/)
* [statground.org](http://www.statground.org/) 수리통계학 pdf 자료 받은 곳
* [R Codes for "허명회 (2001), <수리통계학 강의>"](https://github.com/praster1/MathematicalStatistics)
* 아빠가 들려주는 통계
  * [자료 정리의 중요성](http://blog.naver.com/kjhnav/221044778964)
  * [엑셀 자료 정리 팁](http://blog.naver.com/kjhnav/221025023797)
  * [P값의 이해와 샘플 수 계산의 이해](http://blog.naver.com/kjhnav/220915201622)
  * [chi-square goodness of fit test 카이제곱 적합도 검정](http://blog.naver.com/kjhnav/220939776135)
  * [다중 검정의 위험: 회귀분석의 예에서](http://blog.naver.com/kjhnav/220958669369)
  * [Prediction Model & NIR, cfNIR, IDI](http://blog.naver.com/kjhnav/220990628798)
  * [Cox-Stuart test for trend](http://blog.naver.com/kjhnav/221004222425)
  * [Curve fitting 추세선 편집](http://blog.naver.com/kjhnav/221006027832)
  * [Heat Map의 대안들](http://blog.naver.com/kjhnav/221006351901)
  * [데이터 시각화 dot bar chart](http://blog.naver.com/kjhnav/221009856973)
  * [무작위 추출 연습](http://blog.naver.com/kjhnav/221012172204)
  * [step line chart 계단 차트](http://blog.naver.com/kjhnav/221013234461)
  * [brick chart 벽돌 차트](http://blog.naver.com/kjhnav/221013536421)
  * [예측하기](http://blog.naver.com/kjhnav/221015331524)
  * [brick chart 2](http://blog.naver.com/kjhnav/221035264782)
  * [파이차트 선버스트 도넛차트](http://blog.naver.com/kjhnav/221040480056)
  * [제주 공항 승객수 예측](http://blog.naver.com/kjhnav/221108118837)
  * [dot violin boxplot](http://blog.naver.com/kjhnav/221145918388)
  * [densitogram](http://blog.naver.com/kjhnav/221145999631)
* [Common Probability Distributions: The Data Scientist’s Crib Sheet](http://www.datasciencecentral.com/profiles/blogs/common-probability-distributions-the-data-scientist-s-crib-sheet)
* [보이지 않는 총알 자국 - 남들을 뛰어넘는 생각의 차이(아브라함 발드)](http://blog.naver.com/shc427118/220944502924)
* [www.medicine.mcgill.ca/epidemiology/hanley/software](http://www.medicine.mcgill.ca/epidemiology/hanley/software/)
* [seeing theory](http://students.brown.edu/seeing-theory/)
* [practice - 조건부 확률 문제](https://gist.github.com/hyunjun/248eb9072f307ab4109f2b872674708b)
* [Why Mean Squared Error and L2 regularization? A probabilistic justification](http://aoliver.org/why-mse)
  * 데이터가 zero mean Gaussian 분포를 띌때, maximizing probability의 과정에서 L2 loss function(MSE)이 유도될 수 있음
  * 또한 L2 regularization도 도출 가능
  * 데이터가 라플라스 분포를 띌때는 L1 loss function 및 L1 regularization을 얻을 수 있음
* [Why not Mean Squared Error(MSE) as a loss function for Logistic Regression?](https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c)
* [Introduction to Logistic Regression](https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148)
* [L2 Regularization and Batch Norm](https://blog.janestreet.com/l2-regularization-and-batch-norm/)
* Agreement, Reliability를 보는 Krippendorff’s alpha
  * [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha)
  * [ReCal for Ordinal, Interval, and Ratio Data (OIR)](http://dfreelon.org/utils/recalfront/recal-oir/)
* [통계학에서의 추정법](http://basicstatistics.tistory.com/entry/%ED%86%B5%EA%B3%84%ED%95%99%EC%97%90%EC%84%9C%EC%9D%98-%EC%B6%94%EC%A0%95%EB%B2%95)
* [So You Think You Can Stats](http://nadbordrozd.github.io/blog/2017/07/18/so-you-think-you-can-stats/)
* [평균, 표준편차, 표준정규분포의 이해와 활용](http://ohgyun.com/745)
* [독립사건 (independent event), 종속사건 (dependent event), 조건부 확률(conditional probability), 결합 확률 (joint probability)](https://www.facebook.com/terryum/posts/10155583605654417)
* [지나치게 자세한 수리통계(원)](http://blog.naver.com/kwonpub/221079139699)
* [Frequency diagrams: A first look at Bayes](https://arbital.com/p/bayes_frequency_diagram/?l=55z&pathId=22608)
* [통계에 사용되는 기초 공식들](http://blog.naver.com/kjhnav/221097570909)
* [시리즈 | 기초 확률론 - 수학하는 수달의 벨로그](https://velog.io/@otter275/series/%EA%B8%B0%EC%B4%88-%ED%99%95%EB%A5%A0%EB%A1%A0)
* [CHOOSING THE CORRECT STATISTICAL TEST IN SAS, STATA, SPSS AND R](https://stats.idre.ucla.edu/other/mult-pkg/whatstat/)
* [확률변수 함수의 분포를 알아보자 - Delta method에 대하여 (1)](http://issactoast.com/133)
* [확률변수와 패러미터 ( feat. 베르누이) #10통계 - YouTube](https://www.youtube.com/watch?v=FmIc5LZ7BII)
* [Propensity Score Matching (PSM) 기법 요약](http://blog.naver.com/hancury/221091701744)
* [모수적 방법과 비모수적 방법](http://dermabae.tistory.com/147)
* [Statistical Rethinking - Lecture 01](https://speakerdeck.com/rmcelreath/statistical-rethinking-lecture-01)
* [데이터의 표본 편향(Sample Bias), 그리고 생존 편향(Survivorship Bias)](http://kwangshin.pe.kr/blog/2019/02/07/data-sample-bias-and-survivorship-bias)
* [Fair and Balanced? Thoughts on Bias in Probabilistic Modeling](https://medium.com/@cody.marie.wild/fair-and-balanced-thoughts-on-bias-in-probabilistic-modeling-2ffdbd8a880f)
* [The 10 Statistical Techniques Data Scientists Need to Master](https://towardsdatascience.com/the-10-statistical-techniques-data-scientists-need-to-master-1ef6dbd531f7)
* [Bias-Variance Tradeoff](https://jkeun.github.io/2018-05-03/bias-variance-tradeoff/)
* [4. Variance Bias Trade Off(분산-편향의 관계)](https://doublekpark.blogspot.com/2019/01/4-variance-bias-trade-off.html)
* [통컨(통계컨설팅) :: 분산을 구할 때 n으로 안 나누고 왜 (n-1)로 나누지?](https://rsas.tistory.com/137)
* [Predicting NYC Real Estate Prices with Probabilistic Programming](http://blog.fastforwardlabs.com/2017/03/15/predicting-nyc-real-estate-prices-with-probabilistic-programming.html)
* [Degrees of Freedom](https://jkeun.github.io/2017-07-24/degrees-of-freedom)
* [Statistics 110 : Probability](https://www.edwith.org/harvardprobability/joinLectures/17924)
* [ChoiFran's Analogy (최프란의 비유) 한국어 버전](https://www.youtube.com/playlist?list=PLgSth2TawHJ9-GG9DiEPNhHJ3rWngNJro)
* [Skewness Formula](https://www.macroption.com/skewness-formula/)
* [Kurtosis Formula](https://www.macroption.com/kurtosis-formula/)
* [practice - 통계적으로 유의미한 차이 vs 현실적으로 유의미한 차이](https://gist.github.com/hyunjun/248eb9072f307ab4109f2b872674708b#file-etc-md)
* [The 5 Basic Statistics Concepts Data Scientists Need to Know](https://www.kdnuggets.com/2018/11/5-basic-statistics-concepts-data-scientists-need-know.html)
* [멋지게 데이터 분석을 하려고 했는데 이론이 딸린다](https://humbledude.github.io/blog/2019/02/27/basic-data-analysis/)
* [Understanding Boxplots](https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51)
* [Derivation of the Multivariate Normal Distribution](https://teamdable.github.io/techblog/Derivation-of-the-Multivariate-Normal-Distribution)
* [Statistical-Inference](https://github.com/KaggleBreak/Statistical-Inference)
* [Statistics for people in a hurry](https://towardsdatascience.com/statistics-for-people-in-a-hurry-a9613c0ed0b)
* [Statistical Significance Explained](https://towardsdatascience.com/statistical-significance-hypothesis-testing-the-normal-curve-and-p-values-93274fa32687)
* [아빠가 들려주는 예측모형](https://www.youtube.com/playlist?list=PLQrL7n-YSrfc2psUlBzyhs1ulzcE-7YPO)
* [Dongjin | Basic Statistics(1)](https://dongqui.github.io//posts/basic-statistics)
* [Dongjin | Basic Statistics(2)](https://dongqui.github.io//posts/basic-statistics2)

# Bayes
* [쉽게 이해하는 베이즈 정리](http://blog.naver.com/anthouse28/221077405435)
* [가장 쉽게 이해하는 베이즈 정리(Bayes' Law)](https://junpyopark.github.io/bayes/)
* [베이지언 확률](http://darkpgmr.tistory.com/119)
* [**베이시안 통계 첫걸음!**](https://medium.com/@deepvalidation/%EB%B2%A0%EC%9D%B4%EC%8B%9C%EC%95%88-%ED%86%B5%EA%B3%84-%EC%B2%AB%EA%B1%B8%EC%9D%8C-7e7e1a5f5adc)
* [베이시안 통계 둘째 걸음!](https://medium.com/@deepvalidation/%EB%B2%A0%EC%9D%B4%EC%8B%9C%EC%95%88-%ED%86%B5%EA%B3%84-%EB%91%98%EC%A7%B8-%EA%B1%B8%EC%9D%8C-b486aa23d68b)
  * [github.com/Minsu-Daniel-Kim/bayesian_secon_step](https://github.com/Minsu-Daniel-Kim/bayesian_secon_step)
* [베이지안 추론 - 1편](https://brunch.co.kr/@chris-song/59)
* [Intro to Bayes stat](http://posterior.egloos.com/9602501) 베이지안 통계학 입문서 및 절차, 도구 소개
* [Bayes 101](https://www.facebook.com/pg/SKTBrain/photos/?tab=album&album_id=337638653273622)
* [Bayesian Statistics explained to Beginners in Simple English](http://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english)
* [The Bayesian Trap](https://www.youtube.com/watch?v=R13BD8qKeTg)
* [www.countbayesie.com](http://www.countbayesie.com)
  * [Bayes' Theorem with Lego](http://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)
  * [Building a Voight-Kampff Test with Bayes Factor](http://www.countbayesie.com/blog/2015/2/27/building-a-bayesian-voight-kampff-test)
  * [A Guide to Bayesian Statistics](https://www.countbayesie.com/blog/2016/5/1/a-guide-to-bayesian-statistics)
* [The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification](http://papers.nips.cc/paper/5313-the-bayesian-case-model-a-generative-approach-for-case-based-reasoning-and-prototype-classification)
* [Bayes’ Theorem, Predictions and Confidence Intervals](http://kukuruku.co/hub/algorithms/bayes-theorem-predictions-and-confidence-intervals)
* [Bayesian truth serum](http://nel.mit.edu/bayesian-truth-serum)
* [Kalman and Bayesian Filters in Python](http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb)
  * [Kalman Filter textbook using Ipython Notebook. Focuses on building intuition and experience, not formal proofs. Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)
  * [Kalman and Bayesian Filters in Python](https://drive.google.com/file/d/0By_SW19c1BfhSVFzNHc0SjduNzg/view)
  * [How a Kalman filter works, in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)
  * [칼만 필터를 이용하여 위치에서 속도를 구하는 예제](http://pinkwink.kr/781)
* [How a Kalman filter works, in pictures](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)
* [FilterPy - a Python library that implements a number of Bayesian filters, most notably Kalman filters](http://filterpy.readthedocs.io/)
* [Bayesian Inference : Kalman filter 에서 Optimization 까지 - 김홍배 박사님](https://www.slideshare.net/roboticskrai/bayesian-inference-kalman-filter-optimization-179401407)
* [공학자를 위한 Python 사용법 25 - Quaternion을 이용한 자세 추정 칼만 필터](http://myjr52.tumblr.com/post/128707132156/%EA%B3%B5%ED%95%99%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-python-%EC%82%AC%EC%9A%A9%EB%B2%95-25)
* [Using naive bayes to predict movie review sentiment](http://blog.dataquest.io/blog/naive-bayes-movies/)
* [Continuous Bayes](http://www.sidhantgodiwala.com/blog/2015/03/14/continuous-bayes/)
* [A Case Study in Empirical Bayes](http://www.ebaytechblog.com/2015/02/06/a-case-study-in-empirical-bayes/)
* [BAYESIAN STATISTICS AS A WAY TO INTEGRATE INTUITION AND DATA](https://keen.io/blog/98491909836/bayesian-statistics-as-a-way-to-integrate-intuition-and)
* [나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개](http://bcho.tistory.com/1010)
* [베이지안 네트워크](http://newsight.tistory.com/158)
* [Think Bayes](http://allendowney.blogspot.kr/)
  * [Chapter 02. Introduction : Credibility, Models, and Parameters](https://github.com/psygrammer/bayesianR/blob/master/part1/ch01_02/ch01_02_intro.md)
* [Proper postulates](http://posterior.egloos.com/category/Intro%20to%20Bayes%20stat/page/2)
  * [베이즈 정리](http://posterior.egloos.com/9604153)
  * [주관적 확률의 사용과 그 경험과학적 의미](http://posterior.egloos.com/9603023)
* [Probabilistic Programming and Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Chapter1.ipynb)
* [An intro to Bayesian methods and probabilistic programming from a computation/understanding-first, mathematics-second point of view](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/#contents)
* [BAYESIAN INFERENCE OF A BINOMIAL PROPORTION - THE ANALYTICAL APPROACH](http://www.quantstart.com/articles/Bayesian-Inference-of-a-Binomial-Proportion-The-Analytical-Approach)
* [집단지성프로그래밍 ch6. 문서 필터링](http://www.slideshare.net/icristi/ch6-48743141)
* [An Intuitive Explanation of Bayes' Theorem](http://www.yudkowsky.net/rational/bayes)
* [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
* [메르스 바로 알기: 양성일 때 메르스 환자일 확률은 얼마나 될까?](http://ppss.kr/archives/49107)
* [베이지언이 되자~!](http://pgr21.com/?b=8&n=59237)
* [Bayes’ Theorem](http://crucialconsiderations.org/rationality/bayes-theorem/)
* [A Tutorial on Learning With Bayesian Networks](http://research.microsoft.com/pubs/69588/tr-95-06.pdf)
* [Basic MCMC and Bayesian statistics in... BASIC!](http://sumsar.net/blog/2015/08/basic-mcmc-and-bayesian-statistics-in-basic/)
* [Bayesian과 MCMC 알고리즘 (Gibbs and Metropolis-Hastings Algorithm)](http://enginius.tistory.com/m/514)
* [Bayesian Financial Models](http://toddmoses.com/articles/read/bayesian_financial_models)
* [Bayesian Cookies](http://www.sidhantgodiwala.com/blog/2015/07/12/bayesian-cookies/)
* [In praise of Bayes](http://www.cs.ubc.ca/~murphyk/Bayes/economist.html)
* [A Brief Introduction to Graphical Models and Bayesian Networks](http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html)
* [Bayesian democracy](https://samgentle.com/posts/2015-08-28-bayesian-democracy)
* [The Bayesian Reproducibility Project](http://alexanderetz.com/2015/08/30/the-bayesian-reproducibility-project/)
* [Using Bayes Factors to Get the Most out of Linear Regression: A Practical Guide Using R](https://thewinnower.com/papers/278-using-bayes-factors-to-get-the-most-out-of-linear-regression-a-practical-guide-using-r)
* [베이즈 이론이 푸리에 정리를 만났을 때](https://brunch.co.kr/@cojette/1)
* [Naive Bayesian Classification(나이브 베이즈 분류)](http://unlimitedpower.tistory.com/entry/NLP-Naive-Bayesian-Classification%EB%82%98%EC%9D%B4%EB%B8%8C-%EB%B2%A0%EC%9D%B4%EC%A6%88-%EB%B6%84%EB%A5%98)
* [Bayes Theorem and Naive Bayes](http://alexhwoods.com/2015/11/08/bayes-theorem-and-naive-bayes/)
* [SigOpt for ML: Unsupervised Learning with Even Less Supervision Using Bayesian Optimization](http://blog.sigopt.com/post/140871698423/sigopt-for-ml-unsupervised-learning-with-even)
* [bayes.js - MCMC and Bayes in the browser](https://github.com/rasmusab/bayes.js)
* [Human-level concept learning through probabilistic program induction Bayesian Program Learning (BPL) model for one-shot learning](http://gitxiv.com/posts/jS9LJ5kh9ny6iqD7Z/human-level-concept-learning-through-probabilistic-program)
* [Bayesian reasoning implicated in some mental disorders](https://www.sciencenews.org/article/bayesian-reasoning-implicated-some-mental-disorders)
* [Bayesian Deep Learning](http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/)
* [Bayesian Machine Learning, Explained](http://www.rightrelevance.com/search/articles/hero?article=5f8cc010177776a7f4d48089ec4e539dc42a1ff9)
* [어떻게 하면 싱싱한 데이터를 모형에 바로 적용할 수 있을까? – Bayesian Online Leaning](http://freesearch.pe.kr/archives/4497)
* [Conditional probability explained visually (Bayes Theorem formula)](https://www.youtube.com/watch?v=Zxm4Xxvzohk)
* [Bayesian Machine Learning, Explained](http://www.kdnuggets.com/2016/07/bayesian-machine-learning-explained.html)
* [Machine learning - Bayesian optimization and multi-armed bandits](https://www.youtube.com/watch?v=vz3D36VXefI&t=1786s)
* [How Bayesian inference works](https://www.youtube.com/watch?v=5NMxiOGL39M)
* [A visual guide to Bayesian thinking](https://www.youtube.com/watch?v=BrK7X_XlGB8)
* [Introduction to Bayesian Statistics, part 1: The basic concepts](https://www.youtube.com/watch?v=0F0QoMCSKJ4)
* [Introduction to Bayesian Statistics, part 2: MCMC and the Metropolis Hastings algorithm](https://www.youtube.com/watch?v=OTO1DygELpY)
* [Learning to Love Bayesian Statistics](https://www.youtube.com/watch?v=R6d-AbkhBQ8)
* [Bayesian statistics made (as) simple (as possible)](https://www.youtube.com/watch?v=bobeo5kFz1g)
* [Bayesian statistics syllabus](https://www.youtube.com/watch?v=U1HbB0ATZ_A&list=PLFDbGp5YzjqXQ4oE4w9GVWdiokWB9gEpm)
* [Bayesian Deep Learning NIPS 2016 Workshop](http://bayesiandeeplearning.org/#schedule)
* [bayesian_linear_regression.ipynb](https://github.com/liviu-/notebooks/blob/master/bayesian_linear_regression.ipynb)
* [Introduction to Bayesian Linear Regression](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7)
* Bayesian Linear Regression in Python: Using Machine Learning to Predict Student Grades
  * [Part 1 Exploratory Data Analysis, Feature Selection, and Benchmarks](https://medium.com/@williamkoehrsen/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-1-7d0ad817fca5)
  * [Part 2 Implementing a Model, Interpreting Results, and Making Predictions](https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e)
* [**시뮬레이션이 다해주실거야**](http://mathpsych.tumblr.com/post/155015433099/%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98%EC%9D%B4-%EB%8B%A4%ED%95%B4%EC%A3%BC%EC%8B%A4%EA%B1%B0%EC%95%BC)
* [베이지안통계](http://mathpsych.tumblr.com/post/155014009869/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88%ED%86%B5%EA%B3%84)
* [Stan을 이용한 베이지안 회귀분석](http://mathpsych.tumblr.com/post/155094553934/stan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D)
* [Bayesian Deep Learning and Black Box Variational Inference](https://www.youtube.com/watch?v=cbC1M02BO8I&spfreload=10)
* [The Power and Danger of Bayes’ Theorem](http://strangenotions.com/the-power-and-danger-of-bayes-theorem/)
* [**How To Build a Simple Spam-Detecting Machine Learning Classifier**](https://hackernoon.com/how-to-build-a-simple-spam-detecting-machine-learning-classifier-4471fe6b816e)
* [Bayesian Statistics Course Overview.ipynb](https://github.com/KaggleBreak/analyticstool/blob/master/part4/Bayesian/review/Bayesian%20Statistics%20Course%20Overview.ipynb)
* [Thomas Huijskens - Bayesian optimisation with scikit-learn](https://www.youtube.com/watch?v=jtRPxRnOXnk)
* [Bayesian Nonparametric Models](https://www.datasciencecentral.com/profiles/blogs/6448529:BlogPost:635167)
* [Introduction to Bayesian Thinking: from Bayes theorem to Bayes networks](https://towardsdatascience.com/will-you-become-a-zombie-if-a-99-accuracy-test-result-positive-3da371f5134)
* [Conditional probability explained visually (Bayes' Theorem)](https://www.youtube.com/watch?v=Zxm4Xxvzohk)
* [Statistical Computing for Scientists and Engineers](https://www.zabaras.com/statisticalcomputing)
* [Monty Hall & Bayes Thm](http://rpubs.com/foxeyboy/346435)
* Probability concepts explained
  * [Introduction](https://towardsdatascience.com/probability-concepts-explained-introduction-a7c0316de465)
  * [Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)
  * [Bayesian inference for parameter estimation](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348)
* [Underestimating Estimation](https://hackernoon.com/underestimating-estimation-d2e52372f303)
* [Chapter2: Likelihood-based approach](https://www.slideshare.net/JaekwangKim5/chapter2-likelihoodbased-approach)
* [Maximum Likelihood, Maximum a Posteriori, and Bayesian Parameter Estimation](https://medium.com/@amatsukawa/maximum-likelihood-maximum-a-priori-and-bayesian-parameter-estimation-d99a23a0519f)
* [최대사후확률(Maximum a Posterior)](https://www.youtube.com/watch?v=1wuycMA9ijw)
* [StatQuest: Probability vs Likelihood](https://www.youtube.com/watch?v=pYxNSUDSFH4)
* [Bayes’ Rule Applied - Using Bayesian Inference on a real-world problem](https://towardsdatascience.com/bayes-rule-applied-75965e4482ff)
* [How Bayesian statistics convinced me to hit the gym](https://towardsdatascience.com/how-bayesian-statistics-convinced-me-to-hit-the-gym-fa737b0a7ac)
* [Naive Bayes Algorithm In Python](https://stepupanalytics.com/naive-bayes-algorithm-in-python/)
* [베이즈 정리 Bayes' Theorem - rel. 신호와 소음](https://blog.naver.com/vinci22c/220346570972)
* [Bayes’ Theorem: The Holy Grail of Data Science](https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb)
* [베이시안 통계 첫째걸음](https://medium.com/mighty-data-science-bootcamp/%EB%B2%A0%EC%9D%B4%EC%8B%9C%EC%95%88-%ED%86%B5%EA%B3%84-%EC%B2%AB%EA%B1%B8%EC%9D%8C-fcfec9da9f52)
* [베이지안 사후 확율 분포(posterior probability distribution) 분석은 '백선생 김치 볶음밥 간맞추기'이다 | 최프란의 비유 - 측정 통계 데이터 분석](https://www.youtube.com/watch?v=03SufsRx52Y&list=PLgSth2TawHJ9-GG9DiEPNhHJ3rWngNJro)
* [**Bayes theorem, and making probability intuitive**](https://www.youtube.com/watch?v=HZGCoVF3YvM)
* [False positives/negatives and Bayes rule for COVID-19 testing](https://towardsdatascience.com/false-positives-negatives-and-bayes-rule-for-covid-19-testing-750eaba84acd)
* [스탠코리아 StanKorea 베이즈 통계학 소개 Introduction to Bayesian Statistics | 베이즈 정리 & 베이즈 추론 | 베이지안이 되어야 할 이유 - YouTube](https://www.youtube.com/watch?v=ELSxxe6gMaQ)

# Book
* [기초부터 응용까지 무료 통계학 eBook 19선 + α](http://wsyang.com/2013/08/free-ebooks-for-statistics/)
* [An Adventure in STATISTICS](http://discoveringstatistics.blogspot.com/2016/04/if-youre-not-doing-something-different.html)
* [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)
  * [**github.com/hyunblee/ISLR-with-Python**](https://github.com/hyunblee/ISLR-with-Python) Introduction to Statistical Learning in R (ISLR)을 Python으로
    * [K-Nearest Neighbors Regression/Classification & Model Evaluations](http://nbviewer.jupyter.org/github/hyunblee/ISLR-with-Python/blob/master/Ch4-Classification/Ch4_KNN_Reg_Clf_n_Evaluation.ipynb)
* [Understanding The New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis (Multivariate Applications Series)](https://www.amazon.com/Understanding-New-Statistics-Meta-Analysis-Multivariate/dp/041587968X)
* [Introduction to the New Statistics: Estimation, Open Science, and Beyond](https://www.amazon.com/Introduction-New-Statistics-Estimation-Science/dp/1138825522/)
* [Think Stats 2e](http://greenteapress.com/wp/think-stats-2e/) python + statistics, free download
* [Computer Age Statistical Inference: Algorithms, Evidence and Data Science](https://web.stanford.edu/~hastie/CASI/)
  * [Python code for Computer Age Statistical Inference by Bradley Efron and Trevor Hastie](https://github.com/jrfiedler/CASI_Python)
* [project mosaic book](http://project-mosaic-books.com/) Computer-savvy textbooks on statistics and data science

# Haskell
* [A gentle introduction to statistical relational learning: maths, code, and examples](http://phdp.github.io/posts/2015-07-13-srl-code.html)

# Library
* [Javascript library for the visualization of statistical distributions](https://github.com/richarddmorey/stat-distributions-js)
* [Stan is a probabilistic programming language implementing full Bayesian statistical inference](http://mc-stan.org/)
  * [StanCon Contributed Talks](https://github.com/stan-dev/stancon_talks)
  * [StanCon 2018 - Intro Stan Class Materials](http://mc-stan.org/workshops/stancon2018_intro/)
  * [Stan Conference 2017](https://www.youtube.com/watch?v=DJ0c7Bm5Djk)

# MOOC, Lecture
* [경제통계학](http://snui.snu.ac.kr/ocw/index.php?mode=view&id=1494)
* [pubdata.tistory.com/category/Lecture_Statistics](http://pubdata.tistory.com/category/Data/Statistics)
* [Engineering Statistics](http://www.itl.nist.gov/div898/handbook/index.htm)
* [CS109: Probability for Computer Scientists](http://web.stanford.edu/class/cs109) 강의노트, 슬라이드, 데모 제공

# Poisson Distribution
* [Understanding Waiting Times Between Events with the Poisson and Exponential Distributions](http://nbviewer.ipython.org/github/nicolewhite/notebooks/blob/master/Poisson.ipynb)
* [Predicting the Frequency of Asteroid Impacts with a Poisson Processes](https://towardsdatascience.com/predicting-the-frequency-of-asteroid-impacts-with-a-poisson-processes-98d483efa61d)
* [푸아송 분포의 아이디어와 유도 과정에 대한 구체적인 원리](https://injae-kim.github.io/dev/2020/07/17/easy-to-understand-poisson-distribution.html)

# Probability
* [Probability Cheatsheet](http://www.wzchen.com/probability-cheatsheet)
* [Foundations of probability theory](https://terrytao.wordpress.com/2015/09/29/275a-notes-0-foundations-of-probability-theory/)
* [Heuristic models for marginal probability assessment updates](http://xheimlichkeit.com/methods/2015/10/12/how-to-update-probabilities.html)
* [Probability concepts explained: Marginalisation](https://towardsdatascience.com/probability-concepts-explained-marginalisation-2296846344fc)
* [**Statistics 110: Probability**](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)

## Probablistic Programming
* [What is probabilistic programming?](http://radar.oreilly.com/2013/04/probabilistic-programming.html)
* [Anglican - a open source, just-in-time-compiled probablistic programming language](http://www.robots.ox.ac.uk/~fwood/anglican/index.html)
* [An intro to Bayesian methods and probabilistic programming from a computation/understanding-first, mathematics-second point of view](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/#contents)
* [Probabilistic Programming for Anomaly Detection](http://blog.fastforwardlabs.com/post/143792498983/probabilistic-programming-for-anomaly-detection)
* [probabilistic graphical models](https://ermongroup.github.io/cs228-notes/)
* [**Infer.NET - a framework for running Bayesian inference in graphical models. It can also be used for probabilistic programming**](https://github.com/dotnet/infer)
  * 원래 유료였는데 오픈소스로 바뀌었다고 함
* [pyro.ai](http://pyro.ai/) Deep Universal Probabilistic Programming
  * 딥러닝과 베이지안 모델링을 아우르는 Deep Probablistic Modeling을 위해 만들었다고 함
  * [Uber AI Labs Open Sources Pyro, a Deep Probabilistic Programming Language](https://eng.uber.com/pyro/)
  * [An intro to Probabilistic Programming with Ubers Pyro](https://www.youtube.com/watch?v=ATaMq62fXno)
  * [Financial forecasting with probabilistic programming and Pyro](https://medium.com/@alexrachnog/financial-forecasting-with-probabilistic-programming-and-pyro-db68ab1a1dba)

# Python
* [How To Implement These 5 Powerful Probability Distributions In Python](http://hpc-asia.com/how-to-implement-these-5-powerful-probability-distributions-in-python/)
* [An Introduction to Statistics with Python](http://work.thaslwanter.at/Stats/html/)
* [Computational Statistics in Python](http://people.duke.edu/~ccc14/sta-663/index.html)
* [통계적 사고: 파이썬을 이용한 탐색적 자료 분석](http://think-stat.xwmooc.org/)
* [Fitting Multivariate Normal Distributions](https://waterprogramming.wordpress.com/category/programming/python/)
* [파이썬 확률과 통계 기초 이해하기](http://www.slideshare.net/dahlmoon/lambda-20160315)
* [Eric J Ma Bayesian Statistical Analysis with Python PyCon 2017](https://www.youtube.com/watch?v=p1IB4zWq9C8)
* [Christine Waigl The Next Step Finding Model Parameters With Random Walks PyCon 2017](https://www.youtube.com/watch?v=sHS2-av7AgQ)
* [**Python For Sport Scientists: Descriptive Statistics**](https://towardsdatascience.com/python-for-sport-scientists-descriptive-statistics-96ed7e66ab3c) 기초 내용 설명
* [Statistical Modeling In Python](https://www.youtube.com/watch?v=sZISc-VqVWg)
* [**확률 분포 튜토리얼**](https://brunch.co.kr/@chris-song/90)
* [Christopher Fonnesbeck - Introduction to Statistical Modeling with Python - PyCon 2017](https://www.youtube.com/watch?v=TMmSESkhRtI)
* [Estimating Probabilities with Bayesian Modeling in Python](https://towardsdatascience.com/estimating-probabilities-with-bayesian-modeling-in-python-7144be007815)
* [A Random Walk & Monte Carlo Simulation || Python Tutorial || Learn Python Programming](https://www.youtube.com/watch?v=BfS2H1y6tzQ)
* [Survival Analysis (생존분석) 어떤 사건의 발생 확률을 시간이란 변수와 함께 생각하는 통계 분석 및 예측 기법](https://hyperconnect.github.io/2019/07/16/survival-analysis-part1.html)
* [Survival Analysis (2/3)](https://hyperconnect.github.io/2019/08/22/survival-analysis-part2.html)
* [Bayesian optimization](http://krasserm.github.io/2018/03/21/bayesian-optimization/)
* [**30명이면 된다고? 회의에서 당당하게, 설문조사를 알아보자**](http://triviaz.net/blog:easy_clt_survey)
* [Statistics Tutorial with Python - YouTube](https://www.youtube.com/watch?v=YCPYNXtwKAc)
* [Statistics Tutorial 2 Real World Example - YouTube](https://www.youtube.com/watch?v=ger_Won5sRQ)
* [Moment Generating Function for Probability Distribution with Python | by Towards AI Team | Towards AI — Multidisciplinary Science Journal | Sep, 2020 | Medium](https://medium.com/towards-artificial-intelligence/moment-generating-function-for-probability-distribution-with-python-tutorial-34857e93d8f6)
* [bayesianPy](http://psygrammer.github.io/bayesianPy/)
* [DRL Monte Carlo Mothods](https://parksurk.github.io/deep/reinfocement/learning/drlnd_1-4_monte_calro_methods-post)
* [ISLR-python](https://github.com/JWarmenhoven/ISLR-python)
* [m2cgen - Transform ML models into a native code (Java, C, Python, Go) with zero dependencies](https://github.com/BayesWitnesses/m2cgen)
* [pomegranate - a package for graphical models and Bayesian statistics for Python, implemented in cython](https://github.com/jmschrei/pomegranate)
  * 확률분포, GMM, HMM, Naive Bayes, Bayes Classifiers, Markov Chains 등을 지원
* [powerlaw - Toolbox for testing if a probability distribution fits a power law](https://pypi.org/project/powerlaw/)
* [PyMC: Bayesian Stochastic Modelling in Python http://pymc-devs.github.com/pymc ](https://github.com/pymc-devs/pymc)
  * [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
  * [A/B Testing with Hierarchical Models in Python](http://blog.dominodatalab.com/ab-testing-with-hierarchical-models-in-python/)
  * [Bayesian Methods for Hackers - Using Python and PyMC](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)
  * [Torsten Scholak, Diego Maniloff Intro to Bayesian Machine Learning with PyMC3 and Edward](https://www.youtube.com/watch?v=fR5Wvb86-IU)
  * [Christopher Fonnesbeck Probabilistic Programming with PyMC3 PyCon 2017](https://www.youtube.com/watch?v=5TyvJ6jXHYE)
  * [Markov Chain Monte Carlo in Python - A Complete Real-World Implementation](https://towardsdatascience.com/markov-chain-monte-carlo-in-python-44f7e609be98)
  * [Probabilistic Programming: A Modern Bayesian Workflow || Peadar Coyle](https://www.youtube.com/watch?v=7QlKZKbQa6M)
  * [Hands On Bayesian Statistics with Python, PyMC3 & ArviZ](https://towardsdatascience.com/hands-on-bayesian-statistics-with-python-pymc3-arviz-499db9a59501)
* [Statistics Using Python Tutorial](https://www.youtube.com/playlist?list=PLlz0muypSBNZXEDDy7RftBdIJNHEN0t1a)
  * [Part 4](https://www.youtube.com/watch?v=6ZA5lvooc5I)
  * [Part 5](https://www.youtube.com/watch?v=CISnF83dGTc)
* [ThinkBayes (IPython notebook included)](https://github.com/rlabbe/ThinkBayes)

# R
* [bayesianR](http://psygrammer.github.io/bayesianR/)
