Deep Learning
=============
* [수학자는 어떻게 인공지능을 발전시키는가?](https://brunch.co.kr/@kakao-it/244)
* [Deep Dive into Math Behind Deep Networks](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba)
* [MathsDL-spring18 - Topics course Mathematics of Deep Learning, NYU, Spring 18](https://joanbruna.github.io/MathsDL-spring18/)
* [딥러닝(데이터분석/머신러닝)을 위한 수학](https://github.com/mycampus-io/math-for-deep-learning)
* [왜 크로스 엔트로피를 쓸까? 정확도의 이론적 바운드](https://theeluwin.postype.com/post/6080524)
* [딥러닝 마일스톤](https://www.facebook.com/nextobe1/posts/344853295950672)
* [From Perceptron to Deep Neural Nets](https://becominghuman.ai/from-perceptron-to-deep-neural-nets-504b8ff616e)
* [인공신경망, 퍼셉트론](https://www.youtube.com/playlist?list=PLaTc2c6yEwmpYKMDfj737S7a_KYC5J5Tq)
* [Building a Deep Neural Net In Google Sheets](https://towardsdatascience.com/building-a-deep-neural-net-in-google-sheets-49cdaf466da0)
* [Deep Learning - Taking machine learning to the next level](https://www.udacity.com/course/deep-learning--ud730)
* [Deep Learning Nanodegree Foundation](https://github.com/udacity/deep-learning)
* [**Awesome Deep Learning**](https://github.com/ChristosChristofidis/awesome-deep-learning)
* [Awesome Deep Learning Resources](https://github.com/guillaume-chevalier/awesome-deep-learning-resources)
* [DeepLearning-Summary](https://github.com/taki0112/Awesome-DeepLearning-Study)
* [awesome-network-embedding](https://github.com/chihming/awesome-network-embedding)
* [Deep Learning Drizzle](https://github.com/kmario23/deep-learning-drizzle)
* [Deep Learning Drizzle](https://deep-learning-drizzle.github.io/)
* [Deep Learning - 2016년 8월부터 딥러닝공부를 하면서 봤던 강의영상, 동영상, 블로그들의 목록입니다](https://github.com/GunhoChoi/Deep_Learning_Collection)
* [digest.deeplearningweekly.com](http://digest.deeplearningweekly.com/)
* [Top Deep Learning Projects](https://github.com/hunkim/DeepLearningStars)
* [Deep Learning Resources](https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html)
* [Up to Speed on Deep Learning: September, Part 2 and October, Part 1](https://medium.com/the-mission/up-to-speed-on-deep-learning-september-part-2-and-october-part-1-d72d7e5df1ea)
* [My playlist – Top YouTube Videos on Machine HALearning, Neural Network & Deep Learning](http://www.analyticsvidhya.com/blog/2015/07/top-youtube-videos-machine-learning-neural-network-deep-learning/)
* [Designing Machine Learning Models: A Tale of Precision and Recall](http://nerds.airbnb.com/designing-machine-learning-models/)
* [Deep Learning Study](http://deeplearningstudy.github.io/material/) Caffe, TensorFlow
* [The Deep Learning Playbook](https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a)
* [A Brief Overview of Deep Learning](http://yyue.blogspot.kr/2015/01/a-brief-overview-of-deep-learning.html)
* [github.com/wbaek/deeplearing_exercise](https://github.com/wbaek/deeplearing_exercise)
* [deepcumen.com](http://deepcumen.com/)
* [Deep Learning Study - Study of HeXA at Ulsan National Institute of Science and Technology](https://github.com/carpedm20/deep-learning-study)
* [My Journal from Neural Network to Deep Learning: A Brief Introduction to Deep Learning. Contents](http://haohanw.blogspot.kr/2015/01/deep-learning-introduction.html)
* [Deep learning - Yann LeCun, Yoshua Bengio & Geoffrey Hinton](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html)
* [nvidia Deep Learning Courses](https://developer.nvidia.com/deep-learning-courses)
  * [Deep Learning Course](https://www.youtube.com/playlist?list=PL5B692fm6--tI-ijknnVZWbXU2H4JpSYe)
* [Best Resources to Learn Deep Learning( YouTube, Tutorials, etc)- 2021](https://www.mltut.com/best-resources-to-learn-deep-learning/)
* [Best Courses to Learn Deep Learning Beginner to Advanced Level-2022](https://www.mltut.com/best-courses-to-learn-deep-learning/)
* [Why GEMM is at the heart of deep learning](http://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/)
* [딥러닝 워크샵: 딥러닝의 현재와 미래](http://mlcenter.postech.ac.kr/workshop)
  * [후기](http://whydsp.org/262)
* [Deep Learning at Flickr, Pierre Garrigues](http://techjaw.com/2015/03/04/deep-learning-at-flickr-pierre-garrigues/)
* [Andrew Ng: Why ‘Deep Learning’ Is a Mandate for Humans, Not Just Machines](http://www.wired.com/2015/05/andrew-ng-deep-learning-mandate-humans-not-just-machines/)
* [Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning](https://www.youtube.com/watch?v=n1ViNeWhC24)
* [The tensor renaissance in data science](http://radar.oreilly.com/2015/05/the-tensor-renaissance-in-data-science.html)
* [Tensor Explained](https://www.slideshare.net/seonghunchoe7/tensor-explained)
* [The Paradox of Deeper Learning: The Unlearning Curve](http://blogs.edweek.org/edweek/learning_deeply/2015/04/the_paradox_of_deeper_learning_the_unlearning_curve.html)
* [Are there Deep Reasons Underlying the Pathologies of Today’s Deep Learning Algorithms?](http://goertzel.org/DeepLearning_v1.pdf)
* [집단지성프로그래밍 05. 최적화(optimization) 김지은 20150522](http://www.slideshare.net/yeswldms/05-optimization-20150522)
* [A birds-eye view of optimization algorithms](http://fa.bianp.net/teaching/2018/eecs227at/)
* [slideslive.com/iclr](https://slideslive.com/iclr)
* [Top 8 trends from ICLR 2019 번역글](https://subinium.github.io/top-8-trends-from-ICLR2019-kr)
* [Deep Learning for Computer Vision Barcelona](http://imatge-upc.github.io/telecombcn-2016-dlcv/)
* [Algorithms of the Mind](https://medium.com/deep-learning-101/algorithms-of-the-mind-10eb13f61fc4)
* [What's Wrong With Deep Learning?](https://drive.google.com/file/d/0BxKBnD5y2M8NVHRiVXBnOVpiYUk/edit)
* [Why does Deep Learning work?](https://charlesmartin14.wordpress.com/2015/03/25/why-does-deep-learning-work/)
* [Why Deep Learning Works II: the Renormalization Group](https://charlesmartin14.wordpress.com/2015/04/01/why-deep-learning-works-ii-the-renormalization-group/)
* [Why Deep Learning Works](https://artificial-understanding.com/why-deep-learning-works-1b0184686af6)
* [Normalization 방법](https://www.slideshare.net/ssuser06e0c5/normalization-72539464)
* [Normalization vs Standardization - Quantitative analysis (KR)](https://databreak.netlify.com/2019-05-02-Normalization_vs_Standardization-Quantitative%20analysis)
* [18 Great Deep Learning Resources, most free](http://blog.sense.io/18-great-deep-learning-resources)
* [인공지능의 눈으로 바라본 세상](http://techneedle.com/archives/20800)
* [XLDB2015: Accelerating Deep Learning at Facebook](https://www.youtube.com/watch?v=KviuMAF4pEA)
* [The Brain vs Deep Learning Part I: Computational Complexity — Or Why the Singularity Is Nowhere Near](https://timdettmers.wordpress.com/2015/07/27/brain-vs-deep-learning-singularity/)
* [A Beginner’s Guide to Restricted Boltzmann Machines](http://deeplearning4j.org/restrictedboltzmannmachine.html)
* [Energy based models and boltzmann machines - v2.0](http://www.slideshare.net/blaswan/energy-based-models-and-boltzmann-machines-v20)
* [내맘대로 이해하는 Deep Belief Network와Restricted Boltzmann Machine](http://whydsp.org/283)
* [Deep Learning meets Physics: Restricted Boltzmann Machines Part I](https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15)
* Deep learning for assisting the process of music composition
  * [part 1](https://highnoongmt.wordpress.com/2015/08/11/deep-learning-for-assisting-the-process-of-music-composition-part-1)
  * [part 2](https://highnoongmt.wordpress.com/2015/08/12/deep-learning-for-assisting-the-process-of-music-composition-part-2)
  * [part 3](https://highnoongmt.wordpress.com/2015/08/13/deep-learning-for-assisting-the-process-of-music-composition-part-3)
  * [part 4](https://highnoongmt.wordpress.com/2015/08/15/deep-learning-for-assisting-the-process-of-music-composition-part-4)
* [Neural Translation of Musical Style](http://imanmalik.com/cs/2017/06/05/neural-style.html)
* [End-to-end Music Classification](https://www.slideshare.net/JunKim22/endtoend-music-classification-96586946)
* [Sound Classification using Deep Learning](https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7)
* [Guitar-Set, a New Dataset for Music Information Retrieval](https://medium.com/center-for-data-science/guitar-set-a-new-dataset-for-music-information-retrieval-41b7861a87d7)
* [Music Deep learning 프로젝트는 왜 별로 없을까요?](https://media-ai.tistory.com/15)
* [Machine Learning for Creativity and Design Workshop (NeurIPS2018), and +@](https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/)
* [Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning](https://www.youtube.com/watch?v=n1ViNeWhC24)
* [Deep Learning Summer School 2015](https://sites.google.com/site/deeplearningsummerschool/)
  * [Deep Learning Summer School, Montreal 2015](http://videolectures.net/deeplearning2015_montreal/)
* [Deep Learning Summer School 2016](https://sites.google.com/site/deeplearningsummerschool2016/)
  * [Deep Learning Summer School, Montreal 2016](http://videolectures.net/deeplearning2016_montreal/)
  * [What I learned from Deep Learning Summer School 2016](https://www.linkedin.com/pulse/what-i-learned-from-deep-learning-summer-school-2016-hamid-palangi)
* [Deep Learning Summer School, Montreal 2017](http://videolectures.net/deeplearning2017_montreal/)
* [26 THINGS I LEARNED IN THE DEEP LEARNING SUMMER SCHOOL](http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/)
* [Deep Learning and Neural Networks](http://cl.naist.jp/~kevinduh/a/deep2014/)
* [한국에서 처음 열린 GTC, 딥러닝의 현재를 이야기하다](http://chitsol.com/2273)
* [네이버, 사람 없이 이미지 뉴스 만든다](http://www.bloter.net/archives/238742)
* [Deep Learning Startups, Applications and Acquisitions – A Summary](http://blog.dennybritz.com/2015/10/13/deep-learning-startups-applications-and-acquisitions-a-summary/)
* [Theoretical Motivations for Deep Learning](http://rinuboney.github.io/2015/10/18/theoretical-motivations-deep-learning.html)
* [How We Use Deep Learning to Classify Business Photos at Yelp](http://engineeringblog.yelp.com/2015/10/how-we-use-deep-learning-to-classify-business-photos-at-yelp.html)
* [PyData Tel Aviv Meetup: Deep Analysis of Clickstream - Segev Arbiv](https://www.youtube.com/watch?v=YBl1H3fPBAQ) classify web traffic
* [Artificial Intelligence, Neural Networks, and Deep Learning](http://kimschmidtsbrain.com/2015/10/29/artificial-intelligence-neural-networks-and-deep-learning/)
* [Deep Learning in a Single File for Smart Devices](http://dmlc.ml/mxnet/2015/11/10/deep-learning-in-a-single-file-for-smart-device.html)
* [Boosting Methods](http://enginius.tistory.com/m/post/606)
* [Deep Residual Networks](https://github.com/KaimingHe/deep-residual-networks)
* [stat212b - Topics Course on Deep Learning for Spring 2016](https://github.com/joanbruna/stat212b)
* [Fujitsu develops new deep learning technology to analyze time-series data with high precision](http://phys.org/news/2016-02-fujitsu-deep-technology-time-series-high.html)
* 2016-02-17~18 자연어처리 튜토리얼 심층학습과 언어처리 응용
  * TensorFlow Tutorial; SKT 정상근 박사님
    * [GitHub](https://github.com/hugman/deep_learning)
    * mnist.py 파일을 먼저 본다.
    * mnist_with_monitoring.py
      * TensorBoard 서버에 모니터링 로그를 보내고 웹으로 볼 수 있다
    * Keras
      * computaion backend를 추상화하여 편하게 적용할 수 있도록 하는 라이브러리
      * theano, tensorflow 둘다 지원
      * 형태소 분석기같은 걸 빠르게 만들어 보기에 좋다
    * pos_tagger_fcn.py
      * word embedding => wikipedia로 SENNA에서 만들어서 오픈한 데이터
      * 변수명은 mnist와 일부러 동일하게 뒀으니 비교해서 보면 좋음
      * 참고: fcn => fully connected network
    * pos_tagger_rnn_seq.py
      * 궁극의 코드!
      * learning rate를 처음에는 크게해서 점점 작게 만들어 준다
      * optimizer를 바꿔가며 학습을 할 수도 있다
      * epoch이 50이 넘으면 중간에 바꿔라! 등
    * TensorFlow github 소스에 보면,
      * models -> rnn -> translate 구글의 기계번역 소스가 있다
      * https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/translate
  * Deep Learning for NLP 응용; 강원대 이창기 박사님
    * [NLP from Scratch](http://arxiv.org/abs/1103.0398)
    * [SENNA](http://ronan.collobert.com/senna)
      * CNN + CRF
    * RNN(LSTM) + attention score
      * attention score는 alignment prob과 동일한 역할을 해준다.
    * t-SNE scatter plot
      * 자질의 차원을 축소하여 2차원으로 뿌려주는 방식
* [Visualizing Deep Learning with t-SNE (Tutorial and Video)](https://medium.com/@awjuliani/visualizing-deep-learning-with-t-sne-tutorial-and-video-e7c59ee4080c)
* [Make Your Own 3D t-SNE Visualizations (Download Binary and Code)](https://medium.com/@awjuliani/make-your-own-3d-t-sne-visualizations-download-e0cdfe80d6e3)
* [오픈 소스 딥러닝 소프트웨어](http://kernelstudy.net/t/topic/188)
* [DataScience/Deep Learning](http://khanrc.tistory.com/category/DataScience/Deep%20Learning)
* [Introduction to Deep Learning for Image Analysis at Strata NYC, Sep 2015](http://www.slideshare.net/dato-inc/introduction-to-deep-learning-for-image-analysis-at-strata-nyc-sep-2015)
* [Show and tell takmin: A Neural Image Caption Generator](http://www.slideshare.net/takmin/show-andtell-takmin)
* [Building an Automated Image Captioning Application](https://daniel.lasiman.com/post/image-captioning/)
* [그림 그리는 AI](http://tv.naver.com/v/2417457)
* [딥러닝 임팩트가 온다](http://techholic.co.kr/archives/51820)
* [Deep Learning for Visual Question Answering](http://avisingh599.github.io/deeplearning/visual-qa/)
* [Visualizing and Understanding Deep Neural Networks by Matt Zeiler](https://www.youtube.com/watch?v=ghEmQSxT6tw&spfreload=10)
* [Visualizing Deep Learning Networks - Part II](http://blog.qure.ai/notes/deep-learning-visualization-gradient-based-methods)
* [How to draw Deep learning network architecture diagrams?](https://datascience.stackexchange.com/questions/14899/how-to-draw-deep-learning-network-architecture-diagrams)
* [When Does Deep Learning Work Better Than SVMs or Random Forests?](http://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html)
* [openai.com](https://openai.com)
  * [OpenAI Universe (OpenAI)](https://universe.openai.com/)
  * [오픈소스로…인공지능 학습 플랫폼](http://techholic.co.kr/archives/64126)
  * [GTA V + Universe](https://openai.com/blog/GTA-V-plus-Universe/)
  * [Actor Critic with OpenAI Gym](http://www.rage.net/~greg/2016-07-05-ActorCritic-with-OpenAI-Gym.html)
  * [Learning to communicate](https://openai.com/blog/learning-to-communicate/)
  * [첫번째 프로젝트: gym 기반으로 틱택토 환경 만들어 보기](https://github.com/kekmodel/gym-TicTacToe)
  * [atari_py - A Windows-MSYS2-MinGW compatible version of https://github.com/openai/ale_python_interface](https://github.com/rybskej/atari-py)
  * [강화학습 그리고 OpenAI - 1: Introduction to OpenAI](http://www.modulabs.co.kr/RL_library/1705)
  * [Gathering Human Feedback](https://blog.openai.com/gathering_human_feedback/)
  * [Rendering OpenAi Gym in Colaboratory.ipynb](https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t#scrollTo=8nj5sjsk15IT)
  * [multiprocessing에서 gym이 오작동하는 경우](https://ysr-plus-ultra.github.io/posts/2019/07/30/post004.html)
  * [OpenAI's Jukebox has a Colab Notebook for interacting with it!](https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb)
  * [OpenAI Model Generates Python Code - YouTube](https://www.youtube.com/watch?v=fZSFNUT6iY8)
  * [Trending use cases of GPT-3 by openAI | by Anjali | Eoraa & Co. | Aug, 2021 | Medium](https://medium.com/eoraa-co/trending-use-cases-of-gpt-3-by-openai-56318b6a9184)
  * [Introducing Text and Code Embeddings in the OpenAI API](https://openai.com/blog/introducing-text-and-code-embeddings/)
  * [Solving (Some) Formal Math Olympiad Problems](https://openai.com/blog/formal-math/)
  * [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)
    * [DALL-E, 메타버스, 그리고 한계비용 제로 콘텐츠 (번역)￼ – 이바닥늬우스](https://ebadak.news/2022/07/18/dall-e-the-metaverse-and-zero-marginal-content/)
    * [I replaced all our blog thumbnails using DALL·E 2 for $45: here’s what I learned | Deephaven](https://deephaven.io/blog/2022/08/08/AI-generated-blog-thumbnails/)
      * 이미지가 있는 블로그 글은 2.3배 더 engagement가 높은데, 이 블로그 이미지를 만들 사람이 없으므로
        * DALL·E 2를 이용해서 블로그의 이미지를 만들어 내면서 배운 과정 설명
      * DALL·E 2 프롬프트에 설명을 적으면 이미지를 얻을 수 있는데 이때
        * 창의성이 꽤 필요, 원하는 이미지를 얻으려면 연습이 좀 필요
        * 스타일 수정 요구사항을 주면 도움
        * 아이디어를 얻기 위해 Reddit의 도움을 받을 수 있고
        * 이상한 문자를 종종 출력하므로 이는 따로 지우는 게 좋음
        * 특히 숫자에 대한 것은 잘 처리 못함
      * 예술에서 사람의 역할이 곧 사라지진 않겠지만 이미지 사이트는 오래 가지 않을 거라고 얘기, 100개 블로그 이미지를 얻는데 45달러
    * [How I Used DALL·E 2 to Generate The Logo for OctoSQL | Jacob Martin](https://jacobmartins.com/posts/how-i-used-dalle2-to-generate-the-logo-for-octosql/)
      * OctoSQL이라는 프로젝트의 로고를 만들기 위해서 DALL·E 2를 사용하는 과정 설명
      * Octo라는 이름이 붙은 만큼 문어가 들어간 원하는 아이디어가 있었고
      * 원하는 이미지를 얻기 위해서 계속해서 키워드를 바꿔가면서 얻어낸 로고의 기록
    * [The-DALL·E-2-prompt-book-v1.02.pdf](http://dallery.gallery/wp-content/uploads/2022/07/The-DALL%C2%B7E-2-prompt-book-v1.02.pdf)
      * DALL·E 2의 프롬프트를 어떻게 이용할 수 있고 어떤 결과가 나오는지 정리된 PDF. DALL·E 2를 활용하기 전에 참고해 보기 좋은 문서
  * [OpenAI Baselines: high-quality implementations of reinforcement learning algorithms](https://github.com/openai/baselines)
    * [OpenAI Baselines: DQN](https://blog.openai.com/openai-baselines-dqn/)
    * [OpenAi Baselines을 깔면서 나타나는 오류를 잡아보자](https://blog.naver.com/cjsdyd2000/221263903468)
  * [OpenAI Gym Beta](https://openai.com/blog/openai-gym-beta/)
    * [AI Gym Workout](https://learningai.io/projects/2017/07/28/ai-gym-workout.html)
    * [Walker2D: Learning Progression](https://www.youtube.com/watch?v=irkXnpZP89s)
    * [gist.github.com/pat-coady](https://gist.github.com/pat-coady)
    * [OpenAI GYM atari-py 설치 오류 해결](http://rrbb014.tistory.com/43)
    * [OpenAI GYM을 Jupyter notebook환경에서 실행하기 & headless playing](http://rrbb014.tistory.com/44)
  * [OpenAI는 뉴럴 네트워크 대형 모델을 어떻게 학습시키는가](https://velog.io/@aldente0630/%EB%8C%80%ED%98%95-%EB%89%B4%EB%9F%B4-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%ED%9B%88%EB%A0%A8-%EA%B8%B0%EB%B2%95)
  * [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
    * [natural-language-youtube-search: Search inside YouTube videos using natural language](https://github.com/haltakov/natural-language-youtube-search)
    * [clip-as-service: Embed images and sentences into fixed-length vectors with CLIP](https://github.com/jina-ai/clip-as-service)
    * [clipping-CLIP-to-GAN](https://github.com/cloneofsimo/clipping-CLIP-to-GAN)
  * [orrb - Code for the paper "OpenAI Remote Rendering Backend"](https://github.com/openai/orrb)
  * [requests-for-research](https://openai.com/requests-for-research/)
  * [PIXELCNN++: A PIXELCNN IMPLEMENTATION WITH DISCRETIZED LOGISTIC MIXTURE LIKELIHOOD AND OTHER MODIFICATIONS](https://openreview.net/pdf?id=BJrFC6ceg)
    * [pixel-cnn++ - This is a Python3 / Tensorflow implementation of PixelCNN++](https://github.com/openai/pixel-cnn)
    * [PixelCNN 1601.06759 Summary](https://tensorflow.blog/2016/11/29/pixelcnn-1601-06759-summary/)
* [Neural Programmer-Interpreters](http://www-personal.umich.edu/~reedscot/iclr_project.html)
* [Video Recordings of the ICML’15 Deep Learning Workshop](http://dpkingma.com/?page_id=483)
  * [딥러닝 워크샵 패널토의 @ ICML2015](http://t-robotics.blogspot.com/2015/07/icml2015.html#.VyyRohWLSZ0)
* [Deep Learning: Nine Lectures at Collège de France](http://cilvr.nyu.edu/doku.php?id=courses%3Adeeplearning-cdf2016%3Astart)
* [Deep Learning with RE•WORK #reworkDL](https://www.youtube.com/playlist?list=PLnDbcXCpYZ8m412d2KX5paGKdGUxxWCEP)
* [csl.sony.fr/publications](https://www.csl.sony.fr/publications.php)
  * [인공지능이 편곡한 '환희의 송가'](http://www.yonhapnews.co.kr/local/0899000000.html?cid=MYH20160511017400797)
  * [Machine Learning Techniques for Reorchestrating the European Anthem](https://www.youtube.com/watch?list=PLuOoXrWK6Kz5ySULxGMtAUdZEg9SkXDoq&v=0qnTaAz-xtQ)
* [Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records](http://www.nature.com/articles/srep26094)
* [deepnumbers.com](http://www.deepnumbers.com/)
* [10 Deep Learning Terms Explained in Simple English](http://www.datasciencecentral.com/m/blogpost?id=6448529%3ABlogPost%3A410633)
* [A Statistical View of Deep Learning](http://blog.shakirm.com/ml-series/a-statistical-view-of-deep-learning/)
* [Deep Learning in Practice: Speech Recognition and Beyond](http://events.technologyreview.com/emtech/digital/16/video/watch/andrew-ng-deep-learning/)
* [CHAR2WAV: END-TO-END SPEECH SYNTHESIS](https://mila.umontreal.ca/en/publication/char2wav-end-to-end-speech-synthesis/)
* [DEEP LEARNING AND REINFORCEMENT LEARNING SUMMER SCHOOL 2017](https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/slides/)
* [Google DeepMind Teaches Artificial Intelligence Machines to Read](http://www.technologyreview.com/view/538616/google-deepmind-teaches-artificial-intelligence-machines-to-read/)
* [WaveNet: A Generative Model for Raw Audio](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)
  * [A TensorFlow implementation of DeepMind's WaveNet paper](https://github.com/ibab/tensorflow-wavenet)
  * [Voice User Interfaces Project: Speech Recognition with Neural Networks](https://github.com/udacity/AIND-VUI-Capstone/blob/master/vui_notebook.ipynb)
  * [Speech-to-Text-WaveNet : End-to-end sentence level English speech recognition using DeepMind's WaveNet](https://github.com/buriburisuri/speech-to-text-wavenet)
* [10 Deep Learning Trends at NIPS 2015](http://codinginparadise.org/ebooks/html/blog/ten_deep_learning_trends_at_nips_2015.html)
  * [딥러닝의 10가지 트렌드 from NIPS 2015](http://t-robotics.blogspot.com/2016/01/10-from-nips-2015.html)
* [Nuts and Bolts of Building Deep Learning Applications: Ng @ NIPS2016](http://www.computervisionblog.com/2016/12/nuts-and-bolts-of-building-deep.html)
* Fast and Provably Good Seedings for k-Means
  * [paper](http://papers.nips.cc/paper/6478-fast-and-provably-good-seedings-for-k-means.pdf)
  * [code](https://github.com/obachem/kmc2)
  * [slide](http://olivierbachem.ch/files/afkmcmc-oral-pdf.pdf)
  * [spotlight](https://youtu.be/QtQyeka-tlQ)
  * k-means 클러스터링에서 k-means++으로 초기 클러스터를 정하게 되면 O(log k)번 안에 최적의 클러스터로 수렴하는것이 증명되었지만 초기 O(nkd) 연산이 필요해 대용량 데이터에서는 적합하지 않은 문제가 있음
  * 기존의 k-means++보다 수백배 빠르면서도 결과가 근사한 Assumption-free K-MC^2 를 제안
  * 파이썬 패키지로 배포되어 있으며 scikit-learn에서도 바로 사용 가능
* [클러스터링과 KMeans를 이용한 데이타의 군집화](http://bcho.tistory.com/1203)
* [Hierarchical clustering을 이용한 데이타 군집화](http://bcho.tistory.com/1204)
* [DeepMind Papers @ NIPS (Part 1)](https://deepmind.com/blog/deepmind-papers-nips-part-1/)
* [DeepMind Papers @ NIPS (Part 2)](https://deepmind.com/blog/deepmind-papers-nips-part-2/)
* [DeepMind Papers @ NIPS (Part 3)](https://deepmind.com/blog/deepmind-papers-nips-part-3/)
* [Repo. for NIPS 2016 papers](https://tensorflow.blog/2016/12/15/repo-for-nips-2016-papers/)
* [Bayesian Deep Learning NIPS 2016 Workshop](http://bayesiandeeplearning.org/#schedule)
* [Bayesian Deep Learning](http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/)
* [Bayesian Machine Learning, Explained](http://www.rightrelevance.com/search/articles/hero?article=5f8cc010177776a7f4d48089ec4e539dc42a1ff9)
* [Bayesian Recurrent Neural Networks](https://github.com/mirceamironenco/BayesianRecurrentNN)
* [Understanding Bayesian Deep Learning](https://github.com/sjchoi86/bayes-nn)
* [Bayesian-deep-learning](https://github.com/SeongokRyu/Bayesian-deep-learning)
* [IRT and DKT implementation](https://github.com/Knewton/edm2016)
* [Magenta wins "Best Demo" at NIPS 2016!](https://magenta.tensorflow.org/2016/12/16/nips-demo/)
  * [Magenta AI Jam Session](https://www.youtube.com/watch?v=QlVoR1jQrPk)
  * [Magenta: Music and Art Generation with Machine Intelligence](https://github.com/tensorflow/magenta)
  * [Interactive Musical Improvisation with Magenta (NIPS 2016)](https://github.com/tensorflow/magenta/tree/master/magenta/demos/NIPS_2016)
* [DeepMind Lab (DeepMind)](https://deepmind.com/blog/open-sourcing-deepmind-lab)
* [Learning explanatory rules from noisy data](https://deepmind.com/blog/learning-explanatory-rules-noisy-data/)
  * 신경망의 직관적/지각적 추론과 논리 프로그래밍쪽의 상징/논리 추론을 결합한 프레임워크 ∂ILP
* [모두의연구소 쫄지말자딥러닝](http://www.slideshare.net/modulabs/ss-62503747)
* [쫄지말자딥러닝2 - CNN RNN 포함버전](http://www.slideshare.net/modulabs/2-cnn-rnn)
* [www.modulabs.co.kr/DeepLAB](http://www.modulabs.co.kr/DeepLAB)
  * [딥러닝연구실](http://whydsp.org/m/post?categoryId=525022) 과거 자료
* [What My Deep Model Doesn't Know](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html)
* [Train your deep model faster and sharper — two novel techniques](https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047) training 속도 단축 방법
* [tobigs-gm1 ( 생성모델쟁이) / 시리즈- velog](https://velog.io/@tobigs-gm1/series)
* [Deep Learning with Eigenvalue Decay Regularizer](https://www.researchgate.net/publication/301648136_Deep_Learning_with_Eigenvalue_Decay_Regularizer)
* [Eigenfaces](https://github.com/ml4a/ml4a-guides/blob/master/notebooks/Eigenfaces.ipynb)
* [Deep Network with Stochastic Depth](https://www.evernote.com/shard/s462/sh/2de09526-e8fe-48d9-90da-9baa356d5e1a/7a4259299b26c41d60e05e894dbbc2fa)
* [Prof. Geoff Hinton - Deep Learning](https://www.youtube.com/watch?v=VhmE_UXDOGs)
* [Deep Learning for Recommender Systems](https://www.infoq.com/presentations/dl-models-tensorflow/)
* [맥주마시며 만들어본 딥러닝 맥주 추천엔진](http://freesearch.pe.kr/archives/4656) python
* [SVD를 이용한 추천 시스템 구현하기](http://leebaro.tistory.com/entry/SVD%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)
* [딥러닝 개인화 추천](https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9D%B8%ED%99%94-%EC%B6%94%EC%B2%9C-1eda682c2e8c)
* [딥러닝 추천 시스템 in production](https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-in-production-fa623877e56a) airflow -> kubeflow
* [Absolute ANN: A simplified approach for structuring the learnt representations](https://medium.com/mlreview/aann-absolute-artificial-neural-network-ae8f1a65fa67)
* [차원 축소 (Principal Component Analysis)](http://blog.naver.com/anthouse28/221016346362)
* [차원 감소와 PCA 분석](http://bcho.tistory.com/1209)
* [#5.0. PCA의 이해 (1)](https://www.youtube.com/watch?v=9UggjVi9-9M&list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq&index=23)
  * [PCA의 의미와 한계점](https://www.facebook.com/TRobotics/posts/796663103771140)
  * [PCA(주성분분석)의 의미와 한계점](http://t-robotics.blogspot.com/2015/12/pca.html)
* [PCA: "분산이 큰 축일 수록 정보가 더 많다?"](https://blog.naver.com/hancury/221215245092)
* [PCA; Dimension Reduction + $\alpha$ | Pega Devlog](https://jehyunlee.github.io/2020/07/21/Python-DS-21-PCA/)
* [주성분 분석(Principal Component Analysis) 직관적 & 수식적 설명](https://www.youtube.com/watch?v=UIZhJtOZ6EM)
* [A step by step explanation of Principal Component Analysis](https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2)
* [CS 7931: Deep Learning Seminar](http://ml.cs.utah.edu/deep-learning/)
* [Stanford Seminar - Song Han of Stanford University](https://www.youtube.com/watch?v=hfFkS_vHslI)
  * ["Techniques for Efficient Implementation of Deep Neural Networks," a Presentation from Stanford](http://www.slideshare.net/embeddedvision/techniques-for-efficient-implementation-of-deep-neural-networks-a-presentation-from-stanford)
* [Deep Learning, Tools and Methods workshop](https://portal.klewel.com/watch/webcast/deep-learning-tools-and-methods-workshop/)
* [How to Start Learning Deep Learning](http://www.kdnuggets.com/2016/07/start-learning-deep-learning.html)
* [Summary of Deep Learning Environments](https://www.facebook.com/notes/239472486233783/Summary%20of%20Deep%20Learning%20Environments/587130401467988/)
* [Deep Learning for Object Detection with DIGITS](https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/)
* [Lecture Slides for Deeplearning book](https://github.com/InfolabAI/DeepLearning)
* [khanrc.tistory.com/category/DataScience/Deep Learning](http://khanrc.tistory.com/category/DataScience/Deep%20Learning)
* [도커와 AWS를 활용한 클라우드 딥러닝 환경 구축](https://gist.github.com/haje01/f13053738853f39ce5a2)
  * [Decoupled Neural Interfaces using Synthetic Gradients 1608.05343 Summary](https://tensorflowkorea.wordpress.com/2016/08/22/decoupled-neural-interfaces-using-synthetic-gradients1608-05343-summary/)
* [Initialization Of Deep Networks Case of Rectifiers](http://www.jefkine.com/deep/2016/08/08/initialization-of-deep-networks-case-of-rectifiers/)
* [ANN 구현하고 x^2 근사함수 찾기](https://github.com/dgtgrade/HumanLearning/blob/master/1001.py)
  * Universal Approximation Theorem 에 따르면 간단한 ANN으로도 가능
  * 구현된 간단한 ANN
    * 입력 레이어: 노드 1개
      * x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음
    * 히든 레이어: 1개, 노드: 50개
      * a = sigmoid(wx + b1)
    * 출력 레이어: 노드 1개
      * o = wa + b2
    * 코스트 함수: Squared Error
    * 히든 레이어가 하나라서 DNN이라고 적지 않음
    * ANN 중 가장 표준적이고 기초적이라고 할 수 있는 ANN 그대로, 또는 그중에서도 가장 간단한 형태라고 보면 됨
  * 실험 결과
    * t(x)=x^2 함수: x=[1.0~12.0]까지 학습 시켰는데 잘 되었음
    * t(x)=sin(x) 함수: x=[1.0~10.0]까지 학습 시켰는데 잘 되었음
    * t(x)=x^3+3 * sin(x)^2-10 함수: x=[-5.5~5.5]까지 학습 시켰는데 잘 되었음
    * 히든 노드수를 늘릴 수록 더 넓은 범위의 x 값을 커버할 수 있음을 일정 범위 내에서 확인
  * [코드](https://github.com/dgtgra…/HumanLearning/blob/master/1001.py)
    * numpy 외에 아무런 라이브러리도 사용하지 않았음
    * Back Propagation 외에 요구되는 배경 지식은 없음
    * python 3.5 환경에서 작성 하였고, numpy만 있으면 실행 됨
  * [실행 동영상](https://www.facebook.com/dgtgrade/videos/1161340170591514/)
    * iteration: 학습 회수
    * train: 학습 데이터
    * test: 학습되지 않은 데이터
    * x: 입력
    * h: 학습된 네트워크의 결과
    * y: 정답 출력
    * cost: squared error
* "손으로 아무렇게나 그린 함수"를 "초간단 ANN으로 근사 시키기"; Universal Approximation Theorem의 내용 직접 실험
  * [Human Learning #1003 : Visual Test of Universal Approximation Theorem]((https://www.youtube.com/watch?v=SahmdQs6X74&list=PLefQdA1SdkhtRUuN_D3PdxaR2XTGQw8Ph&index=9)
  * ANN; 지난 글에서와 마찬가지 초간단 (Deep도 아닌) ANN
    * 히든 레이어 1개, 히든 노드 100개
    * 입력 레이어: 노드 1개
      * x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음
    * 히든 레이어: 1개, 노드: 100개
      * a = sigmoid(w1*x + b1)
    * 출력 레이어: 노드 1개
      * o = w2*a + b2
    * 코스트 함수: Squared Error
  * [코드](https://github.com/dgtgra…/HumanLearning/blob/master/1003.py)
    * Artificial Neural Network의 기초, Gradient Descent의 기초, Back Propagation의 기초
    * python에서 매트릭스 다루는 법: numpy
    * python에서 그래프 그리는 법: matplotlib
    * python에서 이미지 읽는 법: skimage
    * Learning Rate 변경에 따른 학습 능력의 변화, 히든 노드수 변경에 따른 학습 능력의 변화
  * 실행환경
    * python3.5 및 numpy
    * [처음부터 새로 설치 하려면 다음 영상을 참고](https://www.youtube.com/watch?v=pMkwjXFZdH4)
  * 실행방법
    * python 1003.py [이미지파일경로]
    * 이미지 파일 경로에 data/1003_plot1.png 등을 넣어주면 됨
    * [예제 이미지 git 페이지](https://github.com/dgtgrade/HumanLearning/tree/master/data)
* [Universal Approximation Theorem](https://en.wikipedia.org/wi…/Universal_approximation_theorem)
* [Universal Approximation Theorem](http://www.slideshare.net/theeluwin/universal-approximation-theorem-70937339)
  * 수식 t(x)는 아무 곡선이나 임의로 그려 보기 위해서 사용한 도구일 뿐인 것으로 이해해야 함
  * 즉, 수식 t(x)의 식이 중요한 것은 아님. 수식 t(x)의 내용을 문제 출제자도 모르는 상태에서 아무렇게나 (물론 함수로 표현은 가능하게) 곡선들을 그려넣으면 단순한 ANN으로도 언제나 그 곡선이 표현 가능
  * 즉 그 곡선에 거의 딱 맞는 함수 t(x)를 (사람은 모르고, 아마 만들 낼수도 없어도) 기계가 (단순 함수 f1, f2 등의 조합으로) 만들수 낼수 있다는 것을 실험해 본 것
  * 그렇기 때문에 학습한 범위 밖의 t(x)를 추정 할수 있느냐 없느냐는 여기서는 중요하지 않음
  * 왜냐하면 수식 t(x)는 범위 안의 값을 그리기 위해서 사용한 도구였으므로 사실 t(x)가 아니라 (범위 안의 출력만 일치 한다면) 수식 t2(x) 또는 t3(x)였어도 상관이 없음
  * ANN은 머신러닝을 통해서 수식 t(x)가 아니라 수식 t10(x)를 만들어 낸 것
  * 자율운전의 이상적인 정답 함수 세트 T(x)가 존재 한다면 그 함수들은 사람이 수식으로 쓸수는 없으나(!) (운전 데이터를 통해서) 곡선 그림 t(x)를 그려주면 기계가 머신러닝으로 근사함수 h(x)를 만들어 낼수도 있지 않을까? 하는 것을 보여주는 실험
  * 바둑의 이상적인 정답 함수 세트 T(x) 또한 사람은 그 함수들의 수식을 정리할 능력이 없지만 기초 학습을 위한 그림 t(x)는 (기보 데이터를 통해서) 그려줄수는 있고 알파고는 우선 그 사람이 그려준 그림 t(x)에 근사하는 h(x)를 머신러닝을 통해서 만들어 보는 것으로 시작
  * 그 근사가 어느 정도 완료된 이후엔 자기 h1(x) vs 자기 h2(x) 싸움을 통한 학습에 들어가므로 t(x)는 불필요
  * 실험 실행 영상; 다음 3가지 함수에 대하여 실험한 영상 첨부
    * x^2
    * 8*x^2-X^3
    * 10*sin(X)+(X-4)^2-10
    * 초록색 선: 실제 함수
    * 파란색 점: 학습용 정답 데이터
    * 빨간색 점: 학습 결과 만들어진 근사 함수의 출력 데이터
  * [코드](https://github.com/dgtgra…/HumanLearning/blob/master/1002.py)
  * ANN; 지난 글에서와 마찬가지 초간단 (Deep도 아닌) ANN이고, 히든 노드만 100개로 변경함
    * 입력 레이어: 노드 1개
      * x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음
    * 히든 레이어: 1개, 노드: 100개
      * a = sigmoid(w1*x + b1)
    * 출력 레이어: 노드 1개
      * o = w2*a + b2
    * 코스트 함수: Squared Error
  * 실행 환경 준비; python3.5, numpy, matplotlib [설치](https://www.youtube.com/watch?v=pMkwjXFZdH4)
  * 목표 함수 t에 따라서 사람이 조정해야 하는 값
    * Learning Rate: 너무 작게 하면 학습이 느리고, 너무 크게 하면 학습이 안 됨
    * 히든 노드수: 너무 적으면 학습이 불가능할테고, 너무 많으면 학습이 느려짐
  * [머신 러닝이란 무엇일까?](https://www.youtube.com/watch?v=3vcG61VC90c)
* [Neural Network Algorithms - Learn How To Train ANN](https://www.datasciencecentral.com/profiles/blogs/neural-network-algorithms-learn-how-to-train-ann)
* [research.artifacia.com](http://research.artifacia.com/)
* [Source Code Classification Using Deep Learning](http://blog.aylien.com/source-code-classification-using-deep-learning/)
* [Deep Learning Cases: Text and Image Processing](http://www.slideshare.net/grigorysapunov/deep-learning-cases-text-and-image-processing)
* [Introduction to Deep Learning part 1](https://www.youtube.com/watch?v=hoN1mnUBUyI)
* [Introduction to Deep Learning part 2](https://www.youtube.com/watch?v=E71SNUqi2cw)
* [An introduction to Deep Learning by Breandan Considine](https://speakerdeck.com/breandan/an-introduction-to-deep-learning)
* [딥러닝의 인공지능 수단으로서의 성격과 방향](http://www.slideshare.net/neuralix/deep-learning-aswaveextractor)
* [CM 세미나](https://www.youtube.com/playlist?list=PLzWH6Ydh35ggVGbBh48TNs635gv2nxkFI)
* [Deep Learning in real world @Deep Learning Tokyo](http://www.slideshare.net/pfi/deep-learning-in-real-world-deep-learning-tokyo)
* [Bay Area DL School Live Stream!](https://tensorflowkorea.wordpress.com/2016/09/24/bay-area-dl-school-live-stream/)
  * [Bay Area Deep Learning School Day 1 at CEMEX auditorium, Stanford](https://www.youtube.com/watch?v=eyovmAtoUx0)
  * [Bay Area Deep Learning School Day 2 at CEMEX auditorium, Stanford](https://www.youtube.com/watch?v=9dXiAecyJrY)
* [Deep Generative Models](http://www.slideshare.net/MijungKim9/deep-generative-models)
* [Generative Model 101](https://www.facebook.com/SKTBrain/posts/313726382331516) 실제와 유사한 음악이나 이미지를 만들어내는 "Generative Model" 주요 논문 정리
* [Deep Advances in Generative Modeling](https://www.youtube.com/watch?v=KeJINHjyzOU)
* [Latent Constraints: Conditional Generation from Unconditional Generative Models](https://colab.research.google.com/notebook#fileId=1oJKhIXi27R3An0sAd6IzazvrKplTnhj-) coalb code
* [딥러닝 ‘생성모델’과 ‘잠재 벡터’에 관하여 – AI PLUS Tech Blog](https://blog.est.ai/2021/09/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%83%9D%EC%84%B1%EB%AA%A8%EB%8D%B8%EA%B3%BC-%EC%9E%A0%EC%9E%AC-%EB%B2%A1%ED%84%B0%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC/)
* [slow paper Glow: Generative Flow with Invertible 1x1 Convolutions | by Sunwoo Park | Medium](https://medium.com/@sunwoopark/slow-paper-glow-generative-flow-with-invertible-1x1-convolutions-837710116939) generative model
* [Nuts and Bolts of Applying Deep Learning: Tips and Tricks by Andrew Ng](https://bigdatascientistblog.wordpress.com/2016/09/26/nuts-and-bolts-of-applying-deep-learning-tips-and-tricks-by-andrew-ng/)
* [Evaluation of Deep Learning Toolkits](https://github.com/zer0n/deepframeworks/blob/master/README.md)
* [딥러닝 프레임워크 조사와 몇가지 홍보](http://www.popit.kr/%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%A1%B0%EC%82%AC%EC%99%80-%EB%AA%87%EA%B0%80%EC%A7%80-%ED%99%8D%EB%B3%B4/)
* [Deep Learning Frameworks](https://developer.nvidia.com/deep-learning-frameworks) 주요 프레임워크들의 설치를 쉽게 안내하는 엔비디아 페이지
* [딥러닝프레임워크비교](https://www.slideshare.net/JunyiSong1/ss-75552936)
* [Comparison of deep learning software](https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software) 위키피디아의 방대한 딥러닝 프레임워크 비교 표
* [Comparison of deep learning software/Resources](https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software/Resources) 위에서 커버되지 않은 최신 프레임워크들
* [Deep Learning Framework Examples](https://github.com/ilkarman/DeepLearningFrameworks)
* [Comparing Deep Learning Frameworks: A Rosetta Stone Approach](https://www.kdnuggets.com/2018/03/deep-learning-frameworks.html)
* [【PyTorch、Chainer、Keras、TensorFlow】ディープラーニングのフレームワークの利点・欠点【2017年10月更新】](http://s0sem0y.hatenablog.com/entry/2017/05/15/063753)
* [Release Chainer Chemistry: A library for Deep Learning in Biology and Chemistry](https://preferredresearch.jp/2017/12/18/chainer-chemistry-beta-release/)
* [A Look at Popular Machine Learning Frameworks](http://redmonk.com/fryan/2016/06/06/a-look-at-popular-machine-learning-frameworks/) 프레임워크들의 깃허브와 스택오버플로에서의 관심도 차이
* [Battle of the Deep Learning frameworks — Part I: 2017, even more frameworks and interfaces](https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750)
* [데이터지능 E9 딥러닝 프레임워크 및 활용편](https://www.youtube.com/watch?v=eIkM-m1Go1k)
* [Choosing a Deep Learning Framework in 2018: Tensorflow or Pytorch?](http://cv-tricks.com/deep-learning-2/tensorflow-or-pytorch/)
* [Deep Learning Framework Power Scores 2018](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a)
* [The Deep Learning Toolset — An Overview](https://medium.com/luminovo/the-deep-learning-toolset-an-overview-b71756016c06)
* [Top 10 Deep Learning Github Repositories 2018](https://www.techleer.com/articles/547-top-10-deep-learning-github-repositories-2018/)
* [딥러닝 분산처리 기술동향](https://www.nextobe.com/single-post/2017/06/09/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B6%84%EC%82%B0%EC%B2%98%EB%A6%AC-%EA%B8%B0%EC%88%A0%EB%8F%99%ED%96%A5)
* [DEEP LEARNING Your daily dose of Deep learning](http://www.notey.com/blogs/deep-learning) 딥러닝에 대한 기사
* [The Next Wave of Deep Learning Architectures](http://www.nextplatform.com/2016/09/07/next-wave-deep-learning-architectures/) 이후 딥러닝 HW에 대한 전망 (2016년 3Q 기준)
* [Deep Architecture Genealogy](https://github.com/hunkim/deep_architecture_genealogy)
* [Reward Augmented Maximum Likelihood for Neural Structured Prediction](http://static.googleusercontent.com/…/pubs/archive/45580.pdf)
  * reinforcement learning에서의 아이디어를 가져와 maximum likelihood objective를 확장해 training data로부터 추가적인 데이터를 샘플링
  * 결과적으로 알고리즘은 간단한 데이터 전처리에 불과한, Speech recognition과 neural machine translation 모두에 있어서 상당한 성능의 향상
  * reinforcement learning과 supervised learning의 아이디어가 결합. structured prediction에서 전통적인 기계학습의 아이디어와 신경망이 결합해 좋은 결과를 가져옴
* [Deep Learning Reading Group: SqueezeNet](http://www.kdnuggets.com/2016/09/deep-learning-reading-group-squeezenet.html)
* [Uncertainty in Deep Learning (PhD Thesis)](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html)
* [Tensor Physics for Deep Learning](http://www.slideshare.net/uspace/tensor-physics-for-deep-learning)
* [Deep Visualization Toolbox](https://www.youtube.com/watch?v=AgkfIQ4IGaM)
* [DEVIEW 2016](https://deview.kr/2016/schedule) 딥러닝/머신러닝 관련 슬라이드
  * [통역하는 앵무새 파파고 이야기](http://www.slideshare.net/deview/134papago)
  * [딥러닝을 이용한 지역 컨텍스트 검색](http://www.slideshare.net/deview/221-67605830)
  * [딥러닝을 활용한 이미지 검색: 포토요약과 타임라인](http://www.slideshare.net/deview/222-20161024)
  * [딥러닝과 강화 학습으로 나보다 잘하는 쿠키런 AI 구현하기](http://www.slideshare.net/deview/ai-67608549)
    * [리뷰 DEVIEW : 쿠키런 AI 구현하기](https://mingrammer.com/review-deview-cookierun-ai)
    * [발표 자료](http://www.slideshare.net/carpedm20/ai-67616630)
    * [데모 영상](https://www.youtube.com/watch?v=exXD6wJLJ6s)
    * [첫번째 시도 (Deep Q-Network)](https://youtu.be/XsJWbAd6rYk)
    * [두번째 시도 (+ Double Q-learning)](https://youtu.be/rurJICmHfHQ)
    * [세번째 시도 (+ Dueling Network)](https://youtu.be/XQJA1Rob0ng)
    * [Deep Q-learning](https://github.com/devsisters/DQN-tensorflow/)
    * [Dueling Newtork, Double Q-learning](https://github.com/carpedm20/deep-rl-tensorflow/)
    * [쿠키런과 같은 discrete action space가 아닌 continuous action space에서의 강화 학습 방법](https://github.com/carpedm20/NAF-tensorflow/)
  * [Backend 개발자의 Neural Machine Translation 개발기](http://www.slideshare.net/deview/224-backend-neural-machine-translation-67608580)
  * [YARN 기반의 Deep Learning Application Cluster 구축](http://www.slideshare.net/deview/225yarn-deep-learning-application-cluster)
  * [Multimodal Residual Learning for Visual Question-Answering](http://www.slideshare.net/deview/multimodal-residual-learning-for-visual-questionanswering)
  * [딥러닝 예제로 보는 개발자를 위한 통계](http://www.slideshare.net/deview/216-67609104)
  * [Deep Recurrent Neural Network를 이용한 대용량 텍스트 마이닝 기술 및 실제 응용사례](http://www.slideshare.net/deview/226-67609105)
  * [빅데이터 분석에 적합한 LDA & HDP 베이지안 토픽모형에 대한 알고리즘](http://www.slideshare.net/deview/214-67608573)
* [Deep Learning is Revolutionary - 10 reasons why deep learning is living up to the hype](https://medium.com/@olivercameron/deep-learning-is-revolutionary-d0f3667bafa0)
* [Intelligence Platform Stack](https://medium.com/@surmenok/intelligence-platform-stack-8c623f71f990)
* [UFLDL Tutorial](http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial)
* [Batch Normalization 설명 및 구현](https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/)
* [Batch normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://blog.soundcorset.kr/2017/07/batch-normalization-accelerating-deep.html)
* [Understanding Batch Normalization with Examples in Numpy and Tensorflow with Interactive Code](https://towardsdatascience.com/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642)
* [Introduction to Deep Learning Normalization](https://subinium.github.io/introduction-to-normalization)
* [Deep Learning - Achieve faster training of deep neural networks on a robust, scalable infrastructure](https://software.intel.com/en-us/ai/deep-learning)
* [CPU, GPU Put to Deep Learning Framework Test](https://www.nextplatform.com/2016/09/01/cpu-gpu-put-deep-learning-framework-test/)
* [딥러닝의 역사와 기본 개념](http://bcho.tistory.com/1147)
* [김현호: 오늘 당장 딥러닝 실험하기 - PyCon Korea 2015](https://www.youtube.com/watch?v=j-CojQwIt70)
* [Nuts and Bolts of Applying Deep Learning](https://kevinzakka.github.io/2016/09/26/applying-deep-learning/)
* [한눈에 보는 실리콘밸리 AI 트렌드(2)](https://brunch.co.kr/@synabreu/13)
* [The major advancements in Deep Learning in 2016](https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/)
* [Deep Learning Into Advance - 1. Image, ConvNet](http://www.slideshare.net/hellovista/deep-learning-into-advance-1-image-convnet)
* [Deep Learning SIMPLIFIED](https://www.youtube.com/playlist?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu)
* [Intel® Distribution for Python for high performance to supercharge all your Python applications on modern Intel platforms](https://software.intel.com/en-us/intel-distribution-for-python)
* [Deep Learning Demystified](https://www.youtube.com/watch?v=Q9Z20HCPnww&spfreload=10)
* [Recognizing Sounds (A Deep Learning Case Study)](https://medium.com/@awjuliani/recognizing-sounds-a-deep-learning-case-study-1bc37444d44d)
* [Has Deep Learning Made Traditional Machine Learning Irrelevant?](http://www.datasciencecentral.com/profiles/blogs/has-deep-learning-made-traditional-machine-learning-irrelevant)
* [Feedback Networks](https://youtu.be/MY5Uhv38Ttg)
  * [paper](https://arxiv.org/abs/1612.09508)
  * 영상분야 Deep Learning에서 일반적인 학습 모델은 연속적인 ConvNets layers를 이용하여 Feature를 추출한 다음 classification layer가 이어지는 모델을 기반
  * 본 논문에서는 이러한 일반적인 Feedfoward Multi Layers 대신 동일한 목표를 달성 할 수있는 대안을 제시
  * Recurrent Neural Networks의 개념을 도입하여 이전 출력에서 받은 피드백을 기반으로 반복적으로 표현이 형성되는 Feedback 기반 접근 방식을 제시
  * Feedback 기반 접근 방식은 Feedfoward보다 몇 가지 장점
    * 연산과정 중 초기에 예측 가능
    * 출력은 자연스럽게 레이블 공간의 계층 구조 (예 : 분류법)를 따르며 커리큘럼의 새로운 기초를 제공
    * Feedback 네트워크는 이러한 장점외에 Feedfoward 대응 네트워크와 비교하여 상당히 다른 표현의 개발이 가능(Feedback architecture (예 : skip connections in time) 및 디자인 선택 (예 : 피드백 길이))
* [A Theory Explains Deep Learning](http://www.deductiontheory.com/2016/12/study-deep-learning-from-scratch.html)
* [20170121 한국인공지능협회 - 제7차 오픈세미나 - 딥러닝](https://www.youtube.com/watch?v=FtHwOo5aICI)
  * [딥러닝 살짝 보기](https://docs.google.com/presentation/d/1K7imkoZy0drztv5_ylP8ZajuM_lUO9wk_nlhp9Z1-vQ/)
* [DeepMind just published a mind blowing paper: PathNet](https://medium.com/@thoszymkowiak/deepmind-just-published-a-mind-blowing-paper-pathnet-f72b1ed38d46)
  * [Tensorflow Implementation of PathNet: Evolution Channels Gradient Descent in Super Neural Networks https://arxiv.org/pdf/1701.08734.pdf](https://github.com/jaesik817/pathnet)
  * [PyTorch implementation of PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://github.com/kimhc6028/pathnet-pytorch)
* [Bringing HPC Techniques to Deep Learning](http://research.baidu.com/bringing-hpc-techniques-deep-learning/)
  * 여러대 GPU머신을 이용하여 parallel하게 학습할 때 네트웍 오버헤드 때문에 오히려 속도가 감소
  * 바이두에서 ring allreduce라는 알고리즘으로 해결
* [実世界の人工知能@DeNA TechCon 2017](https://www.slideshare.net/pfi/dena-techcon-2017)
* [Deep Forest: Towards An Alternative to Deep Neural Networks](https://arxiv.org/abs/1702.08835)
* [**Asynchronous Advantage Actor-Critic (A3C)**](https://jay.tech.blog/2017/01/19/asynchronous-advantage-actor-critic-a3c/)
* [스스로 코딩을 하는 인공지능의 현 주소-Deepcoder](http://etinow.me/187)
* [Improving Hardware Efficiency for DNN Applications](https://www.slideshare.net/ChesterChen/improving-hardware-efficiency-for-dnn-applications)
* [DeepLearning 연구 2016 년의 정리](https://translate.google.com/translate?sl=ja&tl=ko&js=y&prev=_t&hl=ko&ie=UTF-8&u=http%3A%2F%2Fqiita.com%2Feve_yk%2Fitems%2Ff4b274da7042cba1ba76&edit-text) 일본어 번역
* [Squeezing Deep Learning Into Mobile Phones](https://www.slideshare.net/anirudhkoul/squeezing-deep-learning-into-mobile-phones)
* [짚으면 찾아주는 사전 - Just Point It와 모바일 머신러닝](https://www.youtube.com/watch?v=Jq5L_5bRBR0)
  * [Just point it](https://www.slideshare.net/NaverEngineering/just-point-it)
* [딥러닝 분산처리 기술동향](https://ettrends.etri.re.kr/ettrends/pubreader.do?volume=31&issue=3&page=131&paperno=0905002137)
* [Understanding deep learning requires rethinking generalization (2017) 1/2](https://www.slideshare.net/JungHoonSeo2/understanding-deep-learning-requires-rethinking-generalization-2017-12)
* [Understanding deep learning requires rethinking generalization (2017) 2 2(2)](https://www.slideshare.net/JungHoonSeo2/understanding-deep-learning-requires-rethinking-generalization-2017-2-22)
* [Rethinking Generalization in Deep Learning](https://medium.com/intuitionmachine/rethinking-generalization-in-deep-learning-ec66ed684ace)
* [Deep Learning From A to Z (Raphael Gontijo Lopes)](https://www.youtube.com/watch?v=DYlHnxfrrZY)
* [Linear algebra cheat sheet for deep learning](https://medium.com/towards-data-science/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c)
* [**Linear Algebra for Deep Learning**](https://towardsdatascience.com/linear-algebra-for-deep-learning-506c19c0d6fa)
* [The Black Magic of Deep Learning - Tips and Tricks for the practitioner](https://nmarkou.blogspot.com/2017/02/the-black-magic-of-deep-learning-tips.html)
* [Game Theory reveals the Future of Deep Learning](https://medium.com/intuitionmachine/game-theory-maps-the-future-of-deep-learning-21e193b0e33a)
* [Game Theory Study (1) Introduction and Overview](http://sanghyukchun.github.io/101/)
* [todaysdeeplearning.com](http://www.todaysdeeplearning.com/)
* [Try Deep Learning in Python now with a fully pre-configured VM](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b) VMWare
* [Why Momentum Really Works](http://distill.pub/2017/momentum/)
* [dlwiki.finfra.com/start](http://dlwiki.finfra.com/start)
* [Deconvolution and Checkerboard Artifacts](http://distill.pub/2016/deconv-checkerboard/)
* [Compressing and regularizing deep neural networks 번역](https://fuzer.github.io/Compressing-and-regularizing-deep-neural-networks/)
* [Deep Learning for Program Synthesis](https://www.microsoft.com/en-us/research/blog/deep-learning-program-synthesis/)
* [Welcome to The Advanced Matrix Factorization Jungle](https://sites.google.com/site/igorcarron2/matrixfactorizations)
* [인공지능은 의료를 어떻게 혁신할 것인가 (1) 제2의 기계시대와 의료 인공지능](http://www.yoonsupchoi.com/2017/05/07/ai-medicine-1/)
* [Deep learning techniques](https://www.researchgate.net/publication/316829498_Deep_learning_techniques_-_overview)
* [Deep Learning Methods for Image Classification](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015/NN%20Lecture/dcnn-intro-WinstonHsu-15s.pdf)
* [Deep Learning Image Classification Guidebook 1 LeNet, AlexNet, ZFNet, VGG, GoogLeNet, ResNet](https://hoya012.github.io/blog/deeplearning-classification-guidebook-1/)
* [Kullback-Leibler Divergence Explained](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)
* [The Strange Loop in Deep Learning](https://medium.com/intuitionmachine/the-strange-loop-in-deep-learning-38aa7caf6d7d)
* [Training a deep learning model to steer a car in 99 lines of code](https://hackernoon.com/training-a-deep-learning-model-to-steer-a-car-in-99-lines-of-code-ba94e0456e6a)
* [Lane Detection with Deep Learning (Part 1)](https://medium.com/towards-data-science/lane-detection-with-deep-learning-part-1-9e096f3320b7)
* 카카오AI리포트
  * [ICML,NIPS 발표논문 분석](https://brunch.co.kr/@kakao-it/63)
  * [딥러닝연구의 현재와미래 part 1](https://brunch.co.kr/@kakao-it/65)
  * [AI 의료영상 기술 활용 사례](https://brunch.co.kr/@kakao-it/81)
  * [더욱 똑똑해진 AI 광고 알고리듬](https://brunch.co.kr/@kakao-it/84)
* [Deep Learning Project Workflow](https://github.com/thomasj02/DeepLearningProjectWorkflow)
* [Affine Transformation](http://blog.naver.com/atelierjpro/221014255070)
* [애파인 변환 Affine Transformation](https://www.youtube.com/watch?v=DSmXIYkp024)
* [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)
* [**Applying deep learning to real-world problems**](https://medium.com/merantix/applying-deep-learning-to-real-world-problems-ba2d86ac5837)
* [Practical UseCases of Deep Learning Techniques](http://www.cognitivetoday.com/2016/11/practical-deeplearning-usecases-2.html)
* [Practical UseCases of Deep Learning Techniques… Part II](http://www.cognitivetoday.com/2017/02/practical-deeplearning-usecases.html)
* [Policy Gradient](https://nbviewer.jupyter.org/format/slides/gist/kkweon/e8522c4b04e1e7c6665c53ac12ac7f1d#)
* [0. Policy Gradient의 세계로](https://reinforcement-learning-kr.github.io/2018/06/29/0_pg-travel-guide/)
  * [Policy Gradient (PG) Algorithms](https://github.com/reinforcement-learning-kr/pg_travel)
* [PG Travel Guide](https://reinforcement-learning-kr.github.io/2018/06/29/0_pg-travel-guide/)
  * [Policy Gradient (PG) Algorithms](https://github.com/reinforcement-learning-kr/pg_travel)
* [Policy Gradients in a Nutshell](https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d)
* [강화학습 DDPG 리뷰 Deep Deterministic Policy Gradient](https://www.slideshare.net/ssuser41d7e01/ddpg-deep-deterministic-policy-gradient-139832691)
* [Policy Gradient is all you need! A step-by-step tutorial for well-known PG methods](https://github.com/MrSyee/pg-is-all-you-need)
* [가깝고도 먼 Trpo](https://www.slideshare.net/WoongwonLee/trpo-87165690)
* [Policy Gradient(정책 경사) 시리즈 7 - TRPO(1부) : 네이버블로그](https://blog.naver.com/jk96491/222080607415)
* [Policy Gradient(정책 경사) 시리즈 7 - TRPO(2부) : 네이버블로그](https://blog.naver.com/jk96491/222083524673)
* [You can probably use deep learning even if your data isn't that big](http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html)
* [**번역 2017년 iOS를 위한 나의 개발 툴 셋**](http://blog.canapio.com/107)
* [The $1700 great Deep Learning box: Assembly, setup and benchmarks](https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415)
* [Kernel Mixture Networks](https://janvdvegt.github.io/2017/06/07/Kernel-Mixture-Networks.html)
* [Taxonomy of Methods for Deep Meta Learning](http://www.kdnuggets.com/2017/06/taxonomy-methods-deep-meta-learning.html)
* [From zero to research — An introduction to Meta-learning](https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a)
* [Awesome Meta Learning](https://github.com/sudharsan13296/Awesome-Meta-Learning)
* [Baysian Model-Agnostic Meta-Learning](https://github.com/jaesik817/bmaml)
* [Baysian Model-Agnostic Meta-Learning](https://github.com/jaesik817/bmaml_rl)
* [신경 번역 seq2seq 모델 튜토리얼](https://www.facebook.com/nextobe1/posts/339880869781248)
* [seq2seq icml tutorial](https://sites.google.com/view/seq2seq-icml17/)
* [Sequence to sequence tutorial](https://towardsdatascience.com/sequence-to-sequence-tutorial-4fde3ee798d8)
* [Google net](https://www.slideshare.net/BrianKim244/google-net)
* ["Advances in Deep Neural Networks," at ACM Turing 50 Celebration](https://www.youtube.com/watch?v=mFYM9j8bGtg)
* [BUILDING A SOUND CLASSIFIER FROM SCRATCH USING NEURAL NETWORKS](https://www.skcript.com/svr/building-audio-classifier-nueral-network/)
* [WHEN NOT TO USE DEEP LEARNING](http://hyperparameter.space/blog/when-not-to-use-deep-learning/)
* [MLJejuCamp - Call for application for Machine Learning Camp Jeju 2017](https://github.com/TensorFlowKR/MLJejuCamp)
  * [Special Seminar](https://github.com/TensorFlowKR/MLJejuCamp/blob/master/Special_Seminar.md)
* [김태희의 닮은꼴도 머신러닝으로 구분할 수 있을까?](https://brunch.co.kr/@kmbmjn95/20)
* [The limitations of deep learning](https://blog.keras.io/the-limitations-of-deep-learning.html)
* [번외 Why does deep and cheap learning work so well?](http://suma_maple.blog.me/221064089784)
* [**MNIST 시각화 - 차원 감소**](https://brunch.co.kr/@chris-song/37)
* [VisualizeMnist - This project is real-time visualization of a network recognizing digits from user's input](https://github.com/okdalto/VisualizeMNIST)
* [#4.0. 정보량을 나타내는 엔트로피 (Entropy)](https://www.youtube.com/watch?v=zJmbkp9TCXY&list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq&index=19)
* [Designing a Deep Learning Project](https://medium.com/@erogol/designing-a-deep-learning-project-9b3698aef127)
* [github.com/parkskwan](https://github.com/parkskwan)
* [Create self-driving trucks inside Euro Truck Simulator 2](https://medium.com/mars-auto/create-self-driving-trucks-inside-euro-truck-simulator-2-c64424d528ed)
  * [europilot - A toolkit for controlling Euro Truck Simulator 2 with python to develop self-driving algorithms](https://github.com/marshq/europilot)
* [딥러닝, 머신러닝의 차이점은?](https://brunch.co.kr/@itschloe1/8)
* [RNNoise: 소음 감소를 위한 딥러닝 모델](http://hacks.mozilla.or.kr/2017/10/rnnoise-using-deep-learning-for-noise-suppression/)
* [Why Probability Theory Should be Thrown Under the Bus](https://medium.com/intuitionmachine/why-probability-theory-should-be-thrown-under-the-bus-36e5d69a34c9)
* [An Overview of ResNet and its Variants](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)
* [How to Train Your ResNet 8: Bag of Tricks](https://myrtle.ai/how-to-train-your-resnet-8-bag-of-tricks/)
  * [How to Train Your ResNet - 8: Bag of Tricks](https://colab.research.google.com/github/davidcpage/cifar10-fast/blob/master/bag_of_tricks.ipynb#scrollTo=6IGml3SMd6ID) ipynb
* [#Python | Non-linear Connectivity Topology | #ResNet #DeepLearning #Tensorflow #NeuralNetworks - YouTube](https://www.youtube.com/watch?v=CjFL6Ada5Xk) cifar10
* [AI For Filmmaking Recognising Shot Types with ResNets](https://rsomani95.github.io/ai-film-1.html)
* [ResNet: The Most Popular Network in the Computer-Vision Era](https://towardsdatascience.com/resnet-the-most-popular-network-in-computer-vision-era-973df3e92809)
* [ResNet: Deep Residual Learning for Image Recognition (꼼꼼한 딥러닝 논문 리뷰와 코드 실습) - YouTube](https://www.youtube.com/watch?v=671BsKl8d0E)
* [이미지 처리 깊게 더 깊게 ResNet - cobslab](https://cobslab.com/%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%B2%98%EB%A6%AC-%EA%B9%8A%EA%B2%8C-%EB%8D%94-%EA%B9%8A%EA%B2%8C-resnet/)
* [FCN_Implementation](https://github.com/engineerJPark/FCN_Implementation) ResNet
* [딥러닝 ResNet의 개념 - 로스카츠의 AI 머신러닝](https://losskatsu.github.io/machine-learning/resnet/)
* [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35)
* [Estimating an Optimal Learning Rate For a Deep Neural Network](https://medium.com/@surmenok/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)
* [Improving the way we work with learning rate](https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b)
* [딥러닝을 제대로 이해하기 위해서 필요한 배경지식맵](http://bahnsville.tistory.com/1155)
* [Deep Learning Specialization by Andrew Ng — 21 Lessons Learned](https://towardsdatascience.com/deep-learning-specialization-by-andrew-ng-21-lessons-learned-15ffaaef627c)
* [Grad CAM을 이용한 딥러닝 모형 해석](http://freesearch.pe.kr/archives/4685)
* [딥러닝이 덧셈을 하는 방법, Attention Mechanism으로 살펴보기](http://freesearch.pe.kr/archives/4724)
* [gradient를 활용한 DNN 해석 방안](https://seujung.github.io/deep_learning/2017/12/19/Itpr_model.html)
* [onnx.ai](https://onnx.ai)
  * [github.com/onnx/onnx](https://github.com/onnx/onnx)
  * [Getting Started](http://onnx.ai/getting-started)
  * [Operator Schemas](https://github.com/onnx/onnx/blob/master/docs/Operators.md)
  * [Viewer for ONNX neural network models https://www.lutzroeder.com/ai](https://github.com/lutzroeder/Netron)
  * [Convert ONNX models into Apple CoreML format](https://github.com/onnx/onnx-coreml)
  * [Tensorflow Backend for ONNX](https://github.com/onnx/onnx-tensorflow)
  * [ONNX.js is a Javascript library for running ONNX models on browsers and on Node.js](https://github.com/Microsoft/onnxjs)
  * [How to deploy ONNX models in production](https://towardsdatascience.com/how-to-deploy-onnx-models-in-production-60bd6abfd3ae)
* [Comparison of Deepnet & Neuralnet](https://www.datasciencecentral.com/profiles/blogs/comparison-of-deepnet-neuralnet)
* [Modern Theory of Deep Learning: Why Does It Work so Well](https://medium.com/mlreview/modern-theory-of-deep-learning-why-does-it-works-so-well-9ee1f7fb2808)
* [당근마켓에서 딥러닝 활용하기](https://medium.com/n42-corp/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93%EC%97%90%EC%84%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-3b48844eba62)
* [Beyond Deep Learning – 3rd Generation Neural Nets](https://www.datasciencecentral.com/profiles/blogs/beyond-deep-learning-3rd-generation-neural-nets)
* [AI and Deep Learning in 2017 – A Year in Review](http://www.wildml.com/2017/12/ai-and-deep-learning-in-2017-a-year-in-review/)
  * [2017년 인공지능과 딥러닝 리뷰 (번역 by softgear)](http://softgearko.blogspot.com/2018/01/2017-by-softgear.html)
* [The Google Brain Team — Looking Back on 2017 (Part 1 of 2)](https://research.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html)
* [Interpreting Deep Neural Networks](http://www.shallowmind.co/jekyll/pixyll/2017/12/30/tree-regularization/)
* [Deep Learning from first principles in Python, R and Octave – Part 1](https://gigadom.wordpress.com/2018/01/04/deep-learning-from-basic-principles-in-python-r-and-octave-part-1/)
* [Deep Learning from first principles in Python, R and Octave – Part 2](https://gigadom.wordpress.com/2018/01/11/deep-learning-from-first-principles-in-python-r-and-octave-part-2/)
* [NBT 교육 1탄. Ad-Tech](https://www.youtube.com/playlist?list=PLdWpPj-RibJsrc5NzIsO9TKs3ac4HBg8Z)
* [금융의 역사를 통해 본 딥러닝의 함정](https://www.youtube.com/watch?v=mpZSb9DzAR8)
  * [금융의 역사를 통해 본 딥러닝의 함정](https://www.slideshare.net/NaverEngineering/ss-86209440)
* [Introduction of Neural Network Console](https://www.youtube.com/watch?v=-lXjnaUSEtM)
  * [Sony’s Neural Network Console Software is Available at No Cost: A Deep Learning Tool for Training, Evaluating & Designing Neural Networks for Artificial Intelligence Creation](https://www.photoxels.com/sony-neural-network-console-software-is-available-at-no-cost-a-deep-learning-tool-for-training-evaluating-designing-neural-networks-for-artificial-intelligence-creation/)
* [Geometric Deep Learning | Michael Bronstein](https://www.radcliffe.harvard.edu/video/geometric-deep-learning-michael-bronstein)
* [8 Deep Learning Best Practices I Learned About in 2017](https://hackernoon.com/8-deep-learning-best-practices-i-learned-about-in-2017-700f32409512)
* [deepfakes_faceswap - Faceswap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos](https://github.com/deepfakes/faceswap)
  * [practice](https://gist.github.com/hyunjun/fe2293dc299e0d0c4a1a761f13a173cd)
  * [Exploring DeepFakes](https://www.kdnuggets.com/2018/03/exploring-deepfakes.html)
  * [FaceIt](https://github.com/goberoi/faceit)
  * [deepfakes.club](https://www.deepfakes.club/)
  * [It Means Hope | Deepfakes Replacement](https://www.youtube.com/watch?v=ChVgT980Jck)
  * [Awesome - Deepfake / Porn Detection using Deep Learning](https://github.com/subinium/awesome-deepfake-porn-detection)
  * [Live Deep Fakes — you can now change your face to someone else’s in real time video applications](https://medium.com/huia/live-deep-fakes-you-can-now-change-your-face-to-someone-elses-in-real-time-video-applications-a4727e06612f)
  * [FaceForensics++: Learning to Detect Manipulated Facial Images](https://github.com/ondyari/FaceForensics/)
  * [Contributing Data to Deepfake Detection Research](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html)
  * ['아이유인데 아이유가 아닙니다' - YouTube](https://www.youtube.com/watch?v=p2POWAdB2AE)
* [first-order-model: This repository contains the source code for the paper First Order Motion Model for Image Animation](https://github.com/AliaksandrSiarohin/first-order-model)
  * [first-order-model-demo.ipynb - Colaboratory](https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb)
* [Deep Learning summary for 2017: Text and Speech Applications](https://towardsdatascience.com/deep-learning-summary-for-2017-text-and-speech-applications-9ea02bb3835f)
* [The Deep Learning Roadmap](https://medium.com/intuitionmachine/the-deep-learning-roadmap-f0b4cac7009a)
* [Continuous Unsupervised Training of Deep Architectures](https://www.slideshare.net/VincenzoLomonaco/continuous-unsupervised-training-of-deep-architectures)
  * [core50 - A new Dataset and Benchmark for Continuous Object Recognition](https://vlomonaco.github.io/core50/)
* Only Numpy
  * [Implementing Highway Network, OOP approach with Mini Batch with Interactive Code](https://towardsdatascience.com/only-numpy-implementing-highway-network-oop-approach-with-mini-batch-with-interactive-code-b5c2de2df842)
  * [Implementing Different combination of L1 /L2 norm/regularization to Deep Neural Network (regression) with interactive code](https://towardsdatascience.com/only-numpy-implementing-different-combination-of-l1-norm-l2-norm-l1-regularization-and-14b01a9773b)
* [New Deep Learning Techniques](http://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule)
* [Automated front-end development using deep learning](https://blog.insightdatascience.com/automated-front-end-development-using-deep-learning-3169dd086e82)
* [ANN Visualizer: A python library for visualizing Artificial Neural Networks (ANN)](https://www.techleer.com/articles/510-ann-visualizer-a-python-library-for-visualizing-artificial-neural-networks-ann/)
* [Deep Learning’s Uncertainty Principle](https://medium.com/intuitionmachine/deep-learnings-uncertainty-principle-13f3ffdd15ce)
* [The Deep Learning(.ai) Dictionary](https://towardsdatascience.com/the-deep-learning-ai-dictionary-ade421df39e4)
* [Weekly Selection — Apr 6, 2018](https://towardsdatascience.com/weekly-selection-apr-6-2018-586b54f74300)
* [Weekly Selection — Mar 23, 2018](https://towardsdatascience.com/weekly-selection-mar-23-2018-fdb1c918691e)
* [DeepLearn - This repository contains implementation of following research papers on NLP, CV, ML, and deep learning](https://github.com/GauravBh1010tt/DeepLearn/blob/master/README.md)
  * [DeepLearn - to provide reproducible code for some of the interesting AI, ML research papers](http://deeplearn-ai.com/deeplearn/?i=2)
* [Is Deep Learning Innovation Just Due to Brute Force?](https://medium.com/intuitionmachine/the-brute-force-method-of-deep-learning-innovation-58b497323ae5)
* [In defense of skepticism about deep learning](https://medium.com/@GaryMarcus/in-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1)
* [Deep Learning vs Classical Machine Learning](https://towardsdatascience.com/deep-learning-vs-classical-machine-learning-9a42c6d48aa)
* [BeatGAN - Generating Drum Loops via GANs](https://github.com/NarainKrishnamurthy/BeatGAN2.0)
* [Writing a deep learning repo #1](https://medium.com/@prannaykhosla/writing-a-deep-learning-repo-1-744c268c7189)
* [Writing a deep learning repo #2](https://medium.com/@prannaykhosla/writing-a-deep-learning-repo-2-c4589fb169b1)
* [Writing a deep learning repo #3](https://medium.com/@prannaykhosla/writing-a-deep-learning-repo-3-c4c950b20b92)
* [Deep Learning #4 : Energy Based Adversarial Training](https://medium.com/@prannaykhosla/deep-learning-4-energy-based-adversarial-training-93c8499f0253)
* [만능 근사 원리 UAT Universal Approximation Theorem](https://blog.naver.com/atelierjpro/221274573892)
* [인공지능의 두뇌, 뉴럴 네트워크의 만능 근사 정리란 무엇일까?](https://www.youtube.com/watch?v=7AloljyhrBc)
* [An Introduction to Deep Learning for Tabular Data](https://www.kdnuggets.com/2018/05/introduction-deep-learning-tabular-data.html)
  * 테이블 형식 데이터는 업계에서 가장 일반적으로 사용되는 데이터 형식이지만 테이블 형식 데이터에 대한 딥러닝은 컴퓨터 비전과 자연어 처리에 대한 딥러닝보다 훨씬 덜 관심을 받음
  * 신경망을 테이블 형식의 데이터에 적용하는 몇가지 주요 개념, 특히 범주형 변수를 포함한 아이디어를 기술
* [Deep Learning 역사](http://mobicon.tistory.com/523)
* [An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution](https://www.youtube.com/watch?v=8yFQc6elePA)
* [Deep Learning made easy with Deep Learning Studio — Complete Guide](https://towardsdatascience.com/deep-learning-made-easy-with-deep-learning-studio-complete-guide-a5c5ae58a771)
* [Day1, 2-1. 책 읽어주는 딥러닝](https://www.youtube.com/watch?v=klnfWhPGPRs)
* [Deep Learning for AI (1)](https://www.slideshare.net/ssuser421e61/deep-learning-for-ai-1)
* [Deep Learning for AI (2)](https://www.slideshare.net/ssuser421e61/deep-learning-for-ai-2)
* [Deep Learning for AI (3)](https://www.slideshare.net/ssuser421e61/deep-learning-for-ai-3)
* [Montréal.AI Academy : AI 101](https://montrealartificialintelligence.com/academy/#Getting-Started-Readings-Source-Code-and-Science)
* [지도/비지도학습과 강화학습 풀이법](https://tykimos.github.io/2018/09/22/LearningMethod/)
* [Graph Attention Networks](http://petar-v.com/GAT/)
* [Graph Attention Networks - Graph ML review](https://harryjo97.github.io/paper%20review/Graph-Attention-Networks/)
* [Deep Learning To Mobile](https://github.com/younatics/DeepLearningToMobile)
* [Deep learning made easier with transfer learning](https://blog.fastforwardlabs.com/2018/09/17/deep-learning-is-easy-an-introduction-to-transfer-learning.html)
* [A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)
* [191027 딥러닝 전이학습 발표자료](https://drive.google.com/drive/folders/1JPPMFYlGMl1BbjjMnG2WqakWwBkiHgzP)
* [Transfer Learning in SUALAB: 데이터셋 제작부터 Adaptive Transfer Learning까지](http://research.sualab.com/introduction/review/2019/12/19/transfer-learning-in-sualab.html)
* [AI는 광수와 광수 닮은 연습생을 구분할 수 있을까?](https://brunch.co.kr/@businessinsight/64)
* [Deep Learning 위해서는 어떤 GPU를 사야 할까요?](http://tmmse.xyz/2016/05/02/gpureccom/)
* [알기 쉬운 GPU 그리고 머신러닝](https://steemit.com/gpu/@sigmoid/gpu)
* [Learning Acrobatics by Watching YouTube](https://bair.berkeley.edu/blog/2018/10/09/sfv/)
  * [Xue Bin (Jason) Peng](https://xbpeng.github.io/)
* [Glow: Better Reversible Generative Models](https://blog.openai.com/glow/)
  * [An implementation of the GLOW paper and simple normalizing flows lib](https://github.com/kmkolasinski/deep-learning-notes/tree/master/seminars/2018-10-Normalizing-Flows-NICE-RealNVP-GLOW)
* [Optimal real-time landing using DNN](https://www.slideshare.net/ssuser06e0c5/optimal-realtime-landing-using-dnn)
* [Speed up your deep learning language model up to 1000% with the adaptive softmax, Part 1](https://towardsdatascience.com/speed-up-your-deep-learning-language-model-up-to-1000-with-the-adaptive-softmax-part-1-e7cc1f89fcc9)
* [딥러닝 기본 소프트맥스와 로짓에 대한 이해](https://www.youtube.com/watch?v=K7HTd_Zgr3w)
* [PyParis 2018 - Using Deep Learning to rank and tag millions of hotel images](https://www.youtube.com/watch?v=WEWl4cD-y00)
* [Don't be a Turtle Project](https://github.com/motlabs/dont-be-turtle)
  * [181123 poseest101 devfest_pangyo_jwkang](https://www.slideshare.net/JaewookKang1/181123-poseest101-devfestpangyojwkang)
* [Must-read Blogs for AI and Deep Learning Enthusiasts](https://blog.paralleldots.com/data-science/must-read-blogs-ai-deep-learning-enthusiasts/)
* [Deep Learning for Classical Japanese Literature](https://towardsdatascience.com/deep-learning-for-classical-japanese-literature-48ae04c17dfd)
* [2018 In Review: 10 Open-Sourced AI Datasets](https://medium.com/syncedreview/2018-in-review-10-open-sourced-ai-datasets-696b3b49801f)
* [The 10 Deep Learning Methods AI Practitioners Need to Apply](https://medium.com/cracking-the-data-science-interview/the-10-deep-learning-methods-ai-practitioners-need-to-apply-885259f402c1)
* [Setting up a GPU Enabled Kubernetes for Deep Learning](https://gist.github.com/stevenc81/1cad3a0ebca9303923d1cd4c3641f8bc)
* [It is never too much: training deep learning models with more than one modality - Adam Słucki](https://www.youtube.com/watch?v=-UaTdVGfHxQ)
* [A Beginners Guide to Federated Learning](https://hackernoon.com/a-beginners-guide-to-federated-learning-b29e29ba65cf)
* [federated learning - 보안 걱정 없는 모바일 딥러닝 학습법 (연합 학습)](https://www.youtube.com/watch?v=ei_e7nHS6SE)
* [Survey report of Federated Learning - TooTouch](https://tootouch.github.io/research/federated_learning/)
* [Flower: A Friendly Federated Learning Framework](https://flower.dev/)
  * [Flower - 연합 학습(Federated Learning) 프레임워크 | GeekNews](https://news.hada.io/topic?id=6276)
* [아마존, 구글 FLoC 차단 | GeekNews](https://news.hada.io/topic?id=4449)
* [LxMLS 2017](https://www.youtube.com/playlist?list=PLToLj8M4ao-fuRfnzEJCCnvuW2_FeJ73N)
* [Recent Advances for a Better Understanding of Deep Learning − Part I](https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914)
* [Why Randomness should be Embraced and Not Feared](https://medium.com/intuitionmachine/why-randomness-should-be-leveraged-and-not-filtered-be31a94e85ef)
* [AutoML 1.데이터 어그먼테이션 연구 동향을 소개합니다](https://www.kakaobrain.com/blog/64)
* [GPU 성능 파워업! LMS 기술 테스트 결과는?](https://blog.naver.com/ibm_korea/221571488250)
* [How to Train a Very Large and Deep Model on One GPU? | by Synced | SyncedReview | Medium](https://medium.com/syncedreview/how-to-train-a-very-large-and-deep-model-on-one-gpu-7b7edfe2d072)
* [Get started with GPU Compute on the web](https://web.dev/gpu-compute/)
* [Releasing first online 3D Point Cloud labeling tool in Supervisely](https://medium.com/deep-systems/releasing-first-online-3d-point-cloud-labeling-tool-in-supervisely-4faca42b5d6e)
* [작고 빠른 딥러닝 그리고 Edge Computing](https://www.slideshare.net/slideshow/embed_code/key/9gaEyFbAxBOw9Q)
* [Is Rectified Adam actually better than Adam?](https://www.pyimagesearch.com/2019/10/07/is-rectified-adam-actually-better-than-adam/)
* [Deep-Learning-in-Production - In this repository, I will share some useful notes and references about deploying deep learning-based models in production](https://github.com/ahkarami/Deep-Learning-in-Production)
* [XOR solvable activation function helps DNNs](https://github.com/sunggukcha/xor)
* [눈으로 배우는 인공지능, 텐서플로우2.0으로 읽다! 세번째 이야기! #tensorflow2.0 #에이림 #인공지능](https://www.youtube.com/watch?v=UJumtitldn8) AND, OR, XOR, colab code
* [Semantic Segmentation을 활용한 차량 파손 탐지 딥러닝 모델 개발기](https://tech.socarcorp.kr/data/2020/02/13/car-damage-segmentation-model.html)
* [**딥러닝 모델 Serving 간단 구축기 (feat. AWS SQS + Python Application + Kubernetes + Git & Rancher)**](https://tech.socarcorp.kr/data/2020/03/10/ml-model-serving.html)
* [딥러닝 모델 서비스 A-Z 1편 - 연산 최적화 및 모델 경량화](https://blog.pingpong.us/ml-model-optimize/)
* [딥러닝 모델 서비스 A-Z 2편 - Knowledge Distillation – 핑퐁팀 블로그](https://blog.pingpong.us/ml-model-optimize-2/)
* [**딥러닝 웹서비스 개발 도전기 아이즈원과 함께하는 풀스택 개발**](https://medium.com/@inerplat/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-%EB%8F%84%EC%A0%84%EA%B8%B0-e9ca38d53c1b)
* [갈아먹는 딥러닝 기초 1 Activation Function(활성화 함수) 종류](https://yeomko.tistory.com/39)
* [갈아먹는 딥러닝 기초 2 weight initialization](https://yeomko.tistory.com/40)
* [Supervised learning을 시작으로 누구나 쉽게 인공지능(AI)을 이해할 수 있다는 사실 알고 계시나요?](https://blog.naver.com/wacanycorp/221884110863)
* [Guest Lecture - Jai Ranganathan - Full Stack Deep Learning - August 2018 - YouTube](https://www.youtube.com/watch?v=8PjTWFfjkeY)
* [정말 딥러닝은 사람처럼 세상을 인식하고 있을까?](https://www.slideshare.net/NaverEngineering/ss-86897066)
* [Mixed-Precision Training of Deep Neural Networks](https://hoya012.github.io/blog/Mixed-Precision-Training/)
* [딥러닝이 제일 열등한 모델인데 몰랐어? - 마무리 – 파비 블로그](https://blog.pabii.co.kr/deep-learning-most-inferior-model-finale/)
* [Oguzhan Gencoglu - Best Practices for Data Augmentation | PyData Helsinki - YouTube](https://www.youtube.com/watch?v=2bS11DGO5RQ)
* [딥러닝 배치 사이즈(batch size) vs 에포크(epoch) vs 반복(iteration)의 차이 - 로스카츠의 AI 머신러닝](https://losskatsu.github.io/machine-learning/epoch-batch/)
* [원티드는 어떻게 AI로 채용 결과를 예측하고 매칭할까? | by 황리건 Reagan Hwang | 원티드 제품 팀블로그 | May, 2021 | Medium](https://medium.com/wantedjobs/%EC%9B%90%ED%8B%B0%EB%93%9C%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-ai%EB%A1%9C-%EC%B1%84%EC%9A%A9-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%EC%98%88%EC%B8%A1%ED%95%98%EA%B3%A0-%EB%A7%A4%EC%B9%AD%ED%95%A0%EA%B9%8C-7bdcd8840b6b)
* [최신 Optimizer를 적용해보자! – 학습 방향의 최적화 방법을 새롭게 제시한 AngularGrad – Linewalks Blog](https://blog.linewalks.com/archives/7595)
* [옵티마이저(Optimizer) · Data Science](https://yngie-c.github.io/deep%20learning/2020/03/19/training_techs/)
* [How to Train Large Deep Learning Models as a Startup](https://www.assemblyai.com/blog/how-to-train-large-deep-learning-models-as-a-startup/)
* [How to Train Really Large Models on Many GPUs?](https://lilianweng.github.io/lil-log/2021/09/24/train-large-neural-networks.html)
* [인공지능 모델을 데이터셋에 맞게 대량으로 찍어내는 방법 (only 파이썬). 김태영 - PyCon Korea 2021 - YouTube](https://www.youtube.com/watch?v=DtV74hNpLs8) model
* [딥러닝 가속기가 이끄는 반도체 시장의 미래 | GeekNews](https://news.hada.io/topic?id=5120)
* [How Long Does It Take Ordinary People To "Get Good" At Chess?](https://github.com/jcw024/lichess_database_ETL/blob/main/README.md)
* [EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING](https://rockt.github.io/2018/04/30/einsum)
* [Bag-of-Tricks — 딥러닝 성능을 높이기 위한, 다양한 꿀팁들 | by 이도현 | CURG | Medium](https://medium.com/curg/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%84%B1%EB%8A%A5%EC%9D%84-%EB%86%92%EC%9D%B4%EA%B8%B0-%EC%9C%84%ED%95%9C-%EB%8B%A4%EC%96%91%ED%95%9C-%EA%BF%80%ED%8C%81%EB%93%A4-1910c6c7094a)
* [Deep Learning's Most Important Ideas - A Brief Historical Review](https://dennybritz.com/blog/deep-learning-most-important-ideas/)
* [Rosaria Silipo on Codeless Deep Learning and Visual Programming - YouTube](https://www.youtube.com/watch?v=0jWVYBSa6vM)
* [Jon Barron - Understanding and Extending Neural Radiance Fields - YouTube](https://www.youtube.com/watch?v=HfJpQCBTqZs)
* [캐글 딥러닝 강좌 정리 1 - 뉴런(Neuron)과 깊은 신경망(DNN) - 멈춤보단 천천히라도](https://webnautes.tistory.com/1646)
* [캐글 딥러닝 강좌 정리 2 - 확률적 경사 하강법(Stochastic Gradient Descent), 손실함수, 옵티마이저 - 멈춤보단 천천히라도](https://webnautes.tistory.com/1647)
* [Deep Learning Is Hitting a Wall - Nautilus | Science Connected](https://nautil.us/deep-learning-is-hitting-a-wall-14467/)
  * [딥러닝은 한계에 직면했다 | GeekNews](https://news.hada.io/topic?id=6129)
* [A New Link to an Old Model Could Crack the Mystery of Deep Learning | Quanta Magazine](https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/)
* [DeepETA: How Uber Predicts Arrival Times Using Deep Learning](https://eng.uber.com/deepeta-how-uber-predicts-arrival-times/)
  * [DeepETA: Uber가 딥러닝으로 도착시간을 예측하는 법 | GeekNews](https://news.hada.io/topic?id=6048)
* [Deep Learning in Neuroimaging](https://thegradient.pub/the-role-of-deep-learning-in-understanding-neuroimaging-data/)
* [2022-1-deep-learning-applications](https://github.com/sjchoi86/2022-1-deep-learning-applications)
* [딥러닝은 어떻게 동작할까? 현재 어디까지 왔고, 미래는 어떻게 될까?](https://engineering.linecorp.com/ko/blog/how-deep-learning-works-and-how-far-we-now)
* [1. 딥러닝이란 무엇인가? | 텐서 플로우 블로그 (Tensor ≈ Blog)](https://tensorflow.blog/%ec%bc%80%eb%9d%bc%ec%8a%a4-%eb%94%a5%eb%9f%ac%eb%8b%9d/1-%eb%94%a5%eb%9f%ac%eb%8b%9d%ec%9d%b4%eb%9e%80-%eb%ac%b4%ec%97%87%ec%9d%b8%ea%b0%80/)
* [How “Deep Learning” Will Radically Change Our Lives | by Upen Singh | DataDrivenInvestor](https://medium.datadriveninvestor.com/how-deep-learning-will-radically-change-our-lives-8b0f251e0f54)
* [Learnable Dynamics Model로 무엇을 할 수 있을까? | by Taeho Lee | We’re Team MakinaRocks! | Aug, 2022 | Medium](https://medium.com/makinarocks/learnable-dynamics-model%EB%A1%9C-%EB%AC%B4%EC%97%87%EC%9D%84-%ED%95%A0-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C-b801c6d4fe5b)

# AlphaGo
* [Rochester-NRT/AlphaGo](https://github.com/Rochester-NRT/AlphaGo)
* [AlphaGo의 인공지능 알고리즘 분석](http://spri.kr/post/14725)
* [AlphaGo 알고리즘 요약](http://www.slideshare.net/zenithon/alphago)
* [알파고 (바둑 인공지능)의 작동 원리](http://www.slideshare.net/ShaneSeungwhanMoon/ss-59226902)
* [이세돌과 대국으로 ‘알파고’ 설계자가 꿈꾸는 것은?](http://www.bloter.net/archives/251528)
* [모두의 알파고](http://www.slideshare.net/DonghunLee20/ss-59338971)
* [Mastering the game of Go with deep neural networks and tree search](http://www.willamette.edu/~levenick/cs448/goNature.pdf)
* [AlphaGo에 적용된 딥러닝 알고리즘 분석](https://brunch.co.kr/@justinleeanac/2)
* [알파고는 어떻게 바둑을 둘까](https://brunch.co.kr/@madlymissyou/9)
* [이세돌이 알파고를 이기려면 선입견을 버려야 한다](http://blog.daum.net/sadprince57/3331)
* [바둑인을 위한 알파고](http://www.slideshare.net/DonghunLee20/ss-59413793)
* [알파고 해부하기 1부](http://www.slideshare.net/DonghunLee20/1-59501887)
* [알파고 해부하기 2부](http://www.slideshare.net/DonghunLee20/2-59620244)
* [알파고 해부하기 3부](http://www.slideshare.net/DonghunLee20/3-61454159)
* [알파고, 강화학습을 현실에 데뷔시키다](http://t-robotics.blogspot.co.id/2016/03/blog-post_26.html)
* [알파고는 어떤 컴퓨터를 썼을까?](http://www.slideshare.net/jysoo/ss-61950212)
* [AlphaGo 대국 - 한국어](https://deepmind.com/research/alphago/alphago-games-korean/)
* [알파고는 스스로 신의 경지에 올랐다](https://brunch.co.kr/@madlymissyou/18)
* [Alphago zero cheatsheet](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)
* [AlphaGo Zero - How and Why it Works](http://tim.hibal.org/blog/alpha-zero-how-and-why-it-works/)
* [Deep Learning: AlphaGo Zero Explained In One Picture](https://www.datasciencecentral.com/profiles/blogs/deep-learning-alphago-zero-explained-in-one-picture)
* [Explained Simply: How an AI program mastered the ancient game of Go](https://medium.freecodecamp.org/explained-simply-how-an-ai-program-mastered-the-ancient-game-of-go-62b8940a9080)
* [알파고 분석 Part.1 - 엑셈 CTO 박재호](https://www.youtube.com/watch?v=b8MUVASzb8M)
* [쉽게 읽는 강화학습 논문 알파고 제로(Zero) 논문 리뷰](https://www.youtube.com/watch?v=CgOGKChwWrw)
* [플밍노트 너와 나의 인공지능이 멍청한 이유 - YoungJin Shin](http://www.jiniya.net/ng/2020/07/deep-learning-101/) 일반적인 이야기이지만 바둑을 통해 전개
* [2021-KAIST-Include-AlphaGoZero: 2021년 KAIST 동아리 Include 스터디 - AlphaGo와 AlphaGo Zero를 활용한 인공지능 바둑](https://github.com/utilForever/2021-KAIST-Include-AlphaGoZero)
* [한돌 개발 이야기 | NHN FORWARD](https://forward.nhn.com/2021/sessions/12)
* [Alpha-Omok Minimal version of DeepMind AlphaZero](https://github.com/reinforcement-learning-kr/alpha_omok)
  * [알파오목](https://www.youtube.com/watch?v=rJHEM31Dxw8)
* [minigo - An open-source implementation of the AlphaGoZero algorithm](https://github.com/tensorflow/minigo)

# Amazon
* [Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine](https://github.com/amznlabs/amazon-dsstne)

# Auto Encoder VAE
* [Autoencoders](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)
* [인공 신경망에 관한 설명. 스탠포드 대학 앤드류 응 교수의 sparse autoencoder 정리 노트로 인공신경망 이해하기](http://woongheelee.com/m/entry/%EC%9D%B8%EA%B3%B5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%97%90-%EA%B4%80%ED%95%9C-%EC%84%A4%EB%AA%85-%EC%8A%A4%ED%83%A0%ED%8F%AC%EB%93%9C-%EB%8C%80%ED%95%99-%EC%95%A4%EB%93%9C%EB%A5%98-%EC%9D%91-%EA%B5%90%EC%88%98%EC%9D%98-sparse-autoencoder-%EC%A0%95%EB%A6%AC-%EB%85%B8%ED%8A%B8%EB%A1%9C-%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0)
* [What're the differences between PCA and autoencoder?](http://stats.stackexchange.com/questions/120080/whatre-the-differences-between-pca-and-autoencoder)
* [Deep AutoEncoders for Collaborative Filtering](https://github.com/NVIDIA/DeepRecommender) autoencoder 기반 추천 엔진
* [알기쉬운 Variational autoencoder](https://www.slideshare.net/ssuser06e0c5/variational-autoencoder-76552518)
* [Denoising auto encoders(d a)](http://www.slideshare.net/taeyounglee1447/denoising-auto-encodersd-a)
* [What is variational autoencoder?](http://nolsigan.com/blog/what-is-variational-autoencoder/) VAE
* [On manifolds and autoencoders](http://videolectures.net/deeplearning2015_vincent_autoencoders/?q=vincent%20autoencoder)
* [KL divergence와 VAE](http://blog.naver.com/atelierjpro/220981354861)
* [1. 오토인코더(Sparse Autoencoder) 1 – AutoEncoders & Sparsity](http://solarisailab.com/archives/113?ckattempt=1)
* [A Gentle Autoencoder Tutorial (with keras)](http://www.birving.com/presentations/autoencoders/index.html#/)
* [Variational Auto-Encoder for MNIST](https://github.com/hwalsuklee/tensorflow-mnist-VAE)
* [초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE) (1)](http://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-1.html)
* [초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE) (2)](http://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-2.html)
* [초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE) (3)](http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-3.html)
* [NDC2017 딥러닝으로 게임 콘텐츠 제작하기 - VAE를 이용한 콘텐츠 생성 기법 연구 사례](https://www.slideshare.net/HwanheeKim2/ndc2017-vae-75419284)
* [Variational Coin Toss](http://www.openias.org/variational-coin-toss)
* [Variational Autoencoder를 여러 가지 각도에서 이해하기 (Understanding Variational Autoencoder from Various Perspectives)](https://www.slideshare.net/haezoom/variational-autoencoder-understanding-variational-autoencoder-from-various-perspectives)
* [What a Disentangled Net We Weave: Representation Learning in VAEs (Pt. 1)](https://towardsdatascience.com/what-a-disentangled-net-we-weave-representation-learning-in-vaes-pt-1-9e5dbc205bd1)
* [Naver Tech Talk: 오토인코더의 모든 것 (2017년 11월)](https://d2.naver.com/news/0956269)
* [Ali Ghodsi, Lec : Deep Learning, Variational Autoencoder, Oct 12 2017 Lect 6.2](https://www.youtube.com/watch?v=uaaqyVS9-rM)
* [Variational Auto Encoding](https://github.com/MingyuKim87/VAE)
* [AutoEncoder vs Variant AutoEncoder](https://bcho.tistory.com/1326)
* [An Introduction to Variational Autoencoders](https://arxiv.org/abs/1906.02691v1)
* [분포를 추정해서 손글씨를 만들어보자 — (1) Variational Inference | by 박은지 | MODULABS x TECH | Feb, 2022 | Medium](https://medium.com/modulabs/%EB%B6%84%ED%8F%AC%EB%A5%BC-%EC%B6%94%EC%A0%95%ED%95%B4%EC%84%9C-%EC%86%90%EA%B8%80%EC%94%A8%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EC%9E%90-1-variational-inference-8f168e829f9d)
* [Advanced_Models: 여러가지 유명한 신경망 모델들을 제공합니다. (DCGAN, VAE, Resnet 등등)](https://github.com/jk96491/Advanced_Models)
* [benchmark_VAE: Library for Variational Autoencoder benchmarking](https://github.com/clementchadebec/benchmark_VAE)

# Backpropagation
* [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
* [Deep Learning - Geoffrey Hinton - how to do backpropagation in a brain](https://www.youtube.com/watch?v=kxp7eWZa-2M&t=38m13s)
* [Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)
* [Neural Networks: The Backpropagation algorithm in a picture](http://www.datasciencecentral.com/profiles/blogs/neural-networks-the-backpropagation-algorithm-in-a-picture)
* [**Backpropagation 예제와 함께 완전히 이해하기**](http://jaejunyoo.blogspot.com/2017/01/backpropagation.html)
* [A Derivation of Backpropagation in Matrix Form](http://sudeepraja.github.io/Neural/)
* [**Calculus on Computational Graphs: Backpropagation**](http://colah.github.io/posts/2015-08-Backprop/index.html)
* [Gradient Descent with Backpropagation](http://outlace.com/Beginner-Tutorial-Backpropagation/)
* [A Step by Step Backpropagation Example](http://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
* [A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
* [계산 그래프로 역전파 이해하기](https://brunch.co.kr/@chris-song/22)
* [Back-Propagation is very simple. Who made it Complicated ?](https://becominghuman.ai/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c)
* [Back-Propagation is very simple. Who made it Complicated ?](https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c)
* [Backpropagation Through Time: recurrent neural network training technique](http://www.techleer.com/articles/185-backpropagation-through-time-recurrent-neural-network-training-technique/)
* [Backpropagation: A supervised learning neural network method](http://www.techleer.com/articles/242-backpropagation-a-supervised-learning-neural-network-method/)
* [Backprop is not just the chain rule](http://timvieira.github.io/blog/post/2017/08/18/backprop-is-not-just-the-chain-rule/)
  * 단순히 체인룰에 의해 계산되는 BP로만 보면 안된다는 글
  * BP와 같은 종류를 autodiff 라고 이 글에서는 표현했는데, 이게 우리 수학에서 배운 미분과는 다르다는 것을 강조(기존의 미분을 symbolic differentiation 이라고 표기)
  * 기존의 방식은 intermediate variables를 쓸 수 없지만, autodiff 에서는 이것이 가능해서 간결하고 효율적으로 사용 가능(마치 함수와 같음)
  * 또한 방정식의 선형시스템의 형태를 갖추었고, acyclic graph의 형식으로 연산이 연결되므로 전체적인 연산의 복잡도가 대폭 감소
  * 이걸 잘 mix하면 대부분의 문제 해결 가능
  * 이걸 수학적으로 풀어내는 과정에서 Lagrange multiplier, implicit function theorem 등 다소 복잡하고 어려운 내용들이 등장
  * 결론적으로 BP는 단순 체인룰을 도입해서 풀어낸 것이 아니라, intermediate variables를 가진 프로그램으로 전환시켜서 효율과 유연성을 갖추게 하였고, 또한 더 복잡한 문제를 풀어낼 수 있는 기초가 될 수 있도록 했다는 내용
* [Gradient Descent Overview](https://brunch.co.kr/@chris-song/50)
  * [simple_gradient_descent.py](https://gist.github.com/chris-chris/808d383f19f74c537d9b4476b019c59a)
* [Backpropagation In Convolutional Neural Networks](http://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/)
* [Backpropagation](https://www.slideshare.net/MingukKang/backpropagation-85544666?qid=a791b026-a2e5-4d08-bda2-54ad1608b4b7)
* [Efficient Batch Normalization](https://costapt.github.io/2016/07/09/batch-norm-alt/)
* [Fast-BN-BackPropagation.pdf](https://github.com/hccho2/hccho2.github.io/blob/master/Fast-BN-BackPropagation.pdf/)
* [Gradient Descent & Normal Eq](https://www.youtube.com/watch?v=M9Gsi3VBTYM)
* [Numerical Gradient Descent vs. BackPropagation](https://github.com/dgtgrade/HumanLearning/blob/master/1102.py)
* [Keep it simple! How to understand Gradient Descent algorithm](http://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html)
* [Gradient Descent(경사하강법)](http://blog.anthouse.co.kr/221210836545)
* [경사하강법에서 모든 parameter를 동시에 갱신해야 하는 이유](https://blog.naver.com/atelierjpro/220954798036)
* [An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/)
* [Gradient descent, how neural networks learn | Deep learning, part 2](https://www.youtube.com/watch?v=IHZwWFHWa-w)
* [경사하강법](http://likejazz.com/post/171142973969/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95%EC%9D%80-%EC%A0%95%EB%A7%90-%EC%8B%A0%EB%B9%84%EB%A1%9C%EC%9A%B4-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%B4%EB%8B%A4-%EC%96%B4%EB%96%BB%EA%B2%8C-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9E%98-%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94%EC%A7%80-%EC%97%AC%EC%A0%84%ED%9E%88-%EC%8B%A0%EA%B8%B0%ED%95%98%EB%8B%A4)
* [Improving Vanilla Gradient Descent](https://towardsdatascience.com/improving-vanilla-gradient-descent-f9d91031ab1d)
* [The Two Phases of Gradient Descent in Deep Learning](https://medium.com/intuitionmachine/the-peculiar-behavior-of-deep-learning-loss-surfaces-330cb741ec17)
* [Machine Learning 101: An Intuitive Introduction to Gradient Descent](https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645)
* [Understanding the 3 Primary Types of Gradient Descent](https://medium.com/@ODSC/understanding-the-3-primary-types-of-gradient-descent-987590b2c36)
* [Understanding the Mathematics behind Gradient Descent](https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e)
* [Coding Neural Network — Forward Propagation and Backpropagtion](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76)
* [Backpropagation calculus | Deep learning, chapter 4](https://www.youtube.com/watch?v=tIeHLnjs5U8)
* [Lecture 4 | Introduction to Neural Networks](https://www.youtube.com/watch?v=d14TUNcbn1k)
* [The Backpropagation Algorithm Demystified](https://medium.com/@nathaliejeans7/the-backpropagation-algorithm-demystified-41b705229727)
* [Nevergrad : A Python toolbox for performing gradient-free optimization](https://www.techleer.com/articles/576-nevergrad-a-python-toolbox-for-performing-gradient-free-optimization/)
* [**역전파 알고리즘 완전정복 A Step by Step Backpropagation**](https://nbviewer.jupyter.org/github/metamath1/ml-simple-works/blob/master/BP/bp.ipynb)
* [Backpropagation 함께 편미분하기](https://velog.io/@gibonki77/DLmathdifferentiate2)
* [Batch Normalization - backpropagation 유도하기](https://velog.io/@gibonki77/Batch-Normalization-backpropagation-%EC%9C%A0%EB%8F%84%ED%95%98%EA%B8%B0)

# Baidu
* [Silicon Valley AI Lab](https://svail.github.io/)
* [상호 작용을 통해 말하기 학습](https://www.nextobe.com/single-post/2017/06/09/%EB%B0%94%EC%9D%B4%EB%91%90-%EC%83%81%ED%98%B8-%EC%9E%91%EC%9A%A9%EC%9D%84-%ED%86%B5%ED%95%B4-%EB%A7%90%ED%95%98%EA%B8%B0-%ED%95%99%EC%8A%B5)
* [Baidu Reseaech Presentation @ GTC](https://www.facebook.com/nextobe1/photos/a.313464989089503.1073741829.303538826748786/340449486391053)
* [DeepBench - Benchmarking Deep Learning operations on different hardware](https://github.com/baidu-research/DeepBench)
  * 심층 신경 네트워크를 학습 할 때 서로 다른 프로세서가 어떻게 작동하는지 평가할 수 있는 최초의 도구
  * [An update to DeepBench with a focus on deep learning inference](https://svail.github.io/DeepBench-update/)

# Book
* [Top 15 books to make you a Deep Learning Hero - Towards Data Science](https://towardsdatascience.com/top-15-books-to-make-you-a-deep-learning-hero-b1b5f640a680)
* [머신러닝에서 딥러닝까지](http://digital.kyobobook.co.kr/digital/ebook/ebookDetail.ink?selectedLargeCategory=001&barcode=480150001023P&orderClick=LAN&Kc)
* [C++와 CUDA C로 구현하는 딥러닝 알고리즘 Vol.1 Restricted Boltzman Machine의 이해와 Deep Belief Nets 구현](http://www.acornpub.co.kr/book/dbn-cuda-vol1)
* [Deep Learning 이론과 실습 (개정중)](https://wikidocs.net/book/498)
* [한권으로 끝내는 파이썬 & 딥러닝](https://sdc-james.gitbook.io/onebook/)
* [도서 마인드맵](https://www.mindmeister.com/812276967/_)
* [좌충우돌 강화 학습의 이론과 구현 (원고)](http://books.sumeun.org/index.php/2019/01/14/sumeunrl/)
* [파이썬을 이용한 머신러닝, 딥러닝 실전 개발 입문](http://wikibook.co.kr/python-machine-learning/?path=facebook)
  * [머신러닝/딥러닝 실전 입문](https://www.youtube.com/playlist?list=PLBXuLgInP-5m_vn9ycXHRl7hlsd1huqmS)
* [더북(TheBook): 모두의 딥러닝 개정2판](https://thebook.io/080228/)
* [더북(TheBook): 신경망 교과서](https://thebook.io/080232/) 1~3장만
* [11 Deep Learning Articles, Tutorials and Resources](http://www.datasciencecentral.com/profiles/blogs/11-deep-learning-articles-tutorials-and-resources)
* [Artificial Intelligence Book of January 2017](http://artificialbrain.xyz/artificial-intelligence-book-of-january-2017/)
* [Book: Deep Learning With Python](http://www.datasciencecentral.com/forum/topics/book-deep-learning-with-python) Theano and TensorFlow using Keras
* [David MacKay: Information Theory, Pattern Recognition and Neural Networks: The Book](http://www.inference.org.uk/mackay/itprnn/book.html)
* [Deep-Learning-for-Beginners - Sample code in MATLAB/Octave and Python for Deep Learning for Beginners](https://github.com/philbooks/Deep-Learning-for-Beginners)
* [Deep Learning for Programmers](https://aiprobook.com/deep-learning-for-programmers/)
* [Deep Learning Book](https://www.youtube.com/channel/UCF9O8Vj-FEbRDA5DcDGz-Pg/playlists)
* [Deep Learning Book Companion Videos](https://www.youtube.com/playlist?list=PLsXu9MHQGs8df5A4PzQGw-kfviylC-R9b)
* [deep-learning-books](https://github.com/devakar/deep-learning-books)
* [Deep Learning - An MIT Press book in preparation](http://www.deeplearningbook.org/)
  * [DeepLearningBook](https://github.com/HFTrader/DeepLearningBook)
  * [Notation](http://www.deeplearningbook.org/contents/notation.html)
  * [Deep Learning Book Notes, Chapter 3 (part 1): Introduction to Probability](https://towardsdatascience.com/deep-learning-book-notes-chapter-3-part-1-introduction-to-probability-49d13c997f2a)
  * [MIT Deep Learning Book (beautiful and flawless PDF version)](https://github.com/janishar/mit-deep-learning-book-pdf)
  * [11-785 Introduction to Deep Learning Spring 2019](http://deeplearning.cs.cmu.edu/)
* [Deep Learning - A Practitioner's Approach](http://shop.oreilly.com/product/0636920035343.do)
* [Deep Learning With Python](https://machinelearningmastery.com/deep-learning-with-python/)
* [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)
  * [github.com/fchollet/deep-learning-with-python-notebooks](https://github.com/fchollet/deep-learning-with-python-notebooks)
  * [Companion Jupyter notebooks for the book "Deep Learning with Python"](https://www.floydhub.com/redeipirati/projects/deep-learning-with-python-notebooks)
* [fastai book](https://github.com/fastai/fastbook)
* [Free Deep Learning Textbook](http://www.datasciencecentral.com/profiles/blogs/free-deep-learning-textbook)
* [Fundamentals of Deep Learning](http://shop.oreilly.com/product/0636920039709.do)
  * [‘Fundamental of Deep Learning’ Preview](https://tensorflowkorea.wordpress.com/2016/04/18/fundamental-of-deep-learning-preview/#more-2018)
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbooks.io/rl/content/)
* [**Hands-On Reinforcement Learning With Python**](https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python)
* [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
  * [**numpy-neuralnet-exercise**](https://github.com/hwalsuklee/numpy-neuralnet-exercise)
* [NEURAL NETWORKS AND DEEP LEARNING: A TEXTBOOK](http://www.charuaggarwal.net/neural.htm)
  * [Deep Learning- Charu Aggarwal](https://www.youtube.com/playlist?list=PLLo1RD8Vbbb_6gCyqxG_qzCLOj9EKubw7)
* [Reinforcement Learning: An Introduction](https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf)
  * [교과서 읽고 느낀점](http://blog.naver.com/atelierjpro/220896756412)
  * [reinforcement_learning_an_introduction](https://github.com/Curt-Park/reinforcement_learning_an_introduction)
    * [Introduction](https://nbviewer.jupyter.org/github/Curt-Park/reinforcement_learning_an_introduction/blob/master/ch01_introduction/introduction.ipynb)
    * [Multi-armed bandits](https://nbviewer.jupyter.org/github/Curt-Park/reinforcement_learning_an_introduction/blob/master/ch02_multi-armed_bandits/multi-armed_bandits.ipynb)
  * [Rich Sutton's Talks](http://incompleteideas.net/Talks/Talks.html)
* [RL: Reinforcement Learning Algorithms](https://github.com/young2code/RL)
* [TinyML Book](https://tinymlbook.com)
  * [TinyML 세계에 여러분을 초대합니다!](https://brunch.co.kr/@synabreu/97)

# CAN
* [CAN (Creative Adversarial Network) — Explained](https://hackernoon.com/can-creative-adversarial-network-explained-1e31aea1dfe8)

# Conference
* [1st 함께하는 딥러닝 컨퍼런스](https://tykimos.github.io/2018/06/28/ISS_1st_Deep_Learning_Conference_All_Together/)
* [핵심 정리 갓샘숭의 섭외력! 딥러닝 거장들의 현장 토크 요약 (삼성AI포럼 2020)](https://www.philgineer.com/2020/11/samsung-ai-forum.html)
* [뛰어서 딥러닝 속으로 세미나 - 1회 (딥뉴럴네트워크와 컨볼루셔날 뉴럴네트워크 - YouTube](https://www.youtube.com/watch?v=v6lFCg0c4cE)
* [DLCAT#2 참석 후기 & 정리](https://beomi.github.io/2019/07/04/DLCAT2nd/)
  * [2nd DLCAT (이론)딥러닝으로 오디오 만나보기 - 남기현](https://tykimos.github.io/2019/07/04/ISS_2nd_Deep_Learning_Conference_All_Together_namkihyun/)
  * [강화학습 해부학 교실: Rainbow 이론부터 구현까지 (2nd dlcat in Daejeon)](https://www.slideshare.net/KyunghwanKim27/rainbow-2nd-dlcat-in-daejeon)
    * [Rainbow is all you need! Step-by-step tutorials from DQN to Rainbow](https://github.com/Curt-Park/rainbow-is-all-you-need)
* [ICLR 2015](http://www.iclr.cc/doku.php?id=iclr2015%3Amain)
  * [Artificial Tasks for Artificial Intelligence](https://www.dropbox.com/s/ly9y136saba0915/ICLR2015_Oral_Slides_All.pdf?oref=e&n=117881854)
* [Deep Learning Trends @ ICLR 2016](http://www.computervisionblog.com/2016/06/deep-learning-trends-iclr-2016.html)
* [ICLR 2017 - Conference Track International Conference on Learning Representations](http://openreview.net/group?id=ICLR.cc%2F2017%2Fconference)
  * [ICLR2017 Paper Index](https://tensorflowkorea.wordpress.com/2016/11/16/iclr2017-paper-index/)
  * [ICLR 2017 workshop track open review](http://nuit-blanche.blogspot.com/2017/02/iclr-2017-workshop-track-open-review.html)
  * [Learning to remember rare events](https://www.slideshare.net/ssuser06e0c5/learning-to-remember-rare-events)
  * [Designing Neural Network Architectures using Reinforcement Learning" (Under review as a conference paper at ICLR 2017)](https://arxiv.org/abs/1611.02167)
* [ICLR 2019 Notes](https://david-abel.github.io/notes/iclr_2019.pdf)
* [ICLR 2019 리뷰: 프로그램 소개 및 단순하고 효과적인 Network Pruning 방법론을 다룬 Best Paper 리뷰](http://research.sualab.com/review/2019/05/23/ICLR-2019-best-paper-review.html)
* [NIPS 2016](http://beamandrew.github.io/deeplearning/2016/12/12/nips-2016.html)
  * [nips.cc/Conferences/2016/Schedule](https://nips.cc/Conferences/2016/Schedule)
  * [Project All Code Implementations for NIPS 2016 papers : MachineLearning](https://www.reddit.com/r/MachineLearning/comments/5hwqeb/project_all_code_implementations_for_nips_2016/)
  * [LET'S DISCUSS: LEARNING METHODS FOR DIALOGUE NIPS 2016 WORKSHOP](http://letsdiscussnips2016.weebly.com/schedule.html)
  * [NIPS 2016 tutorial - Summary Nuts and bolts of building AI applications using Deep Learning](http://jaejunyoo.blogspot.com/2017/03/nips-2016-tutorial-summary-nuts-and-bolts-of-building-AI-AndrewNg.html)
    * [초짜 대학원생의 입장에서 정리한 NIPS 2016 tutorial: Nuts and bolts of building AI applications using Deep Learning by Andrew Ng](http://jaejunyoo.blogspot.com/2017/03/kr-nips-2016-tutorial-summary-nuts-and-bolts-of-building-AI-AndrewNg.html)
  * [History of Bayesian Neural Networks (Keynote talk)](https://www.youtube.com/watch?v=FD8l2vPU5FY)
* [NVIDIA DEEP LEARNING DAY 2017 CONFERENCE](https://www.nvidia.com/ko-kr/deep-learning-day/agenda/)
* [SAIF 2021 Day 2: Live streaming | Samsung - YouTube](https://www.youtube.com/watch?v=Jy_auavraKg)

# Course MOOC Lecture
* [#39. 딥러닝 공부 가이드 2019 (무료 강의, 책)](t-robotics.blogspot.com/2018/12/39-2019.html)
  * [#0.2 딥러닝 공부 가이드 2019](https://www.youtube.com/watch?v=fEwVeyki5p8)
* [딥러닝 강좌할껀데, 실습만 합니다](https://www.youtube.com/playlist?list=PLqtXapA2WDqbE6ghoiEJIrmEnndQ7ouys)
  * [github.com/hanyoseob](https://github.com/hanyoseob)
* [AI는 내친구 개발자, 전문가 대상 딥뉴럴네트웍 학습이론 특강 | KAIST AI STUDIO - YouTube](https://www.youtube.com/watch?v=ozfynpcvHhU)
* [Learning From Data - Machine Learning course - recorded at a live broadcast from Caltech](http://work.caltech.edu/telecourse.html)
  * [Course Review: Learning from Data (Introductory Machine Learning course)](https://www.class-central.com/report/review-caltech-learning-from-data-intro-machine-learning/)
* [Every single Machine Learning course on the internet, ranked by your reviews](https://medium.freecodecamp.com/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0)
* [Creative Applications of Deep Learning with TensorFlow](https://www.kadenze.com/programs/creative-applications-of-deep-learning-with-tensorflow)
* [How to learn Deep Learning in 6 months](https://towardsdatascience.com/how-to-learn-deep-learning-in-6-months-e45e40ef7d48)
* [Notes from Coursera Deep Learning courses by Andrew Ng](https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng)
* [How To Get The Best Deep Learning Education For Free](https://www.linkedin.com/pulse/how-get-best-deep-learning-education-forfree-mariya-yao)
* [인공지능, 통계 관련 유용한 무료 강의 & 책 모음](http://www.datamarket.kr/xe/board_fpbt85/55766)
* [6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/)
  * [MIT 6.S094: Introduction to Deep Learning and Self-Driving Cars](https://www.youtube.com/watch?v=1L0TKZQcUtA&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)
* [6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/)
  * [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs)
  * [MIT 6.S191: Introduction to Deep Learning](https://medium.com/tensorflow/mit-6-s191-introduction-to-deep-learning-24994d705aca)
* [Advanced Deep Learning & Reinforcement Learning](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)
* [CS 221: 인공지능 (봄 2019), CS 229: 기계 학습 (가을 2018), CS 230: 딥 러닝 (겨울 2019)](https://stanford.edu/~shervine/l/ko/)
* [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/)
* [시리즈 | CS224W Review - 투빅스 GNN 스터디](https://velog.io/@tobigs-gnn1213/series/Part1-CS224W)
* CS 229 [cheatsheet-translation/ko at master · shervinea/cheatsheet-translation](https://github.com/shervinea/cheatsheet-translation/tree/master/ko)
* [CS 230 ― Deep Learning](https://stanford.edu/~shervine/teaching/cs-230.html)
  * [Deep Learning cheatsheets for Stanford's CS 230](https://github.com/afshinea/stanford-cs-230-deep-learning)
* [CS 598 LAZ: Cutting-Edge Trends in Deep Learning and Recognition](http://slazebni.cs.illinois.edu/spring17/)
* [CS W182 / 282A](https://cs182sp21.github.io/)
  * [Deep Learning: CS 182 Spring 2021 - YouTube](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A)
  * [CS W182 / 282A at UC Berkeley Designing, Visualizing and Understanding Deep Neural Networks - Deep Learnings - 2021 - YouTube](https://www.youtube.com/playlist?list=PLuv1FSpHurUevSXe_k0S7Onh6ruL-_NNh)
* [Deep Learning Roadmap for Mechanical Engineering Students - KAsimov Wiki](https://kasimov.korea.ac.kr/dokuwiki/doku.php/activity/public/reference/how_we_study_deep_learning)
* [**Dive into Deep Learning - An interactive deep learning book for students, engineers, and reseachers**](http://d2l.ai/)
  * 기초적인 수학부터 각종 net시리즈들 자연어처리와 고속 컴퓨팅을 위한 병렬처리, GPU사용법 등을 pdf와 github, jupyter note까지 제공
  * [코드, 수학, 그리고 토론과 함께하는 상호적인 딥러닝 책](http://ko.d2l.ai)
  * [Introduction to Deep Learning](https://courses.d2l.ai/berkeley-stat-157/index.html)
  * [**d2l-pytorch - This is an attempt to modify Dive into Deep Learning, Berkeley STAT 157 (Spring 2019) textbook's code into PyTorch**](https://github.com/dsgiitr/d2l-pytorch)
  * [Dive into Deep Learning](https://ko.d2l.ai)
  * [Dive into Deep Learning Colab 실습환경 구축](https://gist.github.com/serithemage/44f7bb9ec9eed7cefa5ce48e13f09772)
  * [Dive into Deep Learning Compiler](http://tvm.d2l.ai/)
* [DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving](http://deepdriving.cs.princeton.edu/?platform=hootsuite)
* [Deep_Learning Ahlad Kumar](https://www.youtube.com/playlist?list=PLdxQ7SoCLQANQ9fQcJ0wnnTzkFsJHlWEj)
  * [Deep_Learning_7: Simple Examples of Variables, Constants and Placeholders in TensorFlow (Part B)](https://www.youtube.com/watch?v=yYfNsZSSkaQ)
* [deeplearning.ai/courses](https://www.deeplearning.ai/courses/)
  * [Review of Deeplearning.ai Courses](https://towardsdatascience.com/review-of-deeplearning-ai-courses-aed1328e4ffe)
  * [github.com/shahariarrabby/deeplearning.ai](https://github.com/shahariarrabby/deeplearning.ai)
  * [Neural Networks and Deep Learning (Course 1 of the Deep Learning Specialization)](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0)
    * [신경망과 딥러닝](https://www.edwith.org/deeplearningai1)
  * [Improving deep neural networks: hyperparameter tuning, regularization and optimization (Course 2 of the Deep Learning Specialization)](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
    * [심층 신경망 성능 향상시키기](https://www.edwith.org/deeplearningai2)
  * [Structuring Machine Learning Projects (Course 3 of the Deep Learning Specialization)](https://www.youtube.com/playlist?list=PLkDaE6sCZn6E7jZ9sN_xHwSHOdjUxUW_b)
    * [머신러닝 프로젝트 구조화하기](https://www.edwith.org/deeplearningai3)
  * [Convolutional Neural Networks (Course 4 of the Deep Learning Specialization)](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF)
    * [합성곱 신경망 네트워크 (CNN)](https://www.edwith.org/deeplearningai4)
  * [Sequence Models](https://www.youtube.com/playlist?list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6)
  * [Heroes of Deep Learning Interviews](https://www.youtube.com/playlist?list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr)
* [Deep Learning Courses](http://machinelearningmastery.com/deep-learning-courses/)
* [Deep Learning course: lecture slides and lab notebooks](https://m2dsupsdlclass.github.io/lectures-labs/)
* [Deep Learning in Python](https://www.datacamp.com/courses/deep-learning-in-python)
* [Deep Learning State of the Art (2020) | MIT Deep Learning Series](https://www.youtube.com/watch?v=0VH1Lim8gL8)
* [DeepMind x UCL | Deep Learning Lecture Series 2020 - YouTube](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)
* [Dive into Deep Learning with 15 free online courses](https://medium.freecodecamp.com/dive-into-deep-learning-with-these-23-online-courses-bf247d289cc0)
* [DS-GA 1008 · 2020 봄 · NYU CENTER FOR DATA SCIENCE](https://atcold.github.io/pytorch-Deep-Learning/ko/) 한글
* [**edwith.org/deeplearningchoi**](http://www.edwith.org/deeplearningchoi/)
* [EE-559 – Deep Learning](https://documents.epfl.ch/users/f/fl/fleuret/www/dlc/)
* [fast.ai · Making neural nets uncool again](https://www.fast.ai/)
  * [Practical Deep Learning for Coders - Practical Deep Learning](https://course.fast.ai/)
  * [fast.ai: How I built a deep learning application to detect invasive species in just 1 day (and for $12.60)](https://medium.com/the-business-of-ai/fast-ai-how-i-built-a-deep-learning-application-to-detect-invasive-species-in-just-1-day-and-for-38e0ced809e9)
  * [Practical Deep Learning for Coders (2020) - YouTube](https://www.youtube.com/playlist?list=PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM)
    * [**Practical Deep Learning For Coders, Part 1**](http://course.fast.ai/)
    * [**Practical Deep Learning For Coders, Part 2**](http://course.fast.ai/part2.html)
    * [Cutting Edge Deep Learning for Coders—Launching Deep Learning Part 2](http://www.fast.ai/2017/07/28/deep-learning-part-two-launch/)
    * [fast.ai 버전3 튜토리얼 3 (v3 lesson 3 - head pose) | Kaggle](https://www.kaggle.com/code/sungjunghwan/fast-ai-3-3-v3-lesson-3-head-pose)
  * [fast.ai literate programming](https://medium.com/@dienhoa.t/fast-ai-literature-programming-2d0d4230dd81)
  * [fast.ai releases new deep learning course, four libraries, and 600-page book · fast.ai](https://www.fast.ai/2020/08/21/fastai2-launch/)
    * fastai-v2: 원래 fastai는 교육용 딥러닝 라이브러리
      * 그러나, 이를 활용하여 강의를 수강한 여러 학생들이 좋은 성과를 내면서 유사한 컨셉의 새로운 라이브러리 작성(v1과 호환되지 않음)
    * 책 (Deep Learning for Coders): fastai 라이브러리 사용법이 포함되지만, PyTorch, Python 고급 기법등도 함께 다룸. 밑바닥부터 구현
    * Practical Deep Learning for Coders: 파트 1과 파트2로 구분되었던 fastai 강의 중 파트 1부분
      * 일반적으로 파트2는 보다 내부적인 코드레벨로의 deep dive입니다.
      * Your first models, Evidence and p values, Production and Deployment, SGD from scratch, Data ethics, Collaborative Filtering, Tabular data, Natural Language Processing
    * 부가적으로 공개된 라이브러리
      * fastcore: fastai에서 사용되는 기초적인 라이브러리. 테스팅, Mixins/Delegation/Composition 등, 함수형 프로그래밍/병렬 프로세싱 등, Dispatch, Transform 등을 Python에서 쉽게 코딩할 수 있는 방법 제공
      * fastscript: 매우 쉽게 argument 를 받아들이는 프로그램을 작성할 수 있도록 도와주는 라이브러리
      * fastgpu: Multiple GPU에 스크립트 단위로 GPU를 할당하여, 여러 종의 스크립트가 병렬적으로 별도의 GPU에서 수행되고자 하는 작업이 있을때 유용
  * [FastAI Deep Learning Course - Study with Me - YouTube](https://www.youtube.com/playlist?list=PLpdmBGJ6ELULBj7a16Dl2m9ABQTrgUOuS)
* [Full Stack Deep Learning - Full Stack Deep Learning](https://course.fullstackdeeplearning.com)
  * [Spring 2019 Full Stack Deep Learning Bootcamp](https://fullstackdeeplearning.com/march2019)
    * [Full Stack Deep Learning Bootcamp 정리](https://zzsza.github.io/mlops/2019/10/06/fullstack-deeplearning-bootcamp/)
  * [FSDL 2022 - Full Stack Deep Learning](https://fullstackdeeplearning.com/course/)
* [MIT Deep Learning](https://deeplearning.mit.edu/)
* [Podcast: The world needs AI researchers. Here’s how to become one](https://80000hours.org/2017/07/podcast-the-world-needs-ai-researchers-heres-how-to-become-one/)
* [STAT 157, Spring 19](https://courses.d2l.ai/berkeley-stat-157/syllabus.html)
* [Theories of Deep Learning (STATS 385)](https://stats385.github.io/)
  * [Theories of Deep Learning (STATS 385)](https://stats385.github.io/lecture_slides)
* [Udacity Deep Learning Nanodegree 수료 후기](https://medium.com/@EJSohn/udacity-deep-learning-nanodegree-%EC%88%98%EB%A3%8C-%ED%9B%84%EA%B8%B0-51449857fc24)
* [**UCL x DeepMind Deep Learning Lecture Series - General**](https://www.eventbrite.co.uk/o/ucl-x-deepmind-deep-learning-lecture-series-general-29078980901)
* [Reinforcement Learning Lecture Series 2021 | DeepMind](https://deepmind.com/learning-resources/reinforcement-learning-series-2021)
* [Yann LeCun’s Deep Learning Course at CDS – NYU Center for Data Science](https://cds.nyu.edu/deep-learning/)

# Extreme Learning Machines
* [Extreme Learning Machines](http://www.ntu.edu.sg/home/egbhuang/pdf/IEEE-IS-ELM.pdf)
* [Basic ELM Algorithms](http://www.ntu.edu.sg/home/egbhuang/elm_codes.html)

# Facebook
* [Facebook Presentation @ GTC](https://www.facebook.com/nextobe1/photos/a.313464989089503.1073741829.303538826748786/340462899723045)

# GAN Generative Adversarial Networks
* [All-About-the-GAN](https://github.com/hollobit/All-About-the-GAN)
* [All-About-the-GAN](https://hollobit.github.io/All-About-the-GAN/)
* [really-awesome-gan](https://github.com/nightrome/really-awesome-gan)
* [gans-awesome-applications](https://github.com/nashory/gans-awesome-applications)
* [Generative Adversarial Networks - The Story So Far](https://blog.floydhub.com/gans-story-so-far)
* NIPS 2016 Tutorial: Generative Adversarial Networks [paper](https://arxiv.org/pdf/1701.00160v1.pdf) [slide](http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf)
* [SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient](https://arxiv.org/pdf/1609.05473v2.pdf)
  * GAN이 처음으로 sequence generation task에 사용
  * GAN은 진짜같은 Fake data를 만들어내는 Generator과 진짜 data와 Fake data를 구분해내는 Discriminator를 학습시키는 알고리즘
  * 실수 픽셀들로 이루어진 그림과 달리 discrete한 토큰들의 sequence를 생성해낼 때 현재 얼마나 Generator가 잘 학습을 하고 있는지 평가할 방법이 마땅치 않아 sequence generation task에서는 사용되지 않음
  * 이번에 발표된 SeqGAN 은 discriminator를 Policy Gradient 의 Reward 로 사용해서 이 문제를 해결, Text Generation, Music Generation Task 에 적용
  * [Ian Goodfellow (GAN 저자) 의 Reddit 문답(왜 NLP에 GAN이 사용되기 힘든가)](https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/)
* [번역 - Generative Adversarial Network (GAN) 설명](http://keunwoochoi.blogspot.com/2016/12/generative-adversarial-network-gan.html)
* [GANs will change the world](https://medium.com/@Moscow25/gans-will-change-the-world-7ed6ae8515ca)
* [A tensorflow implementation of Junbo et al's Energy-based generative adversarial network ( EBGAN ) paper](https://github.com/buriburisuri/ebgan)
* [초짜 대학원생의 입장에서 이해하는 Energy-Based Generative Adversarial Networks (1)](https://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html)
* [초짜 대학원생의 입장에서 이해하는 f-GAN](http://jaejunyoo.blogspot.com/2017/06/f-gan.html)
* [초짜 대학원생의 입장에서 이해하는 f-GAN (2)](http://jaejunyoo.blogspot.com/2017/06/f-gan-2.html)
* [초짜 대학원생의 입장에서 이해하는 f-GAN (3)](http://jaejunyoo.blogspot.com/2017/07/f-gan-3.html)
* [초짜 대학원생 입장에서 이해하는 Generative Adversarial Nets (1)](http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html)
* [초짜 대학원생 입장에서 이해하는 Generative Adversarial Nets (2)](http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-2.html)
* [Catch me if you can: A simple english explanation of GANs or Dueling neural-nets](https://towardsdatascience.com/catch-me-if-you-can-a-simple-english-explanation-of-gans-or-dueling-neural-nets-319a273434db)
* [**Generative adversarial networks**](http://www.slideshare.net/ssuser77ee21/generative-adversarial-networks-70896091)
* [Generative Adversarial Networks](https://github.com/nlintz/TensorFlow-Tutorials/blob/master/11_gan.ipynb)
* [PaintsChainer Demo](http://paintschainer.preferred.tech/)
  * [PaintsCahiner Code](https://github.com/pfnet/PaintsChainer)
  * [tai2an 본인이 올린 글](http://qiita.com/taizan/items/cf77fd37ec3a0bef5d9d)
  * [U-Net](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)
* [Chainer-GAN-lib](https://github.com/pfnet-research/chainer-gan-lib/blob/master/README.md)
* [초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)](http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html)
  * [Pr12 dann jaejun yoo](https://www.slideshare.net/thinkingfactory/pr12-dann-jaejun-yoo)
* [초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (2)](http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural-2.html)
* [초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (3)](http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural-3.html)
* [tf-dann-py35 - Tensorflow-gpu (1.0.0.rc2, Window, py35) implementation of Domain Adversarial Neural Network](https://github.com/jaejun-yoo/tf-dann-py35)
* [Domain Adaptation Methods](https://www.slideshare.net/samchoi7/domain-adaptation-methods)
  * [DOMAIN ADVERSARIAL NEURAL NETWORK](https://github.com/sjchoi86/advanced-tensorflow/blob/master/dann/dann_mnist.ipynb)
* [초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)](https://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html)
* [초짜 대학원생의 입장에서 이해하는 Deep Convolutional Generative Adversarial Network (DCGAN) (1)](http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html)
* [초짜 대학원생의 입장에서 이해하는 Deep Convolutional Generative Adversarial Network (DCGAN) (2)](http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-2.html)
* [Dcgan](https://www.slideshare.net/BrianKim244/dcgan-77452250)
* [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](http://www.slideshare.net/ssuser06e0c5/infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets-72268213)
* [Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f)
* [초짜 대학원생의 입장에서 이해하는 Unrolled Generative Adversarial Networks (1)](http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html)
* [초짜 대학원생의 입장에서 이해하는 Unrolled Generative Adversarial Networks (2)](http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-2.html)
* [초짜 대학원생의 입장에서 이해하는 InfoGAN (1)](http://jaejunyoo.blogspot.com/2017/03/infogan-1.html)
* [초짜 대학원생의 입장에서 이해하는 InfoGAN (2)](http://jaejunyoo.blogspot.com/2017/03/infogan-2.html)
* [Read-through: Wasserstein GAN](http://www.alexirpan.com/2017/02/22/wasserstein-gan.html)
* [Wasserstein GAN 수학 이해하기 I](https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i)
* [Wasserstein GAN(WGAN) and the Kantorovich-Rubinstein Duality](http://nbviewer.jupyter.org/github/maestrojeong/wgan_duality/blob/master/WGAN_duality.ipynb)
* [Wasserstein GAN and the Kantorovich-Rubinstein Duality](https://vincentherrmann.github.io/blog/wasserstein/)
* [Wasserstein GAN: An Alternative To The Traditional GAN Training](https://www.techleer.com/articles/471-wasserstein-gan-an-alternative-to-the-traditional-gan-training/)
* [The story about WGAN](https://medium.com/@sunnerli/the-story-about-wgan-784be5acd84c)
* [InfoGAIL](https://www.slideshare.net/samchoi7/infogail)
* [AI기획 - 경쟁 통해 배우는 인공지능 기술 GAN](http://techm.kr/bbs/?t=Wh)
* [Generative Adversarial Networks Explained](http://www.rubedo.com.br/2017/03/generative-adversarial-networks.html)
* [겐스는 왜 기존 비창의 인공지능과 다른가?](https://www.linkedin.com/pulse/%EA%B2%90%EC%8A%A4-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%80-%EC%99%9C-%EA%B8%B0%EC%A1%B4-%EB%B9%84%EC%B0%BD%EC%9D%98-%EA%B8%B0%EC%88%A0%EA%B3%BC-%EB%8B%A4%EB%A5%B8%EA%B0%80-sung-jin-james-kim)
* [Adversarial Attacks on Neural Network Policies](http://rll.berkeley.edu/adversarial/)
* [Disco GAN - SK T-Brain Research](https://www.facebook.com/notes/sk-t-brain/sk-t-brain-research/398821727155314)
  * [DiscoGAN - Official PyTorch implementation of Learning to Discover Cross-Domain Relations with Generative Adversarial Networks](https://github.com/SKTBrain/DiscoGAN)
  * [DiscoGAN in PyTorch - PyTorch implementation of Learning to Discover Cross-Domain Relations with Generative Adversarial Networks](https://github.com/carpedm20/DiscoGAN-pytorch)
  * [discogan_tensorflow.py](https://github.com/wiseodd/generative-models/blob/master/GAN/disco_gan/discogan_tensorflow.py)
  * [Tensorflow Implementation of DiscoGAN](https://github.com/GunhoChoi/DiscoGAN_TF)
  * [논문반/논문세미나 DiscoGAN](http://www.modulabs.co.kr/DeepLAB_library/12820)
    * [Discover Cross-Domain Relations with GAN (DiscoGAN) with TensorFlow & slim](https://github.com/ilguyi/discoGAN.tensorflow.slim)
  * [Generative Adversarial Networks for Style Transfer (LIVE)](https://www.youtube.com/watch?v=MgdAe-T8obE)
* [Generative Models - Collection of generative models, e.g. GAN, VAE in Pytorch and Tensorflow](https://github.com/wiseodd/generative-models)
  * [Agustinus Kristiadi's Blog](http://wiseodd.github.io/techblog/)
  * [GAN](https://github.com/wiseodd/generative-models/tree/master/GAN)
* [초짜 대학원생의 입장에서 이해하는 LSGAN (1)](http://jaejunyoo.blogspot.com/2017/03/lsgan-1.html)
* [초짜 대학원생의 입장에서 이해하는 LSGAN (2)](http://jaejunyoo.blogspot.com/2017/04/lsgan-2.html)
* [Generative Adversarial Networks](http://cs.stanford.edu/people/karpathy/gan/)
* [aliensunmin.github.io/project/accv16tutorial](http://aliensunmin.github.io/project/accv16tutorial/)
* [Deep Feedforward Generative Models](http://aliensunmin.github.io/project/accv16tutorial/media/generative.pdf)
* [Generative Adversarial Networks to Make 8-bit Pixel Art](http://www.rubedo.com.br/2017/03/generative-adversarial-networks-to-make.html)
* [겐(GANs)이 꿈꾸는 인공지능 번역 끝판왕](https://medium.com/@jskDr/%EA%B2%90-gans-%EC%9D%B4-%EA%BF%88%EA%BE%B8%EB%8A%94-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%B2%88%EC%97%AD-%EB%81%9D%ED%8C%90%EC%99%95-4df872ffa13f)
* [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://junyanz.github.io/CycleGAN/)
* [Image-to-Image Translation](https://www.slideshare.net/ssuser34f9fc/imagetoimage-translation-122354566)
* [CycleGAN](https://github.com/junyanz/CycleGAN)
* [Understanding and Implementing CycleGAN in TensorFlow](https://hardikbansal.github.io/CycleGANBlog/)
* [Finding connections among images using CycleGAN](http://tv.naver.com/v/2203900)
  * [Finding connections among images using CycleGAN](https://www.slideshare.net/NaverEngineering/finding-connections-among-images-using-cyclegan)
* [cycleGAN 낮사진을 밤사진으로 바꾸는 ai](https://docs.google.com/presentation/d/1-82NXqa8oGAxuNOg2xCsVpiKkpzkDeE71PrQQ0YHFbo)
* [Jokeriser with CycleGAN](https://github.com/junkwhinger/jokerise)
* [초짜 대학원생의 입장에서 이해하는 BEGAN: Boundary Equilibrium Generative Adversarial Networks (1)](http://jaejunyoo.blogspot.com/2017/04/began-boundary-equilibrium-gan-1.html)
* [초짜 대학원생의 입장에서 이해하는 BEGAN: Boundary Equilibrium Generative Adversarial Networks (2)](http://jaejunyoo.blogspot.com/2017/04/began-boundary-equilibrium-gan-2.html)
* [Tensorflow implementation of "BEGAN: Boundary Equilibrium Generative Adversarial Networks"](https://github.com/carpedm20/BEGAN-tensorflow)
* [BEGAN: STATE OF THE ART GENERATION OF FACES WITH GENERATIVE ADVERSARIAL NETWORKS](https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/)
* [BEGAN (2017) Summary](https://vics-kwon.github.io/gan/BEGAN-summary)
* [Generalization and Equilibrium in Generative Adversarial Networks (GANs)](http://www.offconvex.org/2017/03/30/GANs2/)
* [zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks](https://kaonashi-tyc.github.io/2017/04/06/zi2zi.html)
* [PR12 딥러닝 논문읽기 모임](https://www.youtube.com/playlist?list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br)
* [PR12 intro. to gans jaejun yoo](https://www.slideshare.net/thinkingfactory/pr12-intro-to-gans-jaejun-yoo)
* [PR12 Deep Learning Paper Presentation List and Summary](https://github.com/taeoh-kim/pr12)
* [**Variants of GANs - Jaejun Yoo**](https://www.slideshare.net/thinkingfactory/variants-of-gans-jaejun-yoo)
* [아주 간단한 GAN 구현하기](http://blog.naver.com/atelierjpro/220984758512)
* [The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo)
* [Generative Adversarial Networks (LIVE)](https://www.youtube.com/watch?v=0VPQHbMvGzg)
* [Deep generative model.pdf](https://www.slideshare.net/HyungjooCho2/deep-generative-modelpdf)
* [GANs (Generative Adversarial Networks)](http://nbviewer.jupyter.org/github/metamath1/ml-simple-works/blob/master/GAN/GANs.ipynb)
* [CaloGAN - Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks](https://github.com/hep-lbdl/CaloGAN)
* [Generative adversarial networks](https://www.slideshare.net/YunjeyChoi/generative-adversarial-networks-75916964)
  * [1시간만에 GAN(Generative Adversarial Network) 완전 정복하기](https://www.youtube.com/watch?v=odpjk7_tGY0&t=2s)
* [Adversarial Variational Bayes](https://github.com/LMescheder/AdversarialVariationalBayes) GAN + VAE
* [A new kind of deep neural networks](https://medium.com/towards-data-science/a-new-kind-of-deep-neural-networks-749bcde19108)
* [A Generative Model of People in Clothing](http://files.is.tue.mpg.de/classner/gp)
* [PR-001: Generative adversarial nets by Jaejun Yoo (2017/4/13)](https://www.youtube.com/watch?v=L3hz57whyNw)
* [PR-005: Playing Atari with Deep Reinforcement Learning (NIPS 2013 Deep Learning Workshop)](https://www.youtube.com/watch?v=V7_cNTfm2i8)
* [kkweon.github.io/pr12-web-app-elm](https://kkweon.github.io/pr12-web-app-elm/)
* [pr12er: PR12를 좀더 잘보기 위한 프로젝트](https://github.com/codingpot/pr12er)
* [Generative Adversarial Networks for Beginners Build a neural network that learns to generate handwritten digits](https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners)
  * [Introduction to generative adversarial networks](https://github.com/jonbruner/generative-adversarial-networks)
  * GAN은 알려진 입력 데이터와 비슷한 합성 데이터를 만드는 방법을 학습하는 신경망
  * 예를 들어, 연구원들은 침실에서 앨범 표지에 이르는 모든 사진의 설득력있는 이미지를 생성하고 고차원적 논리를 반영 할 수있는 뛰어난 능력
  * 이러한 예제는 매우 복잡하지만 아주 간단한 이미지를 생성하는 GAN을 만드는 것은 쉬움
  * 이 자습서에서는 손으로 쓴 숫자의 이미지를 분석하고 점진적으로 새로운 이미지를 생성하는 GAN을 생성
  * 본질적으로 신경망을 작성하는 법을 가르칠 것
* [GANGogh: Creating Art with GANs](https://medium.com/towards-data-science/gangogh-creating-art-with-gans-8d087d8f74a1)
* [**(Pytorch를 사용한) 단 50줄로 코드로 짜보는 GAN**](http://ddanggle.github.io/GANinTorch)
* [Meow Generator](https://ajolicoeur.wordpress.com/cats/)
  * DCGAN, WGAN, WGAN-GP, LSGAN 및 ReLU를 일괄 표준 대 SELU와 비교
* [Deep-learning-with-cats](https://github.com/AlexiaJM/Deep-learning-with-cats)
* [Deep Learning에서 "일러스트와 바람 인간 이미지 생성 모델 '을 만든 이야기 (DCGAN, Wasserstein GAN)](http://mickey24.hatenablog.com/entry/irasutoya_deep_learning)
* [art-DCGAN](https://github.com/robbiebarrat/art-DCGAN/blob/master/README.md)
* [Generative Adversarial Network : DCGAN을 이용한 이미지 생성](http://research.sualab.com/introduction/practice/2019/05/08/generative-adversarial-network.html)
* [How AI can learn to generate pictures of cats](https://medium.freecodecamp.org/how-ai-can-learn-to-generate-pictures-of-cats-ba692cb6eae4)
* [Generative Adversarial Networks (GANs)](http://guertl.me/post/162759264070/generative-adversarial-networks)
* [Audio & Video Manipulation](http://notes.michaeldempsey.me/post/159418832409/audio-video-manipulation)
* [Audio for Deep Learning version 2.0](https://docs.google.com/presentation/d/1s0qEsT5tKQEalGwmaUk4-sPhJLXIXsy81_n-rakz1ow/mobilepresent)
* [MelNet A Generative Model for Audio in the Frequency Domain](https://sjvasquez.github.io/blog/melnet/)
* [My Qcon.ai talk](https://keunwoochoi.wordpress.com/2019/06/09/my-qcon-ai-talk/) Deep Learning with Audio Signals
* [A Step-by-Step Guide to Synthesizing Adversarial Examples](http://www.anishathalye.com/2017/07/25/synthesizing-adversarial-examples/)
* [tf-exercise-gan - Tensorflow implementation of different GANs and their comparisions](https://github.com/sanghoon/tf-exercise-gan)
* [속고 속이는 게임 - Minimax Game](http://learnai.tistory.com/1)
* [GAN 스터디 공유자료](http://www.datamarket.kr/xe/index.php?mid=board_LCmL04&document_srl=33070)
* [2017 beginner's review of GAN architectures](https://sigmoidal.io/beginners-review-of-gan-architectures/)
* [MoCoGAN: Decomposing Motion and Content for Video Generation](https://github.com/sergeytulyakov/mocogan)
* [Do you know GAN? 1/2](https://brunch.co.kr/@kakao-it/145)
* [GAN Playground - Explore Generative Adversarial Nets in your Browser](https://reiinakano.github.io/gan-playground/)
* [Fantastic GANs and where to find them](http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them)
* [Fantastic GANs and where to find them II](http://guimperarnau.com/blog/2017/11/Fantastic-GANs-and-where-to-find-them-II)
* [Do you know GAN? (2/2)](https://brunch.co.kr/@kakao-it/162)
* [Delving deep into Generative Adversarial Networks (GANs)](https://github.com/GKalliatakis/Delving-deep-into-GANs)
* [PassGAN](https://github.com/brannondorsey/PassGAN)
* [Google open sources TFGAN: Lightweight Library for Generative Adversarial Networks](https://www.techleer.com/articles/437-google-open-sources-tfgan-lightweight-library-for-generative-adversarial-networks/)
* [Consecutive category morphing of GANs generated images (submitted to ICLR 2018)](https://www.youtube.com/watch?v=r6zZPn-6dPY)
* [An Intuitive Introduction to Generative Adversarial Networks](http://blog.kaggle.com/2018/01/18/an-intuitive-introduction-to-generative-adversarial-networks/)
* [The New Neural Internet is Coming - And it looks pretty scary from here](https://hackernoon.com/the-new-neural-internet-is-coming-dda85b876adf)
* [Auto-Regressive Generative Models (PixelRNN, PixelCNN++)](https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173)
* [1시간만에 GAN(Generative Adversarial Network) 완전 정복하기](http://tv.naver.com/v/1947034)
* [Black-Box Attacks on Perceptual Image Hashes with GANs](https://towardsdatascience.com/black-box-attacks-on-perceptual-image-hashes-with-gans-cc1be11f277)
* [GAN in Numpy](https://github.com/shinseung428/gan_numpy)
* GAN (Generative Adversarial Network) 관련 특허 최초 공개 및 분석
  * [(1) – 무엇에 관한 특허인가](https://steemit.com/kr/@daeho/gan-generative-adversarial-network-1)
  * [(2) – 논문 발표일과 특허 출원일의 상관관계(https://steemit.com/kr/@daeho/gan-generative-adversarial-network-2)
* [Semi-Supervised Learning and GANs](https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683)
* [**GENERATIVE ADVERSARIAL NETWORK AND ITS APPLICATIONS TO SPEECH SIGNAL AND NATURAL LANGUAGE PROCESSING**](https://sigport.org/documents/generative-adversarial-network-and-its-applications-speech-signal-and-natural-language)
* [Towards data set augmentation with GANs](https://medium.com/jungle-book/towards-data-set-augmentation-with-gans-9dd64e9628e6)
* [Introduction to GAN](https://www.slideshare.net/JiminLee36/introduction-to-gan)
* [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html)
* [Math Insights from 10 GAN papers. InfoGANs, VAEGANs, CycleGAN and more](https://www.youtube.com/watch?v=r3L3JT_TLTM)
* [From GAN to WGAN](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html)
* [Generative Models Part 1: VAE,GAN,DCGAN](https://taeoh-kim.github.io/blog/generative-models-part-1-vaegandcgan/)
* [Generative Models Part 2: ImprovedGAN,InfoGAN,EBGAN](https://taeoh-kim.github.io/blog/generative-models-part-2-improvedganinfoganebgan/)
* [GAN(Generative Adversarial Network) Tour](https://github.com/jason9693/GAN)
* [번역 From GAN to WGAN](https://github.com/yjucho1/articles/blob/master/fromGANtoWGAN/readme.md)
* [TL-GAN: transparent latent-space GAN This is the repository of my three-week project: "Draw as you can tell: controlled image synthesis and edit using TL-GAN"](https://github.com/SummitKwan/transparent_latent_gan)
* [Simple Latent Space](https://sihan-son.github.io/latent-space/)
* [Introduction to generative adversarial network](https://opensource.com/article/19/4/introduction-generative-adversarial-networks)
* [Paper Review; GAN for noise reduction in low dose CT](https://www.slideshare.net/JiminLee36/paper-review-gan-for-noise-reduction-in-low-dose-ct)
* [Efficient, Simplistic Training Pipelines for GANs in the Cloud with Paperspace](https://medium.com/@ODSC/efficient-simplistic-training-pipelines-for-gans-in-the-cloud-with-paperspace-d6cfbc33b7c3)
* [Semantic Image Synthesis with SPADE](https://github.com/NVlabs/SPADE)
* [The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo)
* [How to Develop a Conditional GAN (cGAN) From Scratch](https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/)
* [How to Code the GAN Training Algorithm and Loss Functions](https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions)
* [Progressive Growing of GANs for Improved Quality, Stability, and Variation – Official TensorFlow implementation of the ICLR 2018 paper](https://github.com/tkarras/progressive_growing_of_gans)
* [My Handwriting Styler, with GAN & U-Net](https://github.com/jeina7/Handwriting_styler)
  * [My handwriting styler](https://www.slideshare.net/MinjungChung1/my-handwriting-styler)
  * [내 손글씨를 따라쓰는 인공지능 요정, Wrinie (1) - 이론](https://jeinalog.tistory.com/15)
  * [내 손글씨를 따라쓰는 인공지능 요정, Wrinie (2) - 실습](https://jeinalog.tistory.com/16)
* [AI Generator Learns to 'Draw' Like Cartoonist Lee Mal-Nyeon in Just 10 Hours | Synced](https://syncedreview.com/2020/08/04/ai-generator-learns-to-draw-like-cartoonist-lee-mal-nyeon-in-just-10-hours/)
* [프로젝트 GAN을 이용한 염색 및 헤어 스타일 합성, <꽤 GAN찮은 헤어살롱>](https://comlini8-8.tistory.com/49)
* [Toonify yourself - Colaboratory](https://colab.research.google.com/drive/1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk)
* [StyleGAN2를 이용한 성격 유형별 얼굴 생성 모델 연구 개발 과정 공개! (feat. MBTI) – SPH](https://www.sphinfo.com/stylegan2/)
* [Alias-Free GAN (StyleGAN3) 이론 간단리뷰 :: Ostin](https://ostin.tistory.com/53)
* [Alias-Free GAN (StyleGAN3) 리뷰 - Architecture :: Ostin](https://ostin.tistory.com/55)
* [StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery - YouTube](https://www.youtube.com/watch?v=5icI0NgALnQ)
* [StyleCLIP-Tutorial](https://github.com/ndb796/StyleCLIP-Tutorial)
  * [딥러닝 기반의 이미지 편집 기술: StyleCLIP 설명 및 코드 실습 (꼼꼼한 딥러닝 논문 리뷰와 코드 실습) - YouTube](https://www.youtube.com/watch?v=hFC7DSh9RIw)
* [StyleCLIP에 대한 소개](https://brunch.co.kr/@advisor/33)
* [GAN 이미지 생성 알고리즘 테스트 하기](https://www.infoking.site/54)
* [Alias-Free GAN](https://nvlabs.github.io/alias-free-gan/)
  * [junjun3518/alias-free-torch: Simple torch.nn.module implementation of Alias-Free-GAN style filter and resample](https://github.com/junjun3518/alias-free-torch)
* [DualStyleGAN 논문 리뷰 :: Ostin](https://ostin.tistory.com/56)
* [EqGAN-SA : Improving GAN Equilibrium by Raising Spatial Awareness 논문 리뷰 :: Ostin](https://ostin.tistory.com/87)
* [Face2Webtoon](https://github.com/sangyun884/Face2Webtoon)
* GauGAN [NVIDIA Research's GauGAN AI Art Demo Responds to Words | NVIDIA Blog](https://blogs.nvidia.com/blog/2021/11/22/gaugan2-ai-art-demo/)
* [generative_inpainting: DeepFill v1/v2 with Contextual Attention and Gated Convolution, CVPR 2018, and ICCV 2019 Oral](https://github.com/JiahuiYu/generative_inpainting)
  * [Image Inpainting](https://master-generative-inpainting-woomurf.endpoint.ainize.ai/)
  * [generative_inpainting: DeepFill v1/v2 with Contextual Attention and Gated Convolution, CVPR 2018, and ICCV 2019 Oral](https://ainize.ai/woomurf/generative_inpainting)
* [KID-F: Korean Idol Dataset - Female : High Quality Korean Female Idol Face Image Dataset with Identity Labels](https://github.com/PCEO-AI-CLUB/KID-F)
  * 자체적으로 구축한 테스트 데이터셋을 대상으로 실험한 결과
    * FSR(Facel Super Resolution) 분야의 SOTA 모델과 토파즈의 상용 소프트웨어보다 모든 metric에서 좋은 성능, 원본 초고화질 사진과 굉장히 유사하게 복원
  * 아직은 얼굴의 이목구비를 복원하는 모델
  * 기존 모델은 훈련시에 지나치게 다양한 조건의 사진들을 고려한 데이터셋(예 : FFHQ)을 사용
  * 그보다는 아이돌의 아름다움과 특징을 가장 잘 학습할 수 있도록 데이터를 제한해야한다고 생각
    * 그래서 여자 아이돌 사진을 9만장 수집. 그 중 얼굴 영역의 해상도가 512x512가 넘는 사진들의 얼굴을 잘라 1만장 선별
    * 그 중에서도 진짜 고화질 사진을 골라 약 6천 장(5591장의 훈련용 데이터셋과 300장의 테스트용 데이터셋)의 여자 아이돌 고화질 얼굴 사진 수집
    * 이 데이터셋을 KID-F(Korean Idol Dataset - Female)으로 이름 붙이고 다른 연구자 분들도 편하게 사용하실 수 있도록 깃허브(KID-F)에 공개했습니다.
  * 위 결과가 도출된 모델은 Dual-Blind SR 구조로 이 분야의 SOTA 중 하나를 달성한 HiFaceGAN(2020)을 최적화 하고, 데이터셋을 변경하여 훈련
    * 아직은 얼굴 이목구비와 헤어 등으로 꽉찬 얼굴 사진만 복원할 수 있다는 한계, 실용화는 더 시간 필요
  * [IdolGAN: Project for restoring beautiful Korean Idols Images to high quality](https://github.com/PCEO-AI-CLUB/IdolGAN)
* [malnyun_faces: 침착한 생성모델 학습기](https://github.com/bryandlee/malnyun_faces)
* [Rarity-Score: Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images](https://github.com/hichoe95/Rarity-Score)
  * 생성모델 연구하시는 분들을 위해 유용한 평가지표(metric)
  * 생성모델의 metric이라고 하면 Inception score나 FID 연상하나 다음과 같은 한계 존재
    * 기본적으로 이미지의 품질 측정에 적합한 녀석들이라 모델이 얼마나 다양한 이미지를 만들어내는지 평가하기 어려움
    * 생성된 이미지에 매겨지는 점수가 아니라 많은 생성 이미지들로 부터 계산된 분포 기반으로 계산되는 모델에 매겨지는 점수여서 특정 이미지가 얼마나 좋은 점수를 갖는지 알기 어려움
    * 이건 Precision & Recall이나 NAVER CLOVA 의 density & coverage도 마찬가지
    * LPIPS같은 다양성 척도가 있긴 하나 이 또한 모델에 매겨지는 지표
  * 특히 요즘같이 생성모델이 얼마나 창의적이고 독특한 이미지를 잘 만들어내는가가 중요한 시점에 그리고 만들어진 개별 이미지가 일정 수준 이상 품질을 유지하면서 독특한 정도를 평가할 수 있다면 매우 유용
    * CLOVA AI Lab에서 KAIST-NAVER Hypercreative Center Jaesik Choi 교수님 연구실과 함께 한지연님 주도로 Rarity-score 작성
  * rarity-score는 학습이미지 데이터 latent feature와의 거리기반으로 각 생성된 이미지가 얼마만큼 훈련 데이터들과 비교했을 때 전형적인지 아닌지를 이미지 단위로 계산. 점수가 클수록 특이한 이미지
    * 이미지 개별 점수를 계산 수 있으니 누적을 통해 점수분포를 히스토그램 형태로 그려서 각 생성모델이 얼마나 독특한 이미지를 만들어낼 수 있는지도 평가 가능
    * 다양한 실험으로 각 모델마다 rarity-score와 feature extractor 효과, FID 유지를 위해 널리 쓰이는 truncation trick이 독특함에 미치는 효과 등을 확인 가능
* [sefa: Code for paper `Closed-Form Factorization of Latent Semantics in GANs`](https://github.com/genforce/sefa)
* [TGAN - Generative adversarial training for synthesizing tabular data https://sdv-dev.github.io/TGAN ](https://github.com/sdv-dev/TGAN)
* [This beach does not exist](https://thisbeachdoesnotexist.com/)
  * [이 해변은 존재하지 않습니다 | GeekNews](https://news.hada.io/topic?id=4649)

# Java
* [SmallData | Blog | Building a simple neural net in Java](https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java)
* [Deep Java Library - Open source library to build and deploy Deep Learning in Java](https://djl.ai/)
  * [Getting to Know Deep Java Library (DJL)](https://www.infoq.com/articles/djl-deep-learning-java/)
* [DL4J Deep Learning for Java](http://deeplearning4j.org/)
  * [DL4J Java자바를 위한 딥 러닝](http://deeplearning4j.org/kr-index.html)
  * [인공 신경망 및 심층 신경망 소개](http://deeplearning4j.org/kr-neuralnet-overview.html)
  * [A Beginner’s Guide to Recurrent Networks and LSTMs](http://deeplearning4j.org/lstm.html)
  * [Using Neural Networks With Regression](http://deeplearning4j.org/linear-regression.html)
  * [RBM with DL4J for Deep Learning](http://www.slideshare.net/uspace/rbm-with-dl4j-for-deep-learning-50955012)
  * [NN Models with DL4J for Deep Learning](http://www.slideshare.net/uspace/nn-models-with-dl4j-for-deep-learning)
  * [A Beginner’s Guide to Eigenvectors, PCA, Covariance and Entropy](http://deeplearning4j.org/eigenvector)
  * [“딥러닝, 게을러지려고 연구하죠”...아담 깁슨 DL4J 창시자](https://www.imaso.co.kr/news/article_view.php?article_idx=20150824223056)
  * [Exploring convolutional neural networks with DL4J](http://brooksandrew.github.io/simpleblog/articles/convolutional-neural-network-training-with-dl4j/)
  * [Deep Learning Using DL4J and Spark on HDP for Fun and Profit](https://www.youtube.com/watch?v=XCX0GsswDfM)
  * [rl4j - Reinforcement Learning for the JVM](https://github.com/deeplearning4j/rl4j)
  * [MLPClassifierLinear](https://www.youtube.com/watch?v=BN_g2t0ykxg) This is a screencast that shows building a Linear Classifier using a Neural Network
  * [Introduction to Deep Neural Networks](https://deeplearning4j.org/neuralnet-overview)
  * [Open Data for Deep Learning](https://deeplearning4j.org/opendata)
  * [제가 번역한 딥러닝 문서 목록 (deeplerarning4j.org)](http://keunwoochoi.blogspot.com/2016/03/deeplerarning4jorg.html)
  * [Getting started with Deeplearning4J and Scala](http://datasmarts.net/2017/11/11/getting-started-with-deeplearning4j-and-scala/)
  * [DL4J-Quick Start](http://hugrypiggykim.com/2016/05/15/deep-learning-dl4j-quick-start)
  * [Deep learning on Apache Spark and Apache Hadoop with Deeplearning4j](https://blog.cloudera.com/blog/2017/06/deep-learning-on-apache-spark-and-hadoop-with-deeplearning4j)

# Library
* [프로그래밍 언어별 딥러닝 라이브러리 정리](http://aikorea.org/blog/dl-libraries/)
* [어떤 Deep Learning Library를 선택해야하나요?](http://tmmse.xyz/choosing-deep-learning-libraries/)
* [유용한 딥러닝/머신러닝 프로젝트들](https://tykimos.github.io/2019/01/06/2018_ML_projects/)
* [15 Deep Learning Libraries](http://www.datasciencecentral.com/profiles/blogs/here-are-15-libraries-in-various-languages-to-help-implement-your)
* [15 Deep Learning Tutorials](http://www.datasciencecentral.com/profiles/blogs/15-deep-learning-tutorials)
* [50 Deep Learning Software Tools and Platforms, Updated](http://www.kdnuggets.com/2015/12/deep-learning-tools.html)
* [Best Python Libraries for Machine Learning and Deep Learning](https://towardsdatascience.com/best-python-libraries-for-machine-learning-and-deep-learning-b0bd40c7e8c)
* [A.I. Duet - A piano that responds to you](https://github.com/googlecreativelab/aiexperiments-ai-duet)
* [AIQC Artificial Intelligence Quality Control - an open source framework for rapid & reproducible deep learning](https://aiqc.readthedocs.io/en/latest/)
  * [Layne Sadler - AIQC: Framework for Reproducible and Rapid Deep Learning | PyData Boston Meetup - YouTube](https://www.youtube.com/watch?v=6mhfwuP2UzQ)
* C3DL [딥러닝 분산 플랫폼, C3DL](https://d2.naver.com/helloworld/1914772)
* Caffe
  * [윈도우에서 Caffe 이용하기](https://github.com/jaeho-kang/deep-learning/blob/master/%EC%9C%88%EB%8F%84%EC%9A%B0%EC%97%90%EC%84%9C%20caffe%20%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0.md)
  * [Setting Caffe on Windows with CUDA & Python](http://m.blog.naver.com/bsh0128/220733003127)
  * [A DSL for deep neural networks, supporting Caffe and Torch http://ajtulloch.github.io/dnngraph](https://github.com/ajtulloch/dnngraph)
  * [Deep Dreams (with Caffe)](https://github.com/google/deepdream/blob/master/dream.ipynb)
  * [Running Google’s Deep Dream on Windows (with or without CUDA) – The Easy Way](http://thirdeyesqueegee.com/deepdream/2015/07/19/running-googles-deep-dream-on-windows-with-or-without-cuda-the-easy-way/)
  * [Deep Learning and Caffe](http://whydsp.org/319)
  * [영상을 이용하기위한 Convolutional Neural Networks, CNN](http://jangjy.tistory.com/181)
  * [Modeling Images, Videos and Text Using the Caffe Deep Learning Library, part 1 (by Kate Saenko)](http://www.slideshare.net/ktoshik/kate-saenko-msr-russia-summer-school-modeling-images-video-text-caffe-dl-part1)
  * [Apply simple pruning on Caffemodel](https://github.com/garion9013/impl-pruning-caffemodel)
  * [Caffe to TensorFlow](https://github.com/ethereon/caffe-tensorflow)
  * [github.com/DeepLearningStudy/caffe/tree/master/examples](https://github.com/DeepLearningStudy/caffe/tree/master/examples)
  * [C++ Example 1. Hello Caffe](http://deeplearningstudy.github.io/doc_caffe_example_1hellocaffe.html)
    * [Caffe C++ API on Windows](http://blog.naver.com/atelierjpro/220835313030)
  * [SSD: Single Shot MultiBox Detector](https://github.com/weiliu89/caffe/tree/ssd)
  * [Netscope CNN Analyzer - A web-based tool for visualizing and analyzing convolutional neural network](https://dgschwend.github.io/netscope/quickstart.html)
    * CNN Model 분석을 도와줌
    * Model을 prototxt 형태로 넣어주면, 네트워크 구조와, 하단에 CNN Dimension, parameter 수 등의 세부 정보를 정리
  * [caffe-boo - My own caffe-windows with additional layers and features](https://github.com/seokhoonboo/caffe-boo)
  * [Caffe2 - A New Lightweight, Modular, and Scalable Deep Learning Framework](http://caffe2.ai/)
  * [Classifying ImageNet: using the C++ API](https://github.com/BVLC/caffe/tree/master/examples/cpp_classification)
  * [C++ Example 1. Hello Caffe](http://deeplearningstudy.github.io/doc_caffe_example_1hellocaffe.html)
  * [Deep learning tutorial on Caffe technology : basic commands, Python and C++ code](http://christopher5106.github.io/deep/learning/2015/09/04/Deep-learning-tutorial-on-Caffe-Technology.html)
  * [A Practical Introduction to Deep Learning with Caffe and Python](http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/)
  * [Caffe 와 Python을 사용하여 딥러닝으로 개와 고양이 구분하기 1](http://kyubot.tistory.com/96)
  * [Caffe 와 Python을 사용하여 딥러닝으로 개와 고양이 구분하기 2](http://kyubot.tistory.com/97)
* [ChessCoach](https://chrisbutner.github.io/ChessCoach/)
  * [ChessCoach - 자연어로 조언해주는 신경망 기반 체스 엔진 | GeekNews](https://news.hada.io/topic?id=5150)
* [ch0p1n: Python Package for Automatic Musical Composition](https://github.com/flujoo/ch0p1n)
  * [My Approach to Automatic Musical Composition](https://flujoo.github.io/en/my-approach-to-automatic-musical-composition/)
* [chitra: A multi-functional library for full-stack Deep Learning. Simplifies Model Building, API development, and Model Deployment](https://github.com/aniketmaurya/chitra)
* Cloudera
  * [Deep Learning Frameworks on CDH and Cloudera Data Science Workbench](http://blog.cloudera.com/blog/2017/04/deep-learning-frameworks-on-cdh-and-cloudera-data-science-workbench/)
    * CDH & Cloudera Data Science Workbench 기반의 딥러닝 프레임워크 소개
* [Computational Network Toolkit (CNTK)](https://cntk.codeplex.com)
* CoreML
  * [coreml-scikit-example - Apple CoreML example with scikit-learn](https://github.com/mfpierre/coreml-scikit-example)
  * [pypi.python.org/pypi/coremltools](https://pypi.python.org/pypi/coremltools)
  * [Keras Deep Learning with Apple’s CoreMLTools on iOS 11 – Part 1](https://amundtveit.com/2017/06/07/keras-deep-learning-with-apples-coremltools-on-ios-11-part-1/)
  * [WWDC 애플 코어 머신러닝 (Core ML) 발표 요약 1 ("Introduction to CoreML)](https://www.facebook.com/groups/TensorFlowKR/permalink/482610418746688/)
  * [CoreML and Vision-Create a basic example](https://www.youtube.com/watch?v=mVQB4YEkOKM)
  * [How I Shipped a Neural Network on iOS with CoreML, PyTorch, and React Native](https://attardi.org/pytorch-and-coreml/)
  * [번역 앱에 Core ML 모델 합치기](http://blog.canapio.com/136)
  * [iOS의 모바일용 머신러닝 프레임워크 - Core ML](http://blog.canapio.com/141)
  * [PoseEstimation-CoreML](https://github.com/tucan9389/PoseEstimation-CoreML)
* [craftassist - A virtual assistant bot in Minecraft](https://github.com/facebookresearch/craftassist)
* [darknet: Convolutional Neural Networks](https://github.com/pjreddie/darknet)
  * [Hardware Guide: Neural Networks on GPUs](http://pjreddie.com/darknet/hardware-guide/)
  * [DarkNet · DarkNet Book](https://jjeamin.github.io/darknet_book/)
* [deepart.io](http://www.deepart.io/) - Generate images styled like your favorite artist
* [DeepChem - a Python library democratizing deep learning for science](https://deepchem.io/index.html)
* [Deep Learning Model Convertors](https://github.com/ysh329/deep-learning-model-convertor)
* [deeplearning-models: A collection of various deep learning architectures, models, and tips](https://github.com/rasbt/deeplearning-models)
* [deeplearn.js - a hardware-accelerated machine intelligence library for the web](https://pair-code.github.io/deeplearnjs/)
* [DeepOSM - Classify roads and features in satellite imagery, by training neural networks with OpenStreetMap (OSM) data](https://github.com/trailbehind/DeepOSM)
* [DeepSpeed - a deep learning optimization library that makes distributed training easy, efficient, and effective](https://www.deepspeed.ai/)
* [DL_Compiler: Study Group of Deep Learning Compiler](https://github.com/ConstantPark/DL_Compiler)
* [EagerPy - Writing Code That Works Natively with PyTorch, TensorFlow, JAX, and NumPy](https://eagerpy.jonasrauber.de/) 상호호환
* [Eesen - The official repository of the Eesen project](https://github.com/srvk/eesen)
* [einops - Deep learning operations rethinked (supports tf, pytorch, chainer, gluon and others)](https://github.com/arogozhnikov/einops)
  * [Writing better code with pytorch and einops](https://arogozhnikov.github.io/einops/pytorch-examples.html)
* [Fabrik – Collaboratively build, visualize, and design neural nets in the browser http://fabrik.cloudcv.org](https://github.com/Cloud-CV/Fabrik)
* [gemmlowp: a small self-contained low-precision GEMM library](https://github.com/google/gemmlowp)
* [hiplot - HiPlot makes understanding high dimensional data easy](https://github.com/facebookresearch/hiplot)
  * [페이스북 AI, 인공지능 개발자·연구자 위한... AI 대화식 시각화 도구 'HiPlot' 오픈 소스로 공개](http://www.aitimes.kr/news/articleView.html?idxno=15348)
  * [HiPlot: High-dimensional interactive plots made easy](https://ai.facebook.com/blog/hiplot-high-dimensional-interactive-plots-made-easy)
  * [Visualizing Backpropagation in Neural Network Training at Any Scale | by Deval Parikh | Jan, 2022 | Towards Data Science](https://towardsdatascience.com/visualizing-backpropagation-in-neural-network-training-2647f5977fdb)
* [Horovod - a distributed training framework for TensorFlow, Keras, and PyTorch](https://github.com/uber/horovod)
  * [Training Deep Neural Networks on Distributed GPUs - YouTube](https://www.youtube.com/watch?v=jQgYuThPZVM)
* [Gradient Boosting Interactive Playground](http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html)
* [Labellio: Scalable Cloud Architecture for Efficient Multi-GPU Deep Learning](http://devblogs.nvidia.com/parallelforall/labellio-scalable-cloud-architecture-efficient-multi-gpu-deep-learning/)
* [LabNotebook - A simple experiment manager for deep learning experiments](https://github.com/henripal/labnotebook)
* Lasagne
  * [Lasagne-CTC](https://github.com/skaae/Lasagne-CTC)
* [micrograd: A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API](https://github.com/karpathy/micrograd)
  * [The spelled-out intro to neural networks and backpropagation: building micrograd - YouTube](https://www.youtube.com/watch?v=VMj-3S1tku0)
* [Mind - Flexible neural networks in JavaScript](http://www.mindjs.net/)
* [Mindori - On-demand GPUs for neural networks](http://mindori.com/)
* [MindSpore - a new open source deep learning training/inference framework that could be used for mobile, edge and cloud scenarios](https://github.com/mindspore-ai/mindspore)
* MuZero
  * [딥마인드 MuZero AI가 유튜브 비디오 압축을 개선 | GeekNews](https://news.hada.io/topic?id=6073)
  * [muzero-general: MuZero](https://github.com/werner-duvaud/muzero-general)
* [mxnet - Flexible and Efficient Library for Deep Learning](http://mxnet.io/)
  * [Awesome MXNet](https://github.com/chinakook/Awesome-MXNet) A curated list of MXNet examples, tutorials and blogs
  * [**An interactive book on deep learning. Much easy, so MXNet. Wow. http://gluon.mxnet.io**](https://github.com/zackchase/mxnet-the-straight-dope)
  * [mxnet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Scala, Go, Javascript and more http://mxnet.rtfd.org](https://github.com/dmlc/mxnet)
  * [MXNet - Deep Learning Framework of Choice at AWS](http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html)
  * [Alex Smola at AI Frontiers: Scalable Deep Learning Using MXNet](https://www.slideshare.net/AIFrontiers/scalable-deep-learning-using-mxnet)
  * [**MXNet을 활용한 이미지 분류 앱 개발하기**](http://www.popit.kr/mxnet%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%B6%84%EB%A5%98-%EC%95%B1-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0/)
  * [github.com/JONGGON/Mxnet_Tutorial](https://github.com/JONGGON/Mxnet_Tutorial)
  * [Apache MXNet에 대한 모든 것!](http://channy.creation.net/blog/1155)
  * [MXNet for Deep Learning](https://github.com/apache/incubator-mxnet)
  * [MXNet 기반 추천 오픈 소스 딥러닝 프로젝트 모음](http://blog.creation.net/apache-mxnet-deep-learning-project#.WYJws9Pygcw)
  * [CVPR 2017 Tutorial https://mli.github.io/cvpr17 ](https://github.com/mli/cvpr17)
  * [클라우드에 딱 맞는 MXNet의 5가지 딥러닝 학습 기능](http://blog.creation.net/mxnet-deep-learning-features-aws-cloud)
  * [dl-twitch-series](https://github.com/sunilmallya/dl-twitch-series/blob/master/README.md)
  * [Apache MXNet으로 배워보는 딥러닝(Deep Learning) - 김무현 (AWS 솔루션즈아키텍트)](https://www.youtube.com/watch?v=H66GDuLsGl4)
  * [MXNet 시작하기 (1) – NDArrays API](http://blog.creation.net/mxnet-part-1-ndarrays-api)
  * [deepSpeech.mxnet: Rich Speech Example](https://github.com/apache/incubator-mxnet/tree/master/example/speech_recognition)
    * [deepSpeech.mxnet: Rich Speech Example](https://github.com/samsungsds-rnd/deepspeech.mxnet)
  * [CapsNet-MXNet](https://github.com/samsungsds-rnd/capsnet.mxnet)
  * [An introduction to the MXNet API — part 1](https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab)
  * [전이학습(transfer learning)으로 모형 재사용하기 (Gluon 기반)](http://freesearch.pe.kr/archives/4701)
  * [Gluon을 이용한 Grad CAM](http://freesearch.pe.kr/archives/4695)
  * [seq2seq기반 덧셈 모형 빌드(with Gluon)](http://freesearch.pe.kr/archives/4710)
  * [MXNet 혹은 Gluon으로 모형을 개발할때 반드시 맞닥뜨릴 한가지 이슈](http://freesearch.pe.kr/archives/4737)
  * [Deep learning with Apache MXNet on Cloudera Data Science Workbench](https://blog.cloudera.com/blog/2017/10/deep-learning-with-apache-mxnet-on-cloudera-data-science-workbench/)
  * [Gluon으로구현해보는 한영기계번역 모형 – 마이크로소프트웨어 기고문](http://freesearch.pe.kr/archives/4754)
  * [딥러닝 프레임워크로 임베딩 제대로 학습해보기](http://freesearch.pe.kr/archives/4828)
  * [MXNet for PyTorch users in 10 minutes](https://medium.com/apache-mxnet/mxnet-for-pytorch-users-in-10-minutes-a7353863406a)
  * [Apache MXNet Cheat Sheet](https://aws.amazon.com/ko/blogs/korea/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance)
  * [Apache MXNet (incubating) adds support for Keras 2](https://aws.amazon.com/ko/blogs/machine-learning/apache-mxnet-incubating-adds-support-for-keras-2/)
  * [medium.com/apache-mxnet](https://medium.com/apache-mxnet)
    * [Let Sentiment Classification Model speak for itself using Grad CAM](https://medium.com/apache-mxnet/let-sentiment-classification-model-speak-for-itself-using-grad-cam-88292b8e4186)
    * [A Way to Benchmark Your Deep Learning Framework On-premise](https://medium.com/apache-mxnet/a-way-to-benchmark-your-deep-learning-framework-on-premise-4f7a0f475726)
  * [Relation Networks for Visual Question Answering using MXNet Gluon](https://medium.com/apache-mxnet/relation-networks-for-visual-question-answering-using-mxnet-gluon-f029fde8f863)
  * [Sentiment Analysis via Self-Attention with MXNet Gluon](https://medium.com/apache-mxnet/sentiment-analysis-via-self-attention-with-mxnet-gluon-dc774d38ba69)
  * [MXNet 초보자를 위한 Gluon 한 시간에 뽀개기](https://github.com/serithemage/AWS_AI_Study/blob/master/Gluon_Crash_Course_on_Colab.ipynb)
    * [MXNet 초보자를 위한 Gluon 한 시간에 뽀개기](https://colab.research.google.com/github/serithemage/AWS_AI_Study/blob/master/Gluon_Crash_Course_on_Colab.ipynb)
  * [딥러닝계의 블루오션, Apache MXNet 공헌하기 - 윤석찬 (AWS 테크에반젤리스트) 오규삼 (삼성 SDS)](https://www.slideshare.net/awskorea/apache-mxnet-soscon-2018)
  * [Logging MXNet Data for Visualization in TensorBoard](https://github.com/awslabs/mxboard)
  * [Colab에서 TensorBoard 및 MXBoard를 사용하여 데이터 시각화 하는 방법](https://gist.github.com/serithemage/7cf3937d1532ed94e982353c9349eebc)
  * [Run MXNet Scala Examples Using the IntelliJ IDE (macOS)](https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html)
  * [Implementation of SNAIL(A Simple Neural Attentive Meta-Learner) with Gluon](https://github.com/seujung/SNAIL-gluon)
  * [LipNet: End-to-End Sentence-level Lipreading](https://github.com/ski-net/lipnet)
  * [버트(BERT) 파인튜닝 간단하게 해보자](http://freesearch.pe.kr/archives/4963)
  * [GluonNLP v0.7.1 — BERT Reloaded](https://medium.com/apache-mxnet/gluonnlp-v0-7-1-bert-reloaded-7b9450d33f4b)
  * [Deep Learning Programming Style](https://mxnet.incubator.apache.org/versions/master/architecture/program_model.html) symbolic vs. iterative programming style
  * [**Pycon 2019 Gluon Tutorial 딥러닝 NLP 손쉽게 따라해보기**](https://github.com/seujung/gluonnlp_tutorial)
  * [Apache MXNet/gluon on Colab](https://gist.github.com/serithemage/54bf347b41980b98ade2353b2e27d899)
  * [딥러닝계의 블루오션, Apache MXNet 공헌하기 - 윤석찬 (AWS 테크에반젤리스트) 오규삼 (삼성 SDS)](https://www.slideshare.net/awskorea/apache-mxnet-soscon-2018)
  * [아마존, 개발자용 딥러닝 자동화 툴 '오토글루언' 공개](http://www.itworld.co.kr/news/141350)
  * [Using MXNet to Detect Fire from Live Video](https://medium.com/@jg.kim/using-mxnet-to-detect-fire-d8afaf4d9e07)
  * [A New NumPy Interface for Apache MXNet (Incubating)](https://medium.com/apache-mxnet/a-new-numpy-interface-for-apache-mxnet-incubating-dbb4a4096f9f)
  * [KoGPT2-chatbot: Simple Chit-Chat based on KoGPT2](https://github.com/haven-jeon/KoGPT2-chatbot)
  * [Gluon-Detector - SSD Retinanet YoloV3](https://github.com/JONGGON/Gluon-Detector)
  * [Mxnet-Detector - mxnet one stage detector series](https://github.com/DeepFocuser/Mxnet-Detector)
* [netron - Visualizer for neural network, deep learning and machine learning models https://www.lutzroeder.com/ai ](https://github.com/lutzroeder/netron) 신경망, 딥러닝 모델 시각화 툴이자 뷰어
  * [Netron! Network 구조를 보여주세요! · Jerry's Blog](https://jjerry-k.github.io/deeplearning/2020/07/20/netron/)
* [neural enhance - Super Resolution for images using deep learning](https://github.com/alexjc/neural-enhance)
* [NN-SVG - Publication-ready NN-architecture schematics](http://alexlenail.me/NN-SVG/index.html) visualization
* [NVDLA - Deep Learning Inference Compiler is Now Open Source](https://devblogs.nvidia.com/nvdla/)
* [OSLO: Open Source framework for Large-scale transformer Optimization](https://github.com/tunib-ai/oslo)
* [plaidML - A framework for making deep learning work everywhere](https://vertexai-plaidml.readthedocs-hosted.com/)
  * [PlaidML is a framework for making deep learning work everywhere. https://ai.intel.com/plaidml ](https://github.com/plaidml/plaidml)
* [PlotNeuralNet - Latex code for drawing neural networks for reports and presentation](https://github.com/HarisIqbal88/PlotNeuralNet)
* [Polyaxon - An enterprise-grade open source platform for building, training, and monitoring large scale deep learning applications](https://polyaxon.com/)
  * [Polyaxon: An open source Deep Learning / Machine Learning stack on Kubernetes](https://www.techleer.com/articles/485-polyaxon-an-open-source-deep-learning-machine-learning-stack-on-kubernetes/)
* [PyCNN - Image Processing in Cellular Neural Networks with Python](http://blog.ankitaggarwal.me/PyCNN/)
  * [Sequence To Sequence Attention Models In PyCNN](https://talbaumel.github.io/attention)
* [pylearn2-practice](https://github.com/zygmuntz/pylearn2-practice)
* [SINGA is a general distributed deep learning platform for training big deep learning models over large datasets](http://singa.apache.org/docs/overview.html)
* [Sonnet - TensorFlow-based neural network library](https://github.com/deepmind/sonnet)
  * [DeepMind의 Neural Network를 위한 라이브러리 SONNET](https://www.nextobe.com/single-post/2017/05/11/DeepMind-SONNET)
* [SPOTTY - An Open-source Tool for Training Deep Learning Models in the Cloud](https://spotty.cloud)
* [SRZoo: An integrated repository for super-resolution using deep learning](https://github.com/idearibosome/srzoo)
* TabNine [Autocompletion with deep learning](https://tabnine.com/blog/deep)
* [tinygrad: You like pytorch? You like micrograd? You love tinygrad! ❤️](https://github.com/geohot/tinygrad)
  * [geohot/tinygrad - 미니멀한 딥러닝 프레임워크 | GeekNews](https://news.hada.io/topic?id=6320)
* [VELES - Distributed platform for rapid Deep learning application development](https://velesnet.ml/)
* [TurboTransformers: a fast and user-friendly runtime for transformer inference (Bert, Albert, GPT2, Decoders, etc) on CPU and GPU](https://github.com/Tencent/TurboTransformers)
* [webdnn - Fastest DNN Execution Framework on Web Browser https://mil-tokyo.github.io/webdnn](https://github.com/mil-tokyo/webdnn)
* [xcessiv - A web-based application for quick and scalable construction of massive machine learning ensembles](https://github.com/reiinakano/xcessiv)
* [YOLO DARKNET - 구성 및 설치, 사용방법](http://www.popit.kr/yolo-darknet-%EA%B5%AC%EC%84%B1-%EB%B0%8F-%EC%84%A4%EC%B9%98-%EC%82%AC%EC%9A%A9%EB%B0%A9%EB%B2%95/)
  * [github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet/)
* [waifu2x - Image Super-Resolution for Anime/Fan-Art](https://github.com/nagadomi/waifu2x)
  * [Waifu Synthesis- real time generative anime](https://vimeo.com/342523600)

# Medical
* [MOLIERE: Automatic Biomedical Hypothesis Generation System](https://www.youtube.com/watch?v=wA6OCix-4FU&t=7s)
* [Applying deep learning to medical data](https://www.slideshare.net/hyunseokmin/applying-deep-learning-to-medical-data)
* [의료 ai를 위해 세상에 없는 양질의 data 만드는 도구 제작하기](https://www.slideshare.net/deview/213-ai-data)
* [Cardiac MRI Segmentation](https://chuckyee.github.io/cardiac-segmentation/)
* [Medical Image Segmentation Part 1 — UNet: Convolutional Networks with Interactive Code](https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6)
* [Encrypting Different Medical Images using Deep Neural Network with Interactive Code](https://towardsdatascience.com/encrypting-different-medical-images-using-deep-neural-network-with-interactive-code-b47656dcd1e)
* [A machine learning survival kit for doctors](https://medium.com/owkin/a-machine-learning-survival-kit-for-doctors-97982d69a375)
* [Deep Learning Papers on Medical Image Analysis](https://github.com/albarqouni/Deep-Learning-for-Medical-Applications)
* [HeLP-Challenge-Goldenpass](https://github.com/Taeu/HeLP-Challenge-Goldenpass)
* [How to program a neural network to predict breast cancer in only 5 minutes](https://medium.freecodecamp.org/how-to-program-a-neural-network-to-predict-breast-cancer-in-only-5-minutes-23289d62a4c1)
* [Doc Product: Medical Q&A with Deep Language Models](https://github.com/Santosh-Gupta/DocProduct)
* [RadIO - a library for data science research of computed tomography imaging https://analysiscenter.github.io/radio ](https://github.com/analysiscenter/radio)

# Microsoft
* The Microsoft Cognitive Toolkit 마이크로소프트에서 개발한 딥러닝 프레임워크 CNTK
  * [blog](https://blogs.microsoft.com/next/2016/10/25/microsoft-releases-beta-microsoft-cognitive-toolkit-deep-learning-advances)
  * [website](https://www.microsoft.com/en-us/research/product/cognitive-toolkit/)
  * [github.com/Microsoft/CNTK](https://github.com/Microsoft/CNTK)
  * CNTK v1.x; 속도는 빠르지만 C++, C# API만 지원하고 실서비스 배포가 불편한 문제
  * CNTK v2.0; Python API 지원, 최적화된 분산 학습 가능
  * [1-bit SGD, Model sharing 등 최적화된 대용량 처리에 초점을 맞춰서 개발](https://www.microsoft.com/en-us/research/product/cognitive-toolkit/features/)
  * [Image, Speech, Text 분야의 다양한 학습 모델](https://www.microsoft.com/en-us/research/product/cognitive-toolkit/model-gallery/)
  * [학습된 모델을 Azure로 배포, 서비스 가능](https://github.com/Microsoft/CNTK/wiki/Evaluate-a-model-in-an-Azure-WebApi)
  * [Benchmarking CNTK on Keras: is it Better at Deep Learning than TensorFlow?](http://minimaxir.com/2017/06/keras-cntk/)
  * [Microsoft Congnitive Toolkit 알아보기!](http://digitalbourgeois.tistory.com/37)
  * [Microsoft Face API: Python SDK & Sample](https://github.com/Microsoft/Cognitive-Face-Python)
  * [Keras + CNTK Backend](https://youngjaekim.wordpress.com/2019/03/31/keras-cntk-backend/)
* [Building Deep Neural Networks in the Cloud with Azure GPU VMs, MXNet and Microsoft R Server](https://blogs.technet.microsoft.com/machinelearning/2016/09/15/building-deep-neural-networks-in-the-cloud-with-azure-gpu-vms-mxnet-and-microsoft-r-server/)
* [AirSim - Open source simulator based on Unreal Engine for autonomous vehicles from Microsoft AI & Research](https://github.com/Microsoft/AirSim)
  * [Welcome to AirSim](https://microsoft.github.io/AirSim/)

# Neural Network
* [Google's AI Chief Geoffrey Hinton - How Neural Networks Really Work](https://www.youtube.com/watch?v=l2dVjADTEDU)
* [1. Overview of Mini Batch Gradient Descent](https://www.youtube.com/watch?v=GvHmwBc9N30)
* [Learning How To Code Neural Networks](https://medium.com/learning-new-stuff/how-to-learn-neural-networks-758b78f2736e)
  * [뉴럴네트워크 코드 짜는 법 배우기](http://ddanggle.github.io/ml/ai/cs/2016/07/16/LearningHowToCodeNeuralNetworks.html)
* [Machine Learning 스터디 (18) Neural Network Introduction](http://sanghyukchun.github.io/74/)
* [Artificial Neural Networks for Beginners](http://blogs.mathworks.com/loren/2015/08/04/artificial-neural-networks-for-beginners/)
* [Introduction To Neural Networks](https://kasperfred.com/series/introduction-to-neural-networks)
* [A Visual Explanation of the Back Propagation Algorithm for Neural Networks](http://www.kdnuggets.com/2016/06/visual-explanation-backpropagation-algorithm-neural-networks.html)
* [Machine Learning - Neural Networks Tutorial](http://www.existor.com/en/news-neural-networks.html)
* [A Fast and Accurate Dependency Parser using Neural Networks](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf)
* [Visualizing and Understanding Deep Neural Networks by Matt Zeiler](https://www.youtube.com/watch?v=ghEmQSxT6tw)
* [Machine-Learning Algorithm Mines Rap Lyrics, Then Writes Its Own](http://www.technologyreview.com/view/537716/machine-learning-algorithm-mines-rap-lyrics-then-writes-its-own/)
* [시인 뉴럴](http://pail.unist.ac.kr/carpedm20/poet/)
* [VGG Convolutional Neural Networks Practical](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html)
* [Spectral Representations for Convolutional Neural Networks](http://arxiv.org/pdf/1506.03767.pdf)
* [How to implement a neural network: Part 1](http://peterroelants.github.io/posts/neural_network_implementation_part01/)
* [Inceptionism: Going Deeper into Neural Networks](http://googleresearch.blogspot.kr/2015/06/inceptionism-going-deeper-into-neural.html)
* [Quantifying Creativity in Art Networks](http://arxiv.org/pdf/1506.00711v1.pdf)
* [Neural network의 변천사 이태영](https://www.slideshare.net/secret/dzVcikxOkWg8TP)
* [ai junkie - neural networks in plain english](http://www.ai-junkie.com/ann/evolved/nnt1.html)
* [10 Billion Parameter Neural Networks in your Basement](http://on-demand.gputechconf.com/gtc/2014/presentations/S4694-10-billion-parameter-neural-networks.pdf)
* [Understanding Neural Networks Through Deep Visualization](http://yosinski.com/deepvis)
  * ["Understanding Neural Networks Through Deep Visualization" (2015), J. Yosinski et al](http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf)
  * [github.com/yosinski/deep-visualization-toolbox](https://github.com/yosinski/deep-visualization-toolbox)
* [Interactive Deep Neural Net Hallucinations (+source code) Large Scale Deep Neural Net visualizing top level features](https://317070.github.io/Dream/)
* [Neural Network for Concrete Strength using R](http://andersonjo.github.io/neural-network/2015/07/25/Neural-Network-for-concrete/)
* [fann.js - FANN compiled through Emscripten](https://github.com/louisstow/fann.js/)
* [neurogram - Creating abstract art by evolving neural networks in Javascript](http://blog.otoro.net/2015/07/31/neurogram/)
* [NeuroBind--Yet Another Model for Finding Binding Sites Using Neural Networks](https://github.com/Kyubyong/neurobind)
* [Neural Network for Concrete Strength using R](http://andersonjo.github.io/neural-network/2015/07/25/Neural-Network-for-concrete/)
* [Recent Trends in Neural Net Policy Learning](http://www.slideshare.net/samchoi7/recent-trends-in-neural-net-policy-learning)
* [neural networks by browser](http://neurovis.dataphoric.com/)
* [Scalable Bayesian Optimization Using Deep Neural Networks](http://arxiv.org/abs/1502.05700)
* [Bayesian Optimization 개요: 딥러닝 모델의 효과적인 hyperparameter 탐색 방법론 (1)](http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html)
* [Bayesian Optimization 개요: 딥러닝 모델의 효과적인 hyperparameter 탐색 방법론 (2)](http://research.sualab.com/introduction/practice/2019/04/01/bayesian-optimization-overview-2.html)
* [Data Pipeline Hyperparameter Optimization - Alex Quemy](https://www.youtube.com/watch?v=mmoYYACFX0c)
* [Hyperparameter Definition | DeepAI](https://deepai.org/machine-learning-glossary-and-terms/hyperparameter)
* [Derivation of LBFGS Part 1 - Newton’s Method | Dable Tech Blog](https://teamdable.github.io/techblog/Derivation-of-LBFGS-Part-1)
* [Derivation of LBFGS Part 2 - SR1 Method | Dable Tech Blog](https://teamdable.github.io/techblog/Derivation-of-LBFGS-Part-2)
* [Derivation of LBFGS Part 3 - BFGS Method | Dable Tech Blog](https://teamdable.github.io/techblog/Derivation-of-LBFGS-Part-3)
* [Derivation of LBFGS Part 4 - LBFGS Method | Dable Tech Blog](https://teamdable.github.io/techblog/Derivation-of-LBFGS-Part-4)
* [**An implementation of the paper 'A Neural Algorithm of Artistic Style'**](https://github.com/kaishengtai/neuralart)
  * [거장의 그림을 30초만에 만들다: DeepStyle](http://redtea.kr/?b=3&n=951)
* [neural-style - Torch implementation of neural style algorithm](https://github.com/jcjohnson/neural-style)
* [Comparing Artificial Artists](https://medium.com/@kcimc/comparing-artificial-artists-7d889428fce4)
* [Neural Networks, Types, and Functional Programming](http://colah.github.io/posts/2015-09-NN-Types-FP/)
* [**Implementing a Neural Network from Scratch – An Introduction**](http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/)
* [Hacker's guide to Neural Networks](http://karpathy.github.io/neuralnets/)
  * [**해커가 알려주는 뉴럴 네트워크**](https://tensorflowkorea.wordpress.com/2016/09/13/%ED%95%B4%EC%BB%A4%EA%B0%80-%EC%95%8C%EB%A0%A4%EC%A3%BC%EB%8A%94-%EB%89%B4%EB%9F%B4-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/)
* [neural-network-papers](https://github.com/robertsdionne/neural-network-papers)
* [Pedestrian detection using convolutional neural networks](http://www.diva-portal.org/smash/get/diva2:839692/FULLTEXT01.pdf)
* [Scalable Distributed DNN Training Using Commodity GPU Cloud Computing](https://drive.google.com/file/d/0B6dKRGPLFSd0UGNOYkNaSC1UZTA/view)
* [Deep Style: Inferring the Unknown to Predict the Future of Fashion](http://multithreaded.stitchfix.com/blog/2015/09/17/deep-style/)
* [DeepHear - Composing and harmonizing music with neural networks](http://web.mit.edu/felixsun/www/neural-music.html)
* [Why are Eight Bits Enough for Deep Neural Networks?](http://petewarden.com/2015/05/23/why-are-eight-bits-enough-for-deep-neural-networks/)
* [Neural Net in C++ Tutorial](https://vimeo.com/19569529)
* [A too naive approach to video compression using artificial neural networks](https://github.com/Dobiasd/articles/blob/master/a_too_naive_approach_to_video_compression_using_artificial_neural_networks.md)
* [An interactive introduction to neural network](http://neurovis.mitchcrowe.com/)
* [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch)
* [Skynet for Beginners - Using a Neural Network to Train a Ruby Twitter bot](http://www.fullstackfest.com/agenda/skynet-for-beginners-using-a-neural-network-to-train-a-ruby-twitter-bot)
* [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)
  * [그림으로 이해하는 뉴럴 네트워크 학습과정 1편](https://brunch.co.kr/@chris-song/19)
  * [그림으로 이해하는 뉴럴 네트워크 학습과정 2편](https://brunch.co.kr/@chris-song/20)
* [Deep Neural Network with Pre-training](http://enginius.tistory.com/607)
* [Build your own neural network classifier in R](http://junma5.weebly.com/data-blog/build-your-own-neural-network-classifier-in-r)
* [GNU Gneural Network](https://www.gnu.org/software/gneuralnetwork/)
* [Neural Networks Demystified](http://lumiverse.io/series/neural-networks-demystified)
* [colornet](https://techstory.shma.so/colornet-c10ec398cd45)
* [Sketch-simplifying neural network lets artists leap from pencil to ink](http://boingboing.net/2016/04/28/sketch-simplifying-neural-netw.html)
* [Neural Networks Are Impressively Good At Compression](https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/)
* [An Analysis of Deep Neural Network Models for Practical Applications](https://arxiv.org/pdf/1605.07678v1.pdf)
* [Why are Eight Bits Enough for Deep Neural Networks?](https://petewarden.com/2015/05/23/why-are-eight-bits-enough-for-deep-neural-networks/)
* [Adventures learning Neural Nets and Python](http://katbailey.github.io/post/neural-nets-in-python/)
* [Deep Learning in Neural Networks: An Overview](http://arxiv.org/abs/1404.7828)
* [Using Neural Networks With Regression](http://deeplearning4j.org/linear-regression.html)
* [How To Interpret R-squared and Goodness-of-Fit in Regression Analysis](https://www.datasciencecentral.com/profiles/blogs/regression-analysis-how-do-i-interpret-r-squared-and-assess-the)
* [Neural networks for algorithmic trading. Part One — Simple time series forecasting](https://medium.com/@alexrachnog/neural-networks-for-algorithmic-trading-part-one-simple-time-series-forecasting-f992daa1045a)
* [Deep Learning using Deep Neural Networks](https://www.linkedin.com/pulse/deep-learning-using-neural-networks-niraj-kumar)
* [K-Fold Cross-Validation for Neural Networks](https://jamesmccaffrey.wordpress.com/2013/10/25/k-fold-cross-validation-for-neural-networks/)
* [데이터 분할과 교차 검증 | Pega Devlog](https://jehyunlee.github.io/2022/06/15/Python-DS-104-kierlecture3/) stratified k fold, cross validation
* [What is the Role of the Activation Function in a Neural Network?](http://www.kdnuggets.com/2016/08/role-activation-function-neural-network.html)
  * 신경망에서 activation 함수와 cost(또는 loss, target, objective) 함수는 별개
    * Activation함수, cost함수에 어떤 심오한 (과학적) 의미는 없고, 그냥 인공 신경망을 잘 동작시키기 위해 만든 함수
  * Activation 함수
    * 개별 뉴런에 적용
    * 그 뉴런에 들어온 입력(들)의 합을 출력으로 바꾸는 역할
    * 입력을 그냥 scale 정도 해서 그대로 출력으로 내 보내는 linear 타입, sigmoid 타입, hyperbolic tangent 타입이 존재
  * Cost/loss 함수
    * activation 함수와는 별개로 보통은 신경망 전체에 적용
    * NN이 weight나 bias를 학습할 때 (최적화 할 때) 지표 (metric)이 되는 함수
    * weight, bias를 변수로 갖고 있고, 보통 이 loss/cost를 낮추는 (함수가 에러/cost를 나타낼 때, gradient descent (gradient 반대 방향) 또는 높이는 방향 (함수가 장점/merit을 나탸낼 때, gradient 방향) 으로 만드는 weight(bias)를 계산
    * Sigmoid activation 함수는 초기부터 사용
      * Squared Error 타입 cost 함수와 같이 쓰면 saturation 발생(입력이 매우 negative, 또는 positive 여서 activation이 0 또는 1에 가까울 때), 초기화 잘못으로 학습이 거의 일어나지 않음
    * Cross-entropy loss 함수같은 것은 sigmoid neuron에 대해 써도 이런 saturation 문제 미발생
    * (linear 타입) Relu 를 쓰면, Squared Error 타입 loss 함수를 써도 saturation 미발생
    * [왜 크로스-엔트로피를 쓸까?](https://www.youtube.com/watch?v=srdDQr07sGg)
* [Visualising Activation Functions in Neural Networks](https://dashee87.github.io/data%20science/deep%20learning/visualising-activation-functions-in-neural-networks/)
* [How do you visualize neural network architectures?](https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures)
* [Sketch Simplification](http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/)
* [Neural Network-based Sketch Simplification](http://hi.cs.waseda.ac.jp:8081/)
* [논문 요약 - Deep Neural Networks for YouTube Recommendations](http://keunwoochoi.blogspot.com/2016/09/deep-neural-networks-for-youtube.html)
* [Neural Network Architectures](https://culurciello.github.io/tech/2016/06/04/nets.html)
* [THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)
  * [번역](https://www.facebook.com/SKTBrain/photos/pcb.306040569766764/306035899767231/?type=3&theater)
* [10 misconceptions about Neural Networks](http://www.turingfinance.com/misconceptions-about-neural-networks/)
* [딥러닝_Neural Network_멀티 퍼셉트론1](http://m.blog.naver.com/dunopiorg/220180453865)
* [인공지능(뉴럴 네트워크) 베토벤 월광소나타 훈련시키기](http://blog.naver.com/atelierjpro/220851418829)
* [Four Experiments in Handwriting with a Neural Network](http://distill.pub/2016/handwriting/)
* [Neural Network Architectures](https://culurciello.github.io/tech/2016/06/04/nets.html)
* [CorrNet - an implementation of Correlational Neural Network (CorrNet)](https://github.com/jskDr/CorrNet)
* [Coding a Deep Neural Network to Steer a Car: Step By Step](https://medium.com/udacity/coding-a-deep-neural-network-to-steer-a-car-step-by-step-c075a12108e2)
* [World Models Experiments](http://blog.otoro.net/2018/06/09/world-models-experiments/)
* [뉴럴네트워크, 그것이 알고싶다](https://medium.com/@deepvalidation/%EB%89%B4%EB%9F%B4%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B7%B8%EA%B2%83%EC%9D%B4-%EC%95%8C%EA%B3%A0%EC%8B%B6%EB%8B%A4-8de810a97e69)
* [Stuttgart Neural Network Simulator](http://www.ra.cs.uni-tuebingen.de/SNNS/)
* Spiking Neural Network
  * [SNN Basic Tutorial 1 Spiking Neural Network란 | Euijin's blog](https://jinprelude.github.io/posts/SNN-Basic-Tutorial-1-Spiking-Neural-Network%EB%9E%80/)
  * [SNN Basic Tutorial 2 SNN을 위한 기초 뇌과학 | Euijin's blog](https://jinprelude.github.io/posts/SNN-Basic-Tutorial-2-SNN%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B8%B0%EC%B4%88-%EB%87%8C%EA%B3%BC%ED%95%99/)
  * [SNN Basic Tutorial 3 SNN을 위한 회로이론(1): 기초 | Euijin's blog](https://jinprelude.github.io/posts/SNN-Basic-Tutorial-3-SNN%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%9A%8C%EB%A1%9C%EC%9D%B4%EB%A1%A0(1)-%EA%B8%B0%EC%B4%88/)
  * [SNN Basic Tutorial 4 SNN을 위한 회로이론(2): RC회로 | Euijin's blog](https://jinprelude.github.io/posts/SNN-Basic-Tutorial-4-SNN%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%9A%8C%EB%A1%9C%EC%9D%B4%EB%A1%A0(2)-RC%ED%9A%8C%EB%A1%9C/)
  * [SNN Basic Tutorial 5 Leaky Integrate and Fire(LIF) 모델 설명 | Euijin's blog](https://jinprelude.github.io/posts/SNN-Basic-Tutorial-5-Leaky-Integrate-and-Fire-%EB%AA%A8%EB%8D%B8-%EC%84%A4%EB%AA%85/)
* [How to Choose a Neural Network](https://deeplearning4j.org/neuralnetworktable.html)
* [Neural Network 개선](https://www.nextobe.com/single-post/2017/05/11/Neural-Network-%25EA%25B0%259C%25EC%2584%25A0)
* [Using Machine Learning to Explore Neural Network Architecture](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)
* [COMMON REPRESENTATION LEARNING USING DEEP CORRNET](https://deeplearn.school.blog/2017/05/24/common-representation-learning-using-deep-corrnet/)
* [A simple neural network module for relational reasoning](https://arxiv.org/pdf/1706.01427.pdf)
  * 스탠포드와 FAIR이 발표한, 구성 언어 및 초등 시각 추론을 위한 진단 데이터 세트(CLEVR)
    * [cs.stanford.edu/people/jcjohns/clevr](http://cs.stanford.edu/people/jcjohns/clevr/)
    * [arxiv.org/pdf/1612.06890.pdf](https://arxiv.org/pdf/1612.06890.pdf)
  * 관련연구 : 시각 추리를 위한 프로그램 추론 및 실행
    * [cs.stanford.edu/people/jcjohns/iep](http://cs.stanford.edu/people/jcjohns/iep/)
    * [arxiv.org/pdf/1705.03633.pdf](https://arxiv.org/pdf/1705.03633.pdf)
    * [github.com/facebookresearch/clevr-iep](https://github.com/facebookresearch/clevr-iep)
  * 순수한 텍스트기반 QnA 데이터세트인 페이스북의 bAbI
    * [research.fb.com/downloads/babi](https://research.fb.com/downloads/babi/)
    * [github.com/facebook/bAbI-tasks](https://github.com/facebook/bAbI-tasks)
  * [keras implementation of A simple neural network module for relational reasoning https://arxiv.org/pdf/1706.01427.pdf ](https://github.com/Alan-Lee123/relation-network)
  * [PR-018: A Simple Neural Network Module for Relational Reasoning (DeepMind)](https://www.youtube.com/watch?v=Lb1PVpFp9F8)
  * [Relation Networks for Visual QA](https://tykimos.github.io/Keras/2017/06/10/Relation_Network/)
  * [DeepMind’s Relational Reasoning Networks — Demystified](https://hackernoon.com/deepmind-relational-networks-demystified-b593e408b643)
  * [DeepMind's AI Learns Superhuman Relational Reasoning | Two Minute Papers #168](https://www.youtube.com/watch?v=vzg5Qe0pTKk)
* [**Bridging Relational and Deep Learning**](https://people.cs.kuleuven.be/~sebastijan.dumancic/RelationalDeepLearning/index.html)
* [Learning to Reason with Neural Module Networks](http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/)
* [Self-Normalizing Neural Networks](https://gist.github.com/eamartin/d7f1f71e5ce54112fe05e2f2f17ebedf) 자기 정규화 신경망 이해 및 시각화
* [37 Reasons why your Neural Network is not working](https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607)
  * [37 Reasons why your Neural Network is not working 번역](http://daehoon.tistory.com/2)
* [Understanding Neural Network: A beginner’s guide](https://www.datasciencecentral.com/profiles/blogs/understanding-neural-network-a-beginner-s-guide)
* [A Visual and Interactive Guide to the Basics of Neural Networks](http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)
* [How neural networks are trained](https://ml4a.github.io/ml4a/how_neural_networks_are_trained/)
* [Information Theory of Neural Networks](https://towardsdatascience.com/information-theory-of-neural-networks-ad4053f8e177)
* [Under The Hood of Neural Networks. Part 1: Fully Connected](https://towardsdatascience.com/under-the-hood-of-neural-networks-part-1-fully-connected-5223b7f78528)
* [How Attractive Are You in the Eyes of Deep Neural Network?(https://towardsdatascience.com/how-attractive-are-you-in-the-eyes-of-deep-neural-network-3d71c0755ccc)
* [What Does A Face Detection Neural Network Look Like?](https://towardsdatascience.com/face-detection-neural-network-structure-257b8f6f85d1)
* [Neural Collage - Collaging on Internal Representations: An Intuitive Approach for Semantic Transfiguration](https://github.com/quolc/neural-collage)
* [One neural network, many uses](https://towardsdatascience.com/one-neural-network-many-uses-image-captioning-image-search-similar-image-and-words-in-one-model-1e22080ce73d)
* [Are Deep Neural Networks Dramatically Overfitted?](https://lilianweng.github.io/lil-log/2019/03/14/are-deep-neural-networks-dramatically-overfitted.html)
* [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe)
  * [인공신경망 학습 레시피 (번역)](https://medium.com/@bntejn/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5-%EB%A0%88%EC%8B%9C%ED%94%BC-%EB%B2%88%EC%97%AD-70c5e58341ec?sk=f53042d49fa609d30c80e26f2f7f6b41)
* [First neural network for beginners explained (with code)](https://towardsdatascience.com/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf)
* [simple-neural-networks/simple_nn.py](https://github.com/positive235/simple-neural-networks/blob/master/simple_nn.py)
* [뉴럴 네트워크와 딥러닝](https://sihyeon-kim.github.io/neural-networks-and-deep-learning-korean/index.html)
* [Hacking Neural Networks: A Short Introduction](https://github.com/Kayzaks/HackingNeuralNetworks)
* [Teaching a neural network to use a calculator](https://reiinakano.com/2019/11/12/solving-probability.html)
* [Neural Network (NN) Streamer, Stream Processing Paradigm for Neural Network Apps/Devices](https://github.com/nnsuite/nnstreamer)
* [Uber Creates Generative Teaching Networks to Better Train Deep Neural Networks](https://www.kdnuggets.com/2020/01/uber-generative-teaching-networks-train-neural-networks.html)
* [Neural Network Acceleration Study](https://github.com/ConstantPark/Nerual-Network-Acceleration)
* [Neural-Network-Acceleration-2: Neural Network Acceleration using CPU/GPU, ASIC, FPGA](https://github.com/ConstantPark/Neural-Network-Acceleration-2)
  * [Neural_Acceleration_Study - YouTube](https://www.youtube.com/channel/UCh05O9mScsWVaP3EWX1AKDQ/videos)
* [Neural Networks from Scratch with Python Code and Math in Detail— I | by Towards AI Team | Towards AI — Multidisciplinary Science Journal | Jun, 2020 | Medium](https://medium.com/towards-artificial-intelligence/building-neural-networks-from-scratch-with-python-code-and-math-in-detail-i-536fae5d7bbf)
* [Building Neural Networks with Python Code and Math in Detail — II | by Towards AI Team | Towards AI — Multidisciplinary Science Journal | Jun, 2020 | Medium](https://medium.com/towards-artificial-intelligence/building-neural-networks-with-python-code-and-math-in-detail-ii-bbe8accbf3d1)
* [Python 신경망 학습 (1) : 네이버 블로그](https://blog.naver.com/eunseong31/221590935770)
* [Python 신경망 학습 (2) : 네이버 블로그](https://blog.naver.com/eunseong31/221597561463)
* [Python 신경망 학습 (3) : 네이버 블로그](https://blog.naver.com/eunseong31/221598016421)
* [Neural Networks from Scratch - an interactive guide](https://aegeorge42.github.io/) 뉴럴넷을 배울 수 있도록 단계별로 진행해 볼 수 있는 인터렉티브 가이드
* [신경망(neural networks)에서 편향(bais)의 역할 - 멈춤보단 천천히라도](https://webnautes.tistory.com/1655)
* [Brain.js: GPU accelerated Neural Networks in JavaScript](https://brain.js.org/)
* [nnstreamer: Neural Network (NN) Streamer, Stream Processing Paradigm for Neural Network Apps/Devices](https://github.com/nnstreamer/nnstreamer)
* [nntrainer: NNtrainer is Software Framework for Training Neural Network Models on Devices](https://github.com/nnstreamer/nntrainer)
* [Tools-to-Design-or-Visualize-Architecture-of-Neural-Network: Tools to Design or Visualize Architecture of Neural Network](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)
* [triton: Development repository for the Triton language and compiler](https://github.com/openai/triton)
  * [Introducing Triton: Open-Source GPU Programming for Neural Networks](https://www.openai.com/blog/triton/)

## Neural Network ConvNets CNN
* [컨볼루셔널 뉴럴넷 (Convolutional Neural Network)](http://t-robotics.blogspot.com/2016/05/convolutional-neural-network_31.html)
  * [ConvNet을 시계열 데이터에 적용하는 세가지 방법](https://www.facebook.com/terryum/posts/10154337242359417)
    * Convolutional Neural Network (ConvNet, 또는 CNN)은 원래는 2D 이미지를 인식하기 위해 만듦
      * 뛰어난 성능에 다른 영역에서도 점점 CNN을 적용
      * CNN은 기본적으로 shared parameter를 통해 계산량을 줄이는 동시에 overfitting도 완화해주고 더욱 유용한 피쳐를 생성해주는 등 classification에 좋음
    * 이것을 시계열 데이터(time-series data)에 적용하려면 기본적으로 각각의 데이터마다 길이가 다른 문제를 해결해야 함
      * 예를 들어 음성인식을 한다고 하면 각각 단어마다 길이가 다른데, 뉴럴넷은 기본적으로 고정된 사이즈의 벡터를 인풋으로 받는다는 것이 문제
    * 가장 간단한 해결책은 아마 fixed size window를 슬라이딩하면서 적용하는 것
      * 예를 들어 길이가 하나는 1000이고, 하나는 1200이라면 사이즈 100짜리 윈도우로 각각 10개, 12개의 벡터들을 뽑고 각각을 독립된 예제들로 간주
    * 하지만 이건 그렇게 좋은 방법은 아님
      * 왜냐하면 어떤건 앞쪽 부분을 보고, 어떤건 가운데를 보고, 어떤건 뒤쪽을 보는데 이들을 모두 같은 데이터로 학습해야하기 때문
      * 물론 이 데이터 위에 RNN과 같은 것을 쌓을 수도 있겠지만, 암튼 이건 좀 bruteforce
    * 음성인식에선 이것을 HMM을 통해 해결
      * 딥러닝이 나오기 이전, 음성인식은 보통 HMM-GMM (Hidden Markov Model - Gaussian Mixture Model)을 이용해 해결
      * 아주 간단히 말해 연속된 데이터를 몇 개의 Gaussian의 states로 모델링하고 이를 학습
      * 최근의 딥러닝의 도입은 GMM을 딥러닝으로 대체함으로서 GMM-DNN모델을 제시
    * CNN을 음성인식에 적용하는 기본적인 방법은 먼저 HMM-GMM을 통해 대략의 states를 학습한 후 GMM을 CNN으로 대체해 다시 학습
      * 이렇게 하면 기존엔 아주 많은 윈도우를 각각 학습했어야 하는 것과 달리, 이제는 적절한 크기의 states들만 학습하면 됨
    * 자연어처리에선 max pooling over time을 통해 이 문제를 해결
      * 예를 들어 "나는 오늘 아침에 학교에 갔어요"란 문장을 배운다면 Convolution window를 (나는, 오늘), (나는, 오늘, 아침에), (오늘, 아침에) 등등에 적용한 이후 각각의
윈도우로부터 딱 한 개의 값들만을 max pool
      * 이렇게 하면 만약 feature map의 갯수만 같다면 원래 문장의 길이와는 상관없이 동일한 길이의 벡터가 추출
        *  각각의 피쳐맵에서 딱 한 개씩만 값들을 추출하기 때문
      * 이걸 마지막에 기본 뉴럴넷(FFNN)에 넣음으로서 문장 분류와 같은 일을 함
    * 음성인식과 자연어처리가 다른 점
      * 자연어처리(문장 분류)는 이미 문장 단위로 segment 되어있는 상태에서 다른 길이들을 처리
      * 음성인식은 연속적인 데이터에서 임의로 states를 나누는 경우라는 점
    * [Convolutional neural networks for speech recognition (2014)](http://research-srv.microsoft.com/…/…/TASLP2339736-proof.pdf)
    * [Convolutional neural networks for sentence classification (2014)](http://arxiv.org/pdf/1408.5882)
    * [1509.01626 Character-level Convolutional Networks for Text Classification](http://arxiv.org/abs/1509.01626) 자연어를 word 단위로 보는 것이 아니라 character 단위로 보고 마치 한글자 한글자를 웨이브의 한 점처럼 생각
    * Max over time pooling같은 경우 대부분의 sentence classification류의 문제에서 '실용적으로' 잘 동작
      * 굳이 한계점을 꼽자면 feature가 (예로 들어주신 것 처럼, '나는 오늘'과 같은 단어들을 검출할거라고 예상되는) 문장 내에서 나왔는지/없었는지만을 볼 수 있고, 몇 번 나왔는지는 알 수 없다는 단점
      * 따라서, 긴 문장, 혹은 대화/문서까지를 다룬다고 하면 feature extractor로써 적절하지 않을 것
      * 이를 조금 보완한 것이 [dynamic k-max pooling](http://www.aclweb.org/anthology/P14-1062)
    * 시계열을 다룰때는 (음성인식이나, 자연어처리나) RNN이 더 적합하다고 생각
      * 물론 task가 단순하고, 데이터가 적다면 CNN이나 심지어는 전통적인 TF-IDF방법이 더 좋은 경우도 있음
* [My 1st Kaggle ConvNet: Getting to 3rd Percentile in 3 months](http://ilyakava.tumblr.com/post/125230881527/my-1st-kaggle-convnet-getting-to-3rd-percentile)
* [Image Scaling using Deep Convolutional Neural Networks](http://engineering.flipboard.com/2015/05/scaling-convnets/)
* [cs.stanford.edu/people/karpathy/convnetjs](http://cs.stanford.edu/people/karpathy/convnetjs/)
  * [ConvnetJS demo: Image "Painting"](http://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html)
  * [ConvNetJS CIFAR-10 demo](http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)
* [Fast Convolutional Nets With fbfft: A GPU Performance Evaluation](https://research.facebook.com/publications/695244360582147/fast-convolutional-nets-with-fbfft-a-gpu-performance-evaluation/)
* [Learning Game of Life with a Convolutional Neural Network](http://danielrapp.github.io/cnn-gol/)
* [A Tutorial on Deep Learning Part 2: Autoencoders, Convolutional Neural Networks and Recurrent Neural Networks](http://www-cs.stanford.edu/~quocle/tutorial2.pdf)
* [Texture Synthesis with Convolutional Neural Networks](http://bethgelab.org/deeptextures/)
* [Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)
* [Convolutional Neural Network (CNN)](http://enginius.tistory.com/608)
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/syllabus.html)
  * [Convolutional Neural Networks (CNNs / ConvNets)](http://cs231n.github.io/convolutional-networks/)
  * [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)
  * [archive.org/download/cs231n-CNNs](https://archive.org/download/cs231n-CNNs)
  * [Andrej Karpathy](https://www.youtube.com/channel/UCPk8m_r6fkUSYmvgCBwq-sw)
  * [CS231n : Neural Networks Part 1: Setting up the Architecture (한국어 번역)](http://ishuca.tistory.com/381)
  * [CS231n Winter 2016 Lecture 4 Backpropagation, Neural Networks 1-Q_UWHTY_TEQ.mp4](https://www.youtube.com/watch?v=GZTvxoSHZIo&t=1h11m38s)
  * [Visualizing what ConvNets learn](http://cs231n.github.io/understanding-cnn/)
  * [CS231n/Module 1: Neural Networks](http://ishuca.tistory.com/category/CS231n/Module%201%3A%20Neural%20Networks)
  * [CONVOLUTIONAL NEURAL NETWORKS FOR VISUAL RECOGNITION](http://online.stanford.edu/course/convolutional-neural-networks-visual-recognition)
  * [DSBA CS231n](https://www.youtube.com/playlist?list=PLetSlH8YjIfXMONyPC1t3uuDlc1Mc5F1A)
  * [cs231n_2017_lecture8.pdf](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf)
  * [github.com/Curt-Park/cs231n_assignments](https://github.com/Curt-Park/cs231n_assignments)
  * [Course Project Reports: Spring 2017](http://cs231n.stanford.edu/reports.html)
  * [Lecture Collection | Convolutional Neural Networks for Visual Recognition (Spring 2017)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
  * [github.com/cthorey/CS231](https://github.com/cthorey/CS231) numpy만으로 작성
  * [Korean Subtitles for CS231N Spring 2017](https://github.com/insurgent92/CS231N_17_KOR_SUB)
  * [Assignments CS231N: Convolutional Neural Networks for Visual Recognition (2016 & 2017)](https://github.com/Curt-Park/cs231n_assignments)
  * [딥러닝기반영상분석 (cs231n)](https://www.youtube.com/playlist?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5)
  * [CS231N 2017 video subtitles translation project for Korean Computer Science students](https://github.com/insurgent92/CS231N_17_KOR_SUB)
  * [CS231n Convolutional Neural Networks for Visual Recognition](http://aikorea.org/cs231n/neural-networks-2-kr/) 번역
  * [CS231n Generative Models (1) - AutoEncoder, Variational AutoEncoder(VAE)](https://ahjeong.tistory.com/2)
  * [CS231n Generative Models (2) - GAN](https://ahjeong.tistory.com/3)
  * [excelsior-cjh.tistory.com/category/DeepLearning/개념](https://excelsior-cjh.tistory.com/category/DeepLearning/%EA%B0%9C%EB%85%90)
  * [CS231n Summary - TaeYoung’s Blog](https://taeyoung96.github.io/categories/CS231n/)
* [Implementing a CNN for Text Classification in TensorFlow](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)
* [Case Study of Convolutional Neural Network](http://www.slideshare.net/nmhkahn/case-study-of-convolutional-neural-network-61556303)
* [Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)
* [Kashif Rasul - Intro to ConvNets](https://www.youtube.com/watch?v=W9_SNGymRwo)
* [CNN(Convolution Neural Network)으로 인물을 인식 시켜보자](https://github.com/jaeho-kang/deep-learning/blob/master/blog/post1/contents.md)
* [VGG Convolutional Neural Networks Practical](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/)
* [Q Learning과 CNN을 이용한 Object Localization](http://www.slideshare.net/ssuser06e0c5/q-learning-cnn-object-localization)
* [Benchmarks for popular CNN models](https://github.com/jcjohnson/cnn-benchmarks)
* [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)
  * [번역 A Beginner's Guide To Understanding Convolutional Neural Networks](http://steady7.tistory.com/m/7)
* [A Beginner's Guide To Understanding Convolutional Neural Networks Part 2](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)
  * [번역 A Beginner's Guide To Understanding Convolutional Neural Networks Part 2](http://steady7.tistory.com/8)
* [The 9 Deep Learning Papers You Need To Know About (Understanding CNNs Part 3)](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)
* [Faster R-CNN in MXNet with distributed implementation and data parallelization](https://github.com/dmlc/mxnet/tree/master/example/rcnn)
* [Faster R-CNN](https://curt-park.github.io/2017-03-17/faster-rcnn/)
* [Snagging Parking Spaces with Mask R-CNN and Python](https://medium.com/@ageitgey/snagging-parking-spaces-with-mask-r-cnn-and-python-955f2231c400)
* [A guide to convolution arithmetic for deep learning](https://tensorflowkorea.wordpress.com/a-guide-to-convolution-arithmetic-for-deep-learning/)
* [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)
* [An Intuitive Explanation of Convolutional Neural Networks](https://www.opendatascience.com/blog/an-intuitive-explanation-of-convolutional-neural-networks)
* [‘구글 맵’ 영상에 AI 접목하니, 빈곤국가 경제실태 한눈에](http://www.dongascience.com/news/view/13461)
* [Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721)
* [Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78)
* [NeoCognitron](https://youtu.be/Qil4kmvm2Sw)
  * [1980년 논문: Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position](http://www.cs.princeton.edu/…/co…/Readings/Fukushima1980.pdf)
  * [홈페이지](http://personalpage.flsi.or.jp/fukushima/)
  * [Scholarpedia](http://www.scholarpedia.org/article/Neocognitron)
* GCN
  * [GRAPH CONVOLUTIONAL NETWORKS](http://tkipf.github.io/graph-convolutional-networks/)
  * [How do we capture structure in relational data?](https://thegradient.pub/structure-learning/)
  * [Graph Convolutional Networks for relational graphs](https://github.com/tkipf/relational-gcn) keras
  * [Graph Convolutional Neural Networks](https://www.slideshare.net/uspace/graph-convolutional-neural-networks)
  * [How to do Deep Learning on Graphs with Graph Convolutional Networks](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780)
  * [Graph Convolutional Networks using only NumPy - YouTube](https://www.youtube.com/watch?v=8qTnNXdkF1Q)
  * [Spectral GCN 은… 사드세요 - TooTouch](https://tootouch.github.io/research/spectral_gcn/)
  * [Graph Neural Network 찍어먹기 - TooTouch](https://tootouch.github.io/research/gnn_summary/)
  * [How Powerful are Graph Neural Networks? - Graph ML review](https://harryjo97.github.io/paper%20review/How-Powerful-are-Graph-Neural-Networks/)
  * [**DGL-tutorial: 그래프 딥러닝 라이브러리 DGL 쉽게 배우기**](https://github.com/myeonghak/DGL-tutorial)
  * [Graph Machine Learning at Airbnb. How Airbnb is leveraging graph neural… | by Devin Soni | The Airbnb Tech Blog | Jun, 2022 | Medium](https://medium.com/airbnb-engineering/graph-machine-learning-at-airbnb-f868d65f36ee)
* [Graph Nets - DeepMind's library for building graph networks in Tensorflow and Sonnet](https://github.com/deepmind/graph_nets)
* [How Uber uses Graph Neural Networks to recommend you food (live stream) - YouTube](https://www.youtube.com/watch?v=9O9osybNvyY)
* [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)
* [Representative graph neural network Review!! - YouTube](https://www.youtube.com/watch?v=z-UUq8x1oRw)
* [Intro to graph neural networks (ML Tech Talks) - YouTube](https://www.youtube.com/watch?v=8owQBFAHw7E)
* [Classifying Documents on a Graph using GNNs - Avi Aminov | PyData Global 2021 - YouTube](https://www.youtube.com/watch?v=61qoxP7t0EI)
* [알잘딱깔센 추천 모델 만들기 — GNN을 활용한 요기요의 추천 모델 YoSEMITE | by Kitae Yoon | Jul, 2022 | YOGIYO Tech Blog— 요기요 기술 블로그](https://techblog.yogiyo.co.kr/%EC%95%8C%EC%9E%98%EB%94%B1%EA%B9%94%EC%84%BC-%EC%B6%94%EC%B2%9C-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-gnn%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9A%94%EA%B8%B0%EC%9A%94%EC%9D%98-%EC%B6%94%EC%B2%9C-%EB%AA%A8%EB%8D%B8-yosemite-33b0600d2464)
* [Convolutional neural network in practice](http://www.slideshare.net/ssuser77ee21/convolutional-neural-network-in-practice)
* [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)
* [딥러닝 - 초보자를 위한 컨볼루셔널 네트워크를 이용한 이미지 인식의 이해](http://bcho.tistory.com/1149)
* [딥러닝을 이용한 숫자 이미지 인식 #1/2](http://bcho.tistory.com/1156)
* [딥러닝을 이용한 숫자 이미지 인식 #2/2](http://bcho.tistory.com/1157)
* [Speed/accuracy trade-offs for modern convolutional object detectors](https://arxiv.org/pdf/1611.10012v1.pdf)
  * 구글에서 요즘 나오는 CNN 기반의 object detectors들을 정리
  * Faster R-CNN, R-FCN, SSD 등 디텍션 알고리즘을 다양한 방법으로 실험해 보고 자세히 결과를 리포트
* [CNN VS Preschool Student Eyes](http://loveayase.tumblr.com/post/155708552419/cnn-vs-preschool-student-eyes)
* [DyNet - The Dynamic Neural Network Toolkit](https://github.com/clab/dynet)
* [**CNN 역전파를 이해하는 가장 쉬운 방법 The easist way to understand CNN backpropagation**](https://metamath1.github.io/cnn/index.html)
* [Paints Chainer - line drawing colorizer using chainer. Using CNN, you can colorize your scketch automatically / semi-automatically](https://github.com/taizan/PaintsChainer)
  * [paintschainer.preferred.tech](http://paintschainer.preferred.tech/)
* [Convolutional Neural Networks (CNNs): An Illustrated Explanation](http://xrds.acm.org/blog/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/)
* [CNNs from different viewpoints - Prerequisite: Basic neural networks](https://medium.com/@matthewkleinsmith/cnns-from-different-viewpoints-fab7f52d159c)
* [14 DESIGN PATTERNS TO IMPROVE YOUR CONVOLUTIONAL NEURAL NETWORKS](http://www.topbots.com/14-design-patterns-improve-convolutional-neural-network-cnn-architecture)
* [합성곱 신경망(CNN)](http://astrod.github.io/2017/04/09/%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D(CNN).html)
* [#21. Deformable Convolutional Networks](http://t-robotics.blogspot.kr/2017/04/21-deformable-convolutional-networks.html)
* [#P.1. Deformable Convolutional Networks (2017)]https://www.youtube.com/watch?v=RRwaz0fBQ0Y&list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq)
* [A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN](https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4)
* [Deep Learning #2: Convolutional Neural Networks](https://medium.com/towards-data-science/deep-learning-2-f81ebe632d5c)
* [CNNs in Practice](http://nmhkahn.github.io/CNN-Practice)
* [Conv Nets: A Modular Perspective](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)
  * [Conv Net: 모듈 방식의 관점](https://brunch.co.kr/@chris-song/23)
* [Picasso: A free open-source visualizer for Convolutional Neural Networks](https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-cnns-d8ed3a35cfc5)
* [간단한 구조의 CNN Layer별 시각화](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)
  * handwritten_digit 이미지를 통해 CNN의 각 Layer별로 시각화
  * Input 값으로 직접 그려 넣기 가능
  * CNN에서 각각의 계산과정 특히 Fully Connected Layer을 이해하는데 많은 도움
  * CNN의 여러 Parameter값들을 변경가능해 이를 시각화해줬으면 더 좋았을 것
  * 시각화된 CNN구조

    ```
    handwritten_digit_Input Image : 32x32
    Filter_size = 5x5, stride = 1 , padding = VALID
    pooling = max_pooling(2x2), stride = 2
    activation_function = Tanh
    input -> conv1(6) -> Tanh -> maxpool1 -> conv2(16) -> Tahn -> maxpool2 -> fc1 -> Tanh -> fc2 -> output
    ```
* [Applied Deep Learning 11/03 Convolutional Neural Networks](https://www.slideshare.net/ckmarkohchang/applied-deep-learning-1103-convolutional-neural-networks)
* [A friendly introduction to Convolutional Neural Networks and Image Recognition](https://www.youtube.com/watch?v=2-Ol7ZB0MmU)
* [딥러닝 기반 세차 인증 자동화 모델 개발 이야기 - SOCAR Tech Blog](https://tech.socarcorp.kr/data/2022/04/18/develop-model-classifying-washed-car.html)
* [컨볼루션(Convolution) 이해하기](https://brunch.co.kr/@chris-song/24)
* [CortexNet: Robust Visual Temporal Representations](https://engineering.purdue.edu/elab/CortexNet/)
* [Convolution 종류 설명](https://www.slideshare.net/ssuser06e0c5/convolution-77257148)
* [Deepeyeballers - Ushering in deep learning's foray into the netherworld of eyeballing](https://github.com/vinayprabhu/Deepeyeballers)
  * Scatter2Pearson - 산점도에서 상관 계수를 회귀시키는 CNN 훈련
* [Interpreting (and fooling) convolutional neural networks: Part 1](https://www.jebruner.com/2017/07/interpreting-and-fooling-convolutional-neural-networks-part-1/)
* [Dance Dance Convolution](https://github.com/chrisdonahue/ddc)
* Capsule Networks
  * [Geoffrey Hinton talk "What is wrong with convolutional neural nets ?"](https://www.youtube.com/watch?v=rTawFwUvnLE)
    * [Does the Brain do Inverse Graphics?](http://cseweb.ucsd.edu/~gary/cs200/s12/Hinton.pdf)
  * Understanding Hinton’s Capsule Networks
    * [Part I: Intuition](https://medium.com/@pechyonkin/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b)
    * [Part II: How Capsules Work](https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-ii-how-capsules-work-153b6ade9f66)
    * [Part III: Dynamic Routing Between Capsules](https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-iii-dynamic-routing-between-capsules-349f6d30418)
    * [Part IV: CapsNet Architecture](https://medium.com/@pechyonkin/part-iv-capsnet-architecture-6a64422f7dce)
  * [A Visual Representation of Capsule Network Computations](https://medium.com/@mike_ross/a-visual-representation-of-capsule-network-computations-83767d79e737)
  * [Dynamic Routing Between Capsules - 캡슐 간 동적 라우팅](http://www.python3statement.org/)
  * [Matrix capsules with EM Routing](http://blog.naver.com/sogangori/221136950703)
  * [“Understanding Matrix capsules with EM Routing (Based on Hinton's Capsule Networks)”](https://jhui.github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network/)
  * [Capsule Networks Are Shaking up AI  – Here’s How to Use Them](https://www.kdnuggets.com/2017/11/capsule-networks-shaking-up-ai.html)
  * [Capsule Networks](http://www.cedar.buffalo.edu/~srihari/CSE676/9.12%20CapsuleNets.pdf)
  * [Capsule Networks (CapsNets) – Tutorial](https://www.youtube.com/watch?v=pPN8d0E3900)
  * [How to implement CapsNets using TensorFlow](https://www.youtube.com/watch?v=2Kawrd5szHE)
  * [제프리 힌튼의 캡슐망을 풀이하다](https://brunch.co.kr/@kakao-it/158)
  * [Capsule Networks: An Improvement to Convolutional Networks](https://www.techleer.com/articles/444-capsule-networks-an-improvement-to-convolutional-networks/)
  * [A Nice Easy Tutorial To Follow On Capsule Networks Based On Sabour, Frosst, And Hinton's Paper](https://www.techleer.com/articles/447-a-nice-easy-tutorial-to-follow-on-capsule-networks-based-on-sabour-frosst-and-hintons-paper/)
  * [github.com/Sarasra/models/tree/master/research/capsules](https://github.com/Sarasra/models/tree/master/research/capsules)
  * [**Understanding Capsule Networks — AI’s Alluring New Architecture**](https://medium.freecodecamp.org/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc)
  * [CapsNet-Visualization - A visualization of the CapsNet layers to better understand how it works](https://github.com/bourdakos1/CapsNet-Visualization)
* [How do CNNs Deal with Position Differences?](https://petewarden.com/2017/10/29/how-do-cnns-deal-with-position-differences/)
* [Slides for paper “the effects of noisy labels on deep convolutional neural networks for music tagging”](https://keunwoochoi.wordpress.com/2017/11/04/slides-for-paper-the-effects-of-noisy-labels-on-deep-convolutional-neural-networks-for-music-tagging/)
* [A tutorial on deep learning for music information retrieval (dl4mir) slides, paper](https://keunwoochoi.wordpress.com/2017/11/02/a-tutorial-on-deep-learning-for-music-information-retrieval-dl4mir-slides-paper/)
* [CNN in numpy](http://chris-chris.ai/2017/11/26/conv-in-numpy/)
* [Only Numpy: Understanding Back Propagation for Transpose Convolution in Multi Layer CNN with Example and Interactive Code](https://towardsdatascience.com/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981)
* [Let’s code a Neural Network in plain NumPy](https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795)
* [Convolution operation in Neural Network](http://blog.naver.com/suma_maple/221181408813)
* [컨벌루션 뉴런 네트워크(CNN) 란 무엇인가?](http://www.aitimes.kr/news/articleView.html?idxno=11294)
* [ResNet, AlexNet, VGG, Inception: Understanding various architectures of Convolutional Networks](http://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/)
* [A guide to receptive field arithmetic for Convolutional Neural Networks](https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807)
* [Convolutional Neural Network — I](https://towardsdatascience.com/cnn-part-i-9ec412a14cb1)
* [Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)
* [A guide to receptive field arithmetic for Convolutional Neural Networks](https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807)
* [cnn-watermark-removal - Fully convolutional deep neural network to remove transparent overlays from images](https://github.com/marcbelmont/cnn-watermark-removal)
* [Convolutional Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)
* [1.1 Questions to the Convolutional Neural Networks](https://www.youtube.com/watch?v=LHA_rpE1ERY)
* [Gentle Dive into Math Behind Convolutional Neural Networks](https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)
* [Everything you need to know to master Convolutional Neural Networks](https://medium.freecodecamp.org/everything-you-need-to-know-to-master-convolutional-neural-networks-ef98ca3c7655)
* [합성곱 신경망에서 컨벌루션과 트랜스포즈드 컨벌루션의 관계 Relationship between Convolution and Transposed Convolution in CNN](https://metamath1.github.io/2019/05/09/transconv.html)
* [Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)
* [Convolutional Neural Networks from the ground up](https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1)
* [Convolutional Neural Networks: The Biologically-Inspired Model](https://medium.com/cracking-the-data-science-interview/convolutional-neural-networks-the-biologically-inspired-model-9b7e948f6987)
* [CNN에서 pooling이란?](https://medium.com/@hobinjeong/cnn에서-pooling이란-c4e01aa83c83)
* [assembled-cnn - Official implementation of "Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network"](https://github.com/clovaai/assembled-cnn)
* [CNN으로 TWICE 다현과 ITZY 예지를 구분할 수 있을까? — Intro](https://medium.com/@hslee09/python-cnn%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%97%B0%EC%98%88%EC%9D%B8-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-intro-5dffca629097)
* [CNN으로 TWICE 다현과 ITZY 예지를 구분할 수 있을까? — (1)](https://medium.com/@hslee09/python-cnn%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%97%B0%EC%98%88%EC%9D%B8-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-1-705aee34def4)
* [CNN으로 TWICE 다현과 ITZY 예지를 구분할 수 있을까? — (2)](https://medium.com/@hslee09/python-cnn%EC%9C%BC%EB%A1%9C-twice-%EB%8B%A4%ED%98%84%EA%B3%BC-itzy-%EC%98%88%EC%A7%80%EB%A5%BC-%EA%B5%AC%EB%B6%84%ED%95%A0-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C-2-8d7713ca9aa9)
* [CNN으로 TWICE 다현과 ITZY 예지를 구분할 수 있을까? — (3)](https://medium.com/@hslee09/python-cnn%EC%9C%BC%EB%A1%9C-twice-%EB%8B%A4%ED%98%84%EA%B3%BC-itzy-%EC%98%88%EC%A7%80%EB%A5%BC-%EA%B5%AC%EB%B6%84%ED%95%A0-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C-3-8fd90a321ba9)
* [CNN Explainer](https://poloclub.github.io/cnn-explainer/)
* [2D Visualization of a Convolutional Neural Network](http://www.cs.cmu.edu/~aharley/nn_vis/cnn/2d.html) 숫자를 입력하면 layer별로 그림으로 보여줌
* [ConvNeXt: Code release for ConvNeXt model](https://github.com/facebookresearch/ConvNeXt)

## Neural Network LSTM
* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [엘에스티엠 네트워크 이해하기 (Understanding LSTM Networks)](http://roboticist.tistory.com/m/post/571)
* [GRU & LSTM for machine translations.ipynb](https://github.com/kobikun/study/blob/master/babelpish/GRU_LSTM_for_machine_translation/GRU%20%26%20LSTM%20for%20machine%20translations.ipynb)
* [Backpropogating an LSTM: A Numerical Example](http://blog.aidangomez.ca/2016/04/17/Backpropogating-an-LSTM-A-Numerical-Example/)
* [LSTM Networks for Sentiment Analysis](http://deeplearning.net/tutorial/lstm.html)
* [번역 니코니코동화의 공개코멘트 데이터를 Deep Learning로 해석하기](https://blog.umay.be/2016/06/02/niconico-nlp.html)
  * [わかるLSTM ～ 最近の動向と共に](http://qiita.com/t_Signull/items/21b82be280b46f467d1b)
* [Unsupervised Learning of Video Representations using LSTMs](http://nbviewer.jupyter.org/github/babelpish/deep-elastic/blob/master/part2/paper/unsupervised_lstms_video/Unsupervised_Learning_of_Video_Representations_using_LSTMs.ipynb)
* [LSTMVis - Visual Analysis for Recurrent Neural Networks](http://lstm.seas.harvard.edu/)
* [LSTM(RNN) 소개](https://brunch.co.kr/@chris-song/9)
* [Understanding the new Google Translate](https://codesachin.wordpress.com/2017/01/18/understanding-the-new-google-translate/)
* [Knowing when to look : Adaptive Attention via A Visual Sentinel for Image Captioning](http://www.slideshare.net/ssuser06e0c5/knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning)
  * 본 논문에서는 Hidden layer 뒤에 추가적인 새로운 시각중지 벡터 (visual sentinel vector)를 갖는 LSTM의 확장형을 채택함
  * 시각신호로부터 필요 시 언어모델로 전환이 가능한 Adaptive attention encoder-decoder framework을 제안
  * 이로 인하여 “white”, “bird”, “stop,”과 같은 시각적 단어에 대해서는 좀 더 이미지에 집중하고, “top”, “of”, “on.”의 경우에는 시각중지를 사용함으로서 Image Captioning의 정확도를 향상
  * “Image Captioning”기술은 위성이나 항공영상 분석의 경우 아주 중요한 기술
  * 일반적인 Image Captioning에 비해 예상외로 아주 수월하게 처리가 가능
* [Clickbaits Revisited: Deep Learning on Title + Content Features to Tackle Clickbaits](https://www.linkedin.com/pulse/clickbaits-revisited-deep-learning-title-content-features-thakur)
  * [Clickbaits Revisited](https://github.com/abhishekkrthakur/clickbaits_revisited)
* [Neural Complete](https://github.com/kootenpv/neural_complete)
* [엘에스티엠 네트워크 이해하기](http://whydsp.org/280)
* [Exploring LSTMs](http://blog.echen.me/2017/05/30/exploring-lstms/)
* [**머신러닝 BASIC - RNN과 LSTM에 대해**](http://blog.naver.com/anthouse28/221026536458)
* [딥러닝 기반 기상 예측 모델 연구 사례 (1) : Convolutional LSTM](https://mikigom.github.io/jekyll/update/2017/06/13/deep-learning-forecast-research-1.html)
* [Extreme Event Forecasting with LSTM Autoencoders](https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037)
* [DeepWeather](https://github.com/prl900/DeepWeather)
* [#23. RNN & LSTM](http://t-robotics.blogspot.com/2017/06/23-rnn-lstm.html)
* [RNN : LSTM 구조](https://www.youtube.com/watch?v=3h2tpYWzEa4&t=193s)
* [#6.0. RNN & LSTM](https://www.youtube.com/watch?v=SoNtAjxA3Jo&list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq)
* [RNN & LSTM](http://astrod.github.io/2017/11/26/26.html)
* [NoisyNet-A3C - NoisyNet (LSTM) asynchronous advantage actor-critic (A3C) on the CartPole-v1 environment](https://github.com/Kaixhin/NoisyNet-A3C)
* [RNN and LSTM 01 - stock_data_load.csv](http://beanexpert.tistory.com/entry/RNN-and-LSTM-01-stockdataloadcsv)
* [Evolution: from vanilla RNN to GRU & LSTMs](https://medium.com/towards-data-science/lecture-evolution-from-vanilla-rnn-to-gru-lstms-58688f1da83a)
* [**Vanilla LSTM with numpy**](http://blog.varunajayasiri.com/numpy_lstm.html)
* [LSTM in numpy - Let's calculate LSTMCell in numpy manually](http://chris-chris.ai/2017/10/10/LSTM-LayerNorm-breakdown-eng/)
* [Image recognition using tensorflow in Deep learning | Python | Ajay Jatav](https://www.youtube.com/watch?v=8c0-42U2Rn0)
* [RNN과 LSTM을 이해해보자!](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)
* [왕초보를 위한 RNN](http://nbviewer.jupyter.org/github/bage79/nlp4kor/blob/master/ipynb/RNN_for_beginners.pdf)
* [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)
* [Introduction to Deep Learning Trading in Hedge Funds](https://www.toptal.com/deep-learning/deep-learning-trading-hedge-funds)
* [Stock Price Prediction of Apple Inc. Using Recurrent Neural Network](https://github.com/NourozR/Stock-Price-Prediction-LSTM)
* [The fall of RNN / LSTM](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0)
  * 2D 이미지같은 데이터에는 CNN을 사용하고 시계열 데이터에는 RNN/LSTM/GRU 등을 사용하는 것이 하나의 정석처럼 여겨지지만 RNN 계열의 비효율적인 신경망을 버릴 때가 되었다 + Attention 메커니즘을 가지는 TCN(Temporal convolutional network)이 대안이라는 주장
* [Visualizing LSTM Networks. Part I](https://medium.com/asap-report/visualizing-lstm-networks-part-i-f1d3fa6aace7)
* [Generating Drake Rap Lyrics using Language Models and LSTMs](https://towardsdatascience.com/generating-drake-rap-lyrics-using-language-models-and-lstms-8725d71b1b12)
* [RNN and its applications](https://www.slideshare.net/samchoi7/rnnerica)
* [How to Use the TimeDistributed Layer for Long Short-Term Memory Networks in Python](https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/)
* Exploring LSTMs: Understanding Basics
  * [Part One](https://www.topbots.com/exploring-lstm-tutorial-part-1-recurrent-neural-network-deep-learning)
  * [Part Two](https://www.topbots.com/exploring-lstm-tutorial-part-2-recurrent-neural-network-deep-learning)
* [Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
* [An Introduction to Recurrent Neural Networks](https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912)
* [RNN에서의 alignment 의미와 seq-to-seq 모델](https://dos-tacos.github.io/concept/alignment-in-rnn/)
* [Visualizing memorization in RNNs](https://distill.pub/2019/memorization-in-rnns/)
* [Predicting Trump’s Tweets With A Recurrent Neural Network](https://towardsdatascience.com/predicting-trump-tweets-with-a-rnn-95e7c398b18e)
* [LSTM and Bidirectional LSTM for Regression | by Mohammed Alhamid | Jun, 2021 | Towards Data Science](https://towardsdatascience.com/lstm-and-bidirectional-lstm-for-regression-4fddf910c655)
* [A Brilliant Explanation of LSTM Model | Long Short-Term Memory Model | Deep Learning Tutorial - YouTube](https://www.youtube.com/watch?v=IJ928kZZaQE)

## Neural Network Python
* [A Neural Network in 11 lines of Python (Part 1)](http://iamtrask.github.io/2015/07/12/basic-python-network/)
  * [11줄의 파이썬 코드로 뉴럴 네트워크를 만들어보자](http://ddanggle.github.io/ml/ai/cs/2016/07/16/11lines.html)
* [A Neural Network in 13 lines of Python (Part 2 - Gradient Descent)](http://iamtrask.github.io/2015/07/27/python-network-part2/)
  * [13줄의 파이썬 코드로 뉴럴 네트워크를 만들어보자. (파트2 - 경사하강법)](http://ddanggle.github.io/ml/ai/cs/2016/09/03/13lines.html)
  * [13Lines.ipynb](https://github.com/DDanggle/blogNetwork/blob/master/13Lines.ipynb)
* [파이썬 코딩으로 말하는 데이터 분석 - 6. 경사하강법](http://hamait.tistory.com/747)
* [Hinton's Dropout in 3 Lines of Python](http://iamtrask.github.io/2015/07/28/dropout/)
* [Training (deep) Neural Networks Part: 1](http://upul.github.io/2015/10/12/Training-(deep)-Neural-Networks-Part:-1/)
* [Deep learning – Convolutional neural networks and feature extraction with Python](http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/)
* [Irene Chen A Beginner's Guide to Deep Learning PyCon 2016](https://www.youtube.com/watch?v=nCPf8zDJ0d0)
* [Introduction to Deep Learning with Python](https://www.youtube.com/watch?v=S75EdAcXHKk)
* [A Complete Guide on Getting Started with Deep Learning in Python](https://www.analyticsvidhya.com/blog/2016/08/deep-learning-path/)
* [Python Code Suggestions Using a Long Short-Term Memory RNN](http://blog.algorithmia.com/python-code-suggestions-lstm-rnn)
* [Python for Image Understanding: Deep Learning with Convolutional Neural Nets](http://www.slideshare.net/roelofp/python-for-image-understanding-deep-learning-with-convolutional-neural-nets)
* [Fitting Gaussian Process Models in Python](https://blog.dominodatalab.com/fitting-gaussian-process-models-python/)
  * [Triple Pendulum CHAOS!](http://jakevdp.github.io/blog/2017/03/08/triple-pendulum-chaos/)
* [Gaussian process regression using functional programming](https://github.com/LucaAmbrogioni/Functional-GP-analysis-in-Python/blob/master/Example_Notebook.ipynb)
* [hamait.tistory.com/category/통계&머신러닝&딥러닝](http://hamait.tistory.com/category/%ED%86%B5%EA%B3%84%20%26%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%26%20%EB%94%A5%EB%9F%AC%EB%8B%9D)
  * [파이썬 코딩으로 말하는 데이터 분석 - 6. 경사하강법](http://hamait.tistory.com/747)
* [Understanding and coding Neural Networks From Scratch in Python and R](https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/)
* [Safe Crime Prediction - Homomorphic Encryption and Deep Learning for More Effective, Less Intrusive Digital Surveillance](https://iamtrask.github.io/2017/06/05/homomorphic-surveillance)
* [DEEP LEARNING AND REINFORCEMENT LEARNING SUMMER SCHOOL 2017](https://www.facebook.com/nextobe1/photos/a.313464989089503.1073741829.303538826748786/338217953280873/)
* [How I implemented iPhone X’s FaceID using Deep Learning in Python](https://towardsdatascience.com/how-i-implemented-iphone-xs-faceid-using-deep-learning-in-python-d5dbaa128e1d)
* [Deep Learning with Python](https://towardsdatascience.com/deep-learning-with-python-703e26853820)
* [How to build your own Neural Network from scratch in Python](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)
* [Let’s build a simple Neural Net!](https://becominghuman.ai/lets-build-a-simple-neural-net-f4474256647f)
* [Building a Feedforward Neural Network from Scratch in Python](https://hackernoon.com/building-a-feedforward-neural-network-from-scratch-in-python-d3526457156b)
* [Predict the probability of getting heart disease with a Python neural network](https://medium.com/better-programming/predicting-heart-disease-with-a-neural-network-a48d2ce59bc5)
* [Neural Networks from Scratch in Python - YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3)
* [DeepCreamPy - Decensoring Hentai with Deep Neural Networks](https://github.com/deeppomf/DeepCreamPy)
* [neat-python](https://pypi.python.org/pypi/neat-python/) A NEAT (NeuroEvolution of Augmenting Topologies) implementation
  * [NEAT-Python documentation](https://neat-python.readthedocs.io/)
  * [The NEAT Algorithm is Neat - YouTube](https://www.youtube.com/watch?v=ZC0gMhYhwW0)
* [neon Fast, scalable, easy-to-use Python based Deep Learning Framework by Nervana™ http://neon.nervanasys.com ](https://github.com/NervanaSystems/neon)
* [NeuPy - Neural Networks in Python](http://neupy.com/)
* [Neural Doodle - Use a deep neural network to borrow the skills of real artists and turn your two-bit doodles into masterpieces](https://github.com/alexjc/neural-doodle)
  * [Feed-forward neural doodle](http://dmitryulyanov.github.io/feed-forward-neural-doodle/)
  * [Online neural doodle](https://likemo.net/)
* [ancient-text-restoration - Restoring ancient text using deep learning: a case study on Greek epigraphy](https://github.com/sommerschield/ancient-text-restoration)
  * [Restoring ancient text using deep learning: a case study on Greek epigraphy](https://deepmind.com/research/publications/Restoring-ancient-text-using-deep-learning-a-case-study-on-Greek-epigraphy)

## Neural Network Recurrent Flow Net
* [Recurrent Flow Network on Different Error Rates](https://www.youtube.com/watch?v=twR3wYjwLrM)
  * binary matrix를 입력으로 받아서, 미래의 matrix를 예측하며, 각 cell의 속도 역시 구할 수 있음
  * 예를 들어서 matrx의 1과 0이 해당 공간이 점유됨과 비어있음을 의미하면, 이 네트워크는 무인 자동차와 같은 어플리케이션에서 장애물들의 속도와 미래에 어떻게 움직일지를 예측 가능
  * 구조적으론 재귀 신경망 구조이지만, 기존의 RNN과는 모든 연산과 구조가 다릅니다.
  * 장점
    * 노이즈에 강인. 동영상에서 알 수 있듯이 왼쪽의 입력 matrix에 노이즈가 많이 있어도 오른쪽의 예측된 방향은 꽤나 정확
    * 빠른 속도. 200 * 200의 행렬을 받아 처리하는데 40ms 이하(MATLAB coder 환경)
  * [매트랩 코드](https://github.com/sjchoi86/RecurrentFlowNet)
* [Mobile-robot-simulator - Mobile robot simulator in MATLAB](https://github.com/sjchoi86/Mobile-robot-simulator)
  * [Navigation with Occupancy Flow](https://www.youtube.com/watch?v=Hffzo6-4w24)
* [Where to Apply Dropout in Recurrent Neural Networks for Handwriting Recognition?](https://www.slideshare.net/LeeGyeonghoon/where-to-apply-dropout-in-recurrent-neural-networks-for-handwriting-recognition?ref=https%3A%2F%2Fwww.slideshare.net%2FLeeGyeonghoon%2Fslideshelf)
* [A friendly introduction to Recurrent Neural Networks](https://www.youtube.com/watch?v=UNmqTiOnRfg)

## Neural Network RNN Recurrent Neural Net
* [Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) Baby steps to your neural network's first memories](https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/)
  * [(한글 번역) Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)](http://jaejunyoo.blogspot.com/2017/06/anyone-can-learn-to-code-LSTM-RNN-Python.html)
* [**Awesome Recurrent Neural Networks - A curated list of resources dedicated to recurrent neural networks**](https://github.com/kjw0612/awesome-rnn)
* [**The Unreasonable Effectiveness of Recurrent Neural Networks**](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [opinion mining with deep recurrent nets](http://www.cs.cornell.edu/~oirsoy/drnt.htm)
* [Composing Music With Recurrent Neural Networks](http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/)
* [Composing Music with LSTM Recurrent Networks - Blues Improvisation](http://people.idsia.ch/~juergen/blues/)
* [Training a Recurrent Neural Network to Compose Music](https://maraoz.com/2016/02/02/abc-rnn/)
* [A Recurrent Neural Network Music Generation Tutorial](https://magenta.tensorflow.org/2016/06/10/recurrent-neural-network-generation-tutorial/)
* [How Generative Music Works](https://teropa.info/loop/#/title)
* [Composing Music With Recurrent Neural Networks](http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/)
* [Recurrent neural network (depth=3) generates next 1,000 bytes of "Let It Go":](http://elnn.snucse.org/sandbox/music-rnn/)
* [Recurrent Neural Network Writes Music and Shakespeare Novels | Two Minute Papers](https://www.youtube.com/watch?v=Jkkjy7dVdaY)
* [Music x ICML2019 papers](https://keunwoochoi.wordpress.com/2019/06/24/music-x-icml2019-papers/)
* [My recent talks – Keunwoo Choi](https://keunwoochoi.wordpress.com/2022/01/06/my-recent-talks/)
* [Recurrent Neural Network, Fractal for Deep Learning](http://www.slideshare.net/uspace/recurrent-neural-network-fractal-for-deep-learning)
* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch](https://github.com/karpathy/char-rnn)
* [mrchrisjohnson Recurrent Neural Shady](https://soundcloud.com/mrchrisjohnson/recurrent-neural-shady)
* [recurrent neural network handwriting generation demo](http://www.cs.toronto.edu/~graves/handwriting.cgi?text=Recurrent+neural+nets+are+fucking+magical.&style=&bias=0.5&samples=3)
* [Teaching recurrent Neural Networks about Monet](http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/)
* [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
  * [Recurrent Neural Network (RNN) Tutorial - Part 1](http://aikorea.org/blog/rnn-tutorial-1/)
* [Recurrent Neural Networks Tutorial, Part 2 – Implementing a RNN with Python, Numpy and Theano](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/)
  * [RNN Tutorial Part 2 - Python, NumPy와 Theano로 RNN 구현하기](http://aikorea.org/blog/rnn-tutorial-2/)
* [Recurrent Neural Networks Tutorial, Part 3 – Backpropagation Through Time and Vanishing Gradients](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)
  * [RNN Tutorial Part 3 - BPTT와 Vanishing Gradient 문제](http://aikorea.org/blog/rnn-tutorial-3/)
* [Vanishing Gradient Problem](https://brunch.co.kr/@chris-song/39)
* [Recurrent Neural Network Tutorial, Part 4 – Implementing a GRU/LSTM RNN with Python and Theano](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)
  * [RNN Tutorial Part 4 - GRU/LSTM RNN 구조를 Python과 Theano를 이용하여 구현하기](http://aikorea.org/blog/rnn-tutorial-4/)
* [Auto-Generating Clickbait With Recurrent Neural Networks](http://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/)
* [Modeling Molecules with Recurrent Neural Networks](http://csvoss.github.io/projects/2015/10/08/rnns-and-chemistry.html)
* [char_rnn_ari 한글 Character RNN 구현](https://github.com/bluedisk/char_rnn_ari)
* [Introduction to Recurrent Networks in TensorFlow](http://www.kdnuggets.com/2016/05/intro-recurrent-networks-tensorflow.html)
* [Recurrent Flow Network for Occupancy Flow](https://github.com/sjchoi86/RecurrentFlowNet)
* [Large-Scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks](http://www.kdd.org/kdd2016/subtopic/view/large-scale-item-categorization-in-e-commerce-using-multiple-recurrent-neur/)
* [RNNS IN TENSORFLOW, A PRACTICAL GUIDE AND UNDOCUMENTED FEATURES](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)
  * [RNNs in Tensorflow, A Practical Guide and Undocumented Features](https://tgjeon.github.io/post/rnns-in-tensorflow/)
* [Recurrent Neural Network tutorial (2nd)](http://www.slideshare.net/uspace/recurrent-neural-network-tutorial-2nd)
* [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/)
* [Transformer를 이용해 대량의 게임 데이터를 임베딩 해보자!](https://danbi-ncsoft.github.io/works/2021/04/13/transformer_embedding.html)
* [Fast Weights RNN](https://tensorflowkorea.wordpress.com/2016/10/25/fast-weights-rnn/)
* [Recurrent Neural Networks for Beginners (Tutorial)](https://medium.com/@awjuliani/recurrent-neural-networks-for-beginners-24288e37ac91)
* [RNN(Recurrent Neural Network)과 Torch로 발라드곡 작사하기](http://www.popit.kr/rnnrecurrent-neural-network%EA%B3%BC-torch%EB%A1%9C-%EB%B0%9C%EB%9D%BC%EB%93%9C%EA%B3%A1-%EC%9E%91%EC%82%AC%ED%95%98%EA%B8%B0/)
* [Rohan & Lenny #3: Recurrent Neural Networks](https://ayearofai.com/rohan-lenny-3-recurrent-neural-networks-10300100899b)
* [A Neural Representation of Sketch Drawings](https://arxiv.org/pdf/1704.03477.pdf)
  * [Sketch RNN](https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn.ipynb)
  * [Teaching Machines to Draw](http://blog.otoro.net/2017/05/19/teaching-machines-to-draw/)
* [Implementing RNN for Spam Prediction](https://drive.google.com/file/d/0Byx2LlqPbfj2cHQ3RmJ2SXI4U3c/view)
* [#P.2. On Human Motion Prediction using RNNs (2017)](http://t-robotics.blogspot.com/2017/06/p2-on-human-motion-prediction-using.html#.WTavhRPyiZ0)
* [RNN-implementation-using-Numpy-binary-digit-addition](https://github.com/jaejun-yoo/RNN-implementation-using-Numpy-binary-digit-addition)
* [RNN 관련 글 모음](http://hamait.tistory.com/849)
* [Tips for Training Recurrent Neural Networks](http://danijar.com/tips-for-training-recurrent-neural-networks/)
* [Decoding the Enigma with Recurrent Neural Networks](https://greydanus.github.io/2017/01/07/enigma-rnn/)
  * [Crypto-RNN: Decoding Polyalphabetic Ciphers with Recurrent Neural Networks](https://github.com/greydanus/crypto-rnn)
* [RNN을 이용한 stock 종가 예측](http://mybeta.tistory.com/27)
* [RNNoise: Learning Noise Suppression](https://people.xiph.org/~jm/demo/rnnoise/)
* [CTRNN - Python package that implements Continuous Time Recurrent Neural Networks (CTRNNs)](https://github.com/madvn/CTRNN)
* [Using Genetic Algorithm for Optimizing Recurrent Neural Networks](https://www.kdnuggets.com/2018/01/genetic-algorithm-optimizing-recurrent-neural-network.html)
* [Artificial Neural Networks Optimization using Genetic Algorithm with Python](https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html)
* [Genetic Algorithm (GA) Introduction with Example Code | Towards AI](https://medium.com/towards-artificial-intelligence/genetic-algorithm-ga-introduction-with-example-code-e59f9bc58eaf)
* [Only Numpy: NIPS 2017 - Implementing Dilated Recurrent Neural Networks with Interactive Code](https://towardsdatascience.com/only-numpy-nips-2017-implementing-dilated-recurrent-neural-networks-with-interactive-code-e83abe8c9b27)
* [Recurrent Neural Networks by Example in Python](https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470)
* [Animated RNN, LSTM and GRU - Recurrent neural network cells in GIFs](https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45)
* [Illustrated Guide to LSTM’s and GRU’s: A step by step explanation](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)
* [Long Short-Term Memory Networks Are Dying: What’s Replacing It? | by Andre Ye | Sep, 2020 | Towards Data Science](https://towardsdatascience.com/long-short-term-memory-networks-are-dying-whats-replacing-it-5ff3a99399fe)
* [Understanding A Recurrent Neural Network For Image Generation](https://hackernoon.com/understanding-a-recurrent-neural-network-for-image-generation-7e2f83wdg)
* [An Introduction To Recurrent Neural Networks And The Math That Powers Them](https://machinelearningmastery.com/an-introduction-to-recurrent-neural-networks-and-the-math-that-powers-them/)

# Neuroevolution
* [Neuroevolution: A different kind of deep learning](https://www.oreilly.com/ideas/neuroevolution-a-different-kind-of-deep-learning)
* [Find the Right Version of NEAT for Your Needs](http://eplex.cs.ucf.edu/neat_software/)
* [Paper Repro: Deep Neuroevolution](https://towardsdatascience.com/paper-repro-deep-neuroevolution-756871e00a66)

# Paper
* [**paperswithcode.com**](https://paperswithcode.com/)
  * [Papers with Code 2021 : A Year in Review | by elvis | PapersWithCode | Dec, 2021 | Medium](https://medium.com/paperswithcode/papers-with-code-2021-a-year-in-review-de75d5a77b8b)
* [Browse State-of-the-Art](https://paperswithcode.com/sota)
* [Two Minute Papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)
* [Awesome - Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)
* [Awesome Deep Learning: Most Cited Deep Learning Papers](http://www.kdnuggets.com/2017/04/awesome-deep-learning-most-cited-papers.html)
* [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
* [Five Hundred Deep Learning Papers, Graphviz and Python](http://dnlcrl.github.io/projects/2015/10/10/500-deep-learning-papers-graphviz-python.html?imm_mid=0dd0f3&cmp=em-data-na-na-newsltr_20151202)
* [deeplearning-papernotes](https://github.com/nolsigan/deeplearning-papernotes)
* [the morning paper](https://blog.acolyer.org/)
* [Summaries and notes on Deep Learning research papers](https://github.com/dennybritz/deeplearning-papernotes)
* [openreview.net](https://openreview.net/)
* [취미로 연구하다 논문까지 썼다고?](https://brunch.co.kr/@modulabs/20)
* [3줄논문리뷰 자가지도학습과 강화학습의 샘플 효율성](https://bellman.tistory.com/20)
* [9 Key Deep Learning Papers, Explained](http://www.kdnuggets.com/2016/09/9-key-deep-learning-papers-explained.html/3)
  * 이름 / 이해 난이도 / 읽기 수월함 / 필수성 / 선행지식
  * AlexNet (2012) 하 / 쉬움 / 필수 / 콘볼루션 오퍼레이션 지식, 이미지넷 챌린지
  * ZF Net (2013) 하 / 쉬움 / 옵션 (Segmentation, Localization을 하겠다고 하면 필수) / AlexNet
  * VGG Net (2014) 하 / 쉬움 / 옵션 / AlexNet
  * GoogLeNet (2015) 상 / 어려움 / 옵션 / AlexNet, Hebb 법칙
  * Microsoft ResNet (2015) 중 / 쉬움 / 필수와 옵션의 중간 / AlexNet, VGG Net, NiN(Network in Network)
  * Region Based CNNs (R-CNN - 2013, Fast R-CNN - 2015, Faster R-CNN - 2015)
    * 하 (부분적 상) / 중간 / 옵션 (Segmentation, Localization을 하겠다고 하면 필수. Fast R-CNN을 중심으로 보는게 좋음) / PASCAL 챌린지
  * Generative Adversarial Networks (2014) ? / ? / 필수 / VGG Net
  * Generating Image Descriptions (2014) 상 / 쉬움 / 중간 (이미지 to 문장을 하겠다고 하면 필수) / LSTM, 캡셔닝 챌린지
  * Spatial Transformer Networks (2015) 중 / 어려움 / 옵션 (아직 불명) / 공간변환
* [Deep Learning Paper Implementations: Spatial Transformer Networks - Part I](https://kevinzakka.github.io/2017/01/10/stn-part1/)
* [Swin-Transformer: This is an official implementation for "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"](https://github.com/microsoft/Swin-Transformer)
* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
* [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
* [The Transformer – Attention is all you need](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need)
* [Attention is all you need paper 뽀개기](https://pozalabs.github.io/transformer/)
* [Attention (7): Attention is All You Need, Transformers (1)](https://www.youtube.com/watch?v=Ng9MRx76zS8)
* [Attention (8): Attention is All You Need, Transformers (2)](https://www.youtube.com/watch?v=fTtCakv8a_M)
* [Transformers from Scratch](https://e2eml.school/transformers.html)
* [Attn: Illustrated Attention](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
* [Attn: Illustrated Attention(KR)](https://databreak.netlify.com/2019-05-31-illustrated_Attention/)
* [어텐션 메커니즘과 transfomer(self-attention) | by platfarm tech team | platfarm | Medium](https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225)
* [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/)
* [Computer Vision and Pattern Recognition (cs.CV)](https://scirate.com/arxiv/cs.CV) arXiv에 올라온, CV/PR 주제 논문의 초록만 모아 보여줌
* MNIST 숫자 인식기 Gaussian Bayesian 확률 모델로 구현
  * 목표
    * MNIST 데이터 특성 시각적으로 이해하기
    * Python, numpy, matplotlib 사용해 보기
    * Bayesian Theorem 이해하고 구현해 보기
    * Multivariate Gaussian Distribution 이해하고 구현해 보기
  * 실험 데이터
    * 학습 데이터: MNIST 기본 60,000개
    * 테스트 데이터: MNIST 기본 10,000개
  * 실험 결과
    * Bayesian 확률 모델만으로 분류 정확도가 대략 84% 정도 나오는 것을 확인
    * Multivariate Gaussian 적용하니까 분류 정확도가 대략 92% 정도까지 올라가는 것을 확인
  * 코드
    * [메인 프로그램](https://github.com/dgtgrade/HumanLearning/blob/master/2001a.py)
      * numpy, matplotlib 외에 본격 머신러닝 라이브러리는 전혀 사용하지 않았음
      * 머신러닝 관련 부분 대략 200줄 이하로 매우 짧음
      * 시각화 관련 코드 및 코멘트 등이 대략 300줄 정도임
    * [MNIST 데이터 파일](https://github.com/dgtgrade/HumanLearning/tree/master/data) MNIST 공식 홈페이지에서 받은 그대로
    * [MNIST 데이터 로딩 프로그램](https://github.com/dgtgrade/HumanLearning/blob/master/mnist2ndarray.py)
    * [Multivariate Gaussian 적용하지 않고 Bayesian 확률 모형만으로 돌아가는 코드: 위 2001a.py 옛날 버전](https://github.com/dgtgrade/HumanLearning/blob/8e57a2b3340da3b38956b83cf24433d3a9fbd11b/2001a.py)
  * 실험 동영상
    * 학습: 실험데이터 전체 60000개를 학습하는 과정을 보여줌
    * 테스트: 테스트 데이터 전체 10000개를 테스트 하는 과정을 보여줌
    * 테스트 과정에서 정답률은 1번 후보만으로 구했으나, 표시는 3번후보까지 하였음
* [A Review on a Deep Learning that Reveals the Importance of Big Data](https://fananymi.wordpress.com/)
* [Decoupled Neural Interfaces using Synthetic Gradients](https://arxiv.org/pdf/1608.05343.pdf) synthetic gradient - 뉴럴넷 업데이트 과정의 모듈간 강결합을 decouple
* [Deep Learning without Backpropagation Tutorial: DeepMind's Synthetic Gradients](https://iamtrask.github.io/2017/03/21/synthetic-gradients/)
* [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
* [Deep Learning Research Review Week 1: Generative Adversarial Nets](https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-1-Generative-Adversarial-Nets)
* ["Distributed Training of Deep Neuronal Networks: Theoretical and Practical Limits of Parallel Scalability](http://arxiv.org/abs/1609.06870v1)
  * 여러 노드를 썼을 때, 네트웍 벤드위쓰와 전체 노드에서의 계산을 기다리면 어떻게 되는지
  * 싱글 노드에서 할 때 batch 사이즈를 달리하면 어느 layer 계산이 bottleneck인지
  * 이런 문제를 방지하기 위해 디자인을 바꿀 때 어디부터 보면 되는지
  * 계산량을 어떻게 계산하는지
* [Highway and Residual Networks learn Unrolled Iterative Estimation](https://arxiv.org/abs/1612.07771)
  * VGGNet, GoogLeNet, ResNet 등과 같은 매우 많은 계층을 가진 Deep Net 들이 뛰어난 이유를
  * 기존의 각각의 계층이 특정한 추상적인 feature를 대표하며 이를 계층적으로 계산하기 때문이라는 "representation view" 를 뒤집고
  * 각각의 블록 또는 단계마다 단계적인 feature의 변화가 반복적으로 일어난다는 "unrolled iterative estimation" 으로 설명
* [Solving Verbal Comprehension Questions in IQ Test by Knowledge-Powered Word Embedding](http://arxiv.org/pdf/1505.07909v1.pdf)
* [Stacked Approximated Regression Machine: A Simple Deep Learning Approach](https://arxiv.org/pdf/1608.04062v1.pdf)
  * SARM이라는 layer wise training 기법
  * Back propagation 없이 layer 단위로 학습을 시켜도 현재 state of the art DNN과 비슷하거나 더 나은 성능을 보인다는 주장
  * PCANet에 non linearity를 추가
* [The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition ECCV 2016](https://arxiv.org/pdf/1511.06789v3.pdf)
  * Fine-Grained Recognition을 할 때 Noisy Fine-Grained Data, 즉 Web에서 검색한 Noisy하지만 큰 데이터가 도움이 된다는 내용
  * Noisy Fine-Grained Data 구축
    * 새의 종을 구별하는 데이터베이스를 구축한다면, Wikipedia에서 종을 검색하여 그 키워드를 기반으로 구글링하여 이미지 구축
    * 여러 카테고리에 동시에 등장하는 그림을 지우는 등의 간단한 정제작업을 추가
    * 여전히 이 데이터베이스는 롱테일 문제도 있고 에러도 존재
  * 실험 결과, 퀄리티가 좋지만 작은 데이터보다 성능이 좋다
  * 큰 Noisy Fine-Grained Data로 학습한 후 좋은 데이터로 튜닝하면 더 좋다
  * [Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution](http://www.ee.cuhk.edu.hk/~wlouy…/…/OuyangFactors_CVPR16.pdf)
    * Long-tail Distribution을 가진 DB의 문제점 지적
  * [Training Region-based Object Detectors with Online Hard Example Mining](https://arxiv.org/abs/1604.03540,
CVPR2016)
    * easy examples과 hard examples의 너무 큰 차이에 대해서 문제를 지적
  * Fine-Grained Recognition이라는 테스크에 한정된 실험, 분석, 수학적인 설명 부족한 논문
* [Learning to Remember Rare Events](http://www.gitxiv.com/posts/vnbEtdiH3qZEeKBGb/learning-to-remember-rare-events)
* [Best Practices for Applying Deep Learning to Novel Applications](https://github.com/TeamLab/seminar/blob/master/paper/2017/1704_01568.md)
* [Top 20 Recent Research Papers on Machine Learning and Deep Learning](http://www.kdnuggets.com/2017/04/top-20-papers-machine-learning.html)
* [Deep Learning Papers by task](https://github.com/sbrugman/deep-learning-papers)
* [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515) overfitting 방지
  * [SELUs (scaled exponential linear units) - Visualized and Histogramed Comparisons among ReLU and Leaky ReLU](https://github.com/shaohua0116/Activation-Visualization-Histogram)
  * [SelfNormalizingNetworks](https://github.com/bioinf-jku/SNNs)
  * [SELU_Keras_Tutorial](https://github.com/bigsnarfdude/SELU_Keras_Tutorial)
* [One Model To Learn Them All](http://xxx.lanl.gov/pdf/1706.05137v1)
  * [One Model To Learn Them All](http://xxx.lanl.gov/abs/1706.05137)
  * 이미지,음성, 텍스트 처리를 위한 하나의 모델
  * 딥러닝은 음성 인식, 이미지 분류에서부터 번역에 이르기까지 많은 분야에서 훌륭한 결과를 제공
  * 그러나 각 문제마다 깊이있는 모델을 잘 작동 시키려면 아키텍처 연구와 장기간의 튜닝이 필요
  * 여러 도메인에 걸쳐있는 여러 가지 문제에 대해 좋은 결과를 얻을 수있는 단일 모델을 제시
  * 특히 ImageNet, 다중 번역 작업, 이미지 캡션 (COCO 데이터 세트), 음성 인식 코퍼스 및 영어 구문 분석 작업에서 이
단일 모델을 동시에 학습
  * 우리의 모델 아키텍처는 여러 도메인의 빌딩 블록을 통합
  * convolutional layer, attention mechanism, sparsely-gated layer가 포함
  * 흥미롭게도 블록이 작업에 중요하지 않더라도 이 계산 블록 각각은 우리가 훈련하는 작업의 하위 집합에 결정적인 역할
  * 그것이 성능에 해를 입히지 않으며, 대부분의 경우 모든 작업에서 성능을 향상 시킨다는 것을 관찰
  * 또한 데이터가 적은 작업은 다른 작업과의 공동 교육을 통해 큰 효과를 얻는 반면 큰 작업의 성능은 전혀 저하되지 않음
* [초짜 대학원생 입장에서 이해하는 CVPR 2017 Learning by Association - A versatile semi-supervised training method for neural networks](http://jaejunyoo.blogspot.com/2017/07/learning-by-association-versatile-semi-supervised-training.html)
* [Tutorial on Theory and Application of Generative Adversarial Networks](https://github.com/mingyuliutw/cvpr2017_gan_tutorial)
* [ACL 2017에서 Google 발표 논문](https://www.facebook.com/nextobe1/posts/355787631523905)
* [Layer Normalization](https://tensorflow.blog/2016/07/)
* [blog.lunit.io](https://blog.lunit.io/)
* [인공지능(AI) 관련 최신 공개된 주요 논문 발표 요약](http://www.aitimes.kr/news/articleView.html?idxno=10966)
* [MY FAVORITE DEEP LEARNING PAPERS OF 2017](http://cachestocaches.com/2017/12/favorite-deep-learning-2017/)
* [A List Of Top 10 Deep Learning Papers, The 2018 Edition](https://www.techleer.com/articles/517-a-list-of-top-10-deep-learning-papers-the-2018-edition/)
* [Deep Variational Bayes Filters (2017)](http://t-robotics.blogspot.kr/2018/05/35-deep-variational-bayes-filters-2017.html) VAE를 time series에 확장, 칼만필터에 딥러닝을 더함
* [구글 Active QA 코드 공개 #논문소개](https://thepsygrammer.wordpress.com/2018/10/11/%EA%B5%AC%EA%B8%80-active-qa-%EC%BD%94%EB%93%9C-%EA%B3%B5%EA%B0%9C-%EB%85%BC%EB%AC%B8%EC%86%8C%EA%B0%9C/#more-70)
* [**Papers with code. Sorted by stars. Updated weekly**](https://github.com/zziz/pwc)
* [hugrypiggykim.com/category/study-deep-learning-paper-and-test-programs](http://hugrypiggykim.com/category/study-deep-learning-paper-and-test-programs/)
* [ML/DL/RL Papers](https://www.notion.so/d4aacd7f00564116bb707e09618f4e3c)
* [“EfficientNet; Improving Accuracy and Efficiency through AutoML and Model Scaling 리뷰”](https://hoya012.github.io//blog/EfficientNet-review/)
* [annotated_deep_learning_paper_implementations: 🧑‍🏫 50! Implementations/tutorials of deep learning papers with side-by-side notes 📝; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, ...), gans(cyclegan, stylegan2, ...), 🎮 reinforcement learning (ppo, dqn), capsnet, distillation, ... 🧠](https://github.com/labmlai/annotated_deep_learning_paper_implementations)
* [AutoML-Zero：Evolving Machine Learning Algorithms From Scratch Review](https://hoya012.github.io/blog/automl-zero-review/)
* [Deep Visual-SLAM의 미래 0 (Deep-SLAM의 시작)](https://cv-learn.com/Deep-Visual-SLAM-0-Deep-SLAM-603a26c47c3848a88b90559d273f95dc)
* [DL_PaperReadingMeeting: Deep Learning Paper Reading Meeting-Archive](https://github.com/Lilcob/-DL_PaperReadingMeeting)
* [self-supervised-learning-narratives-1: 거꾸로 읽는 self-supervised learning 파트 1](https://github.com/jwkanggist/self-supervised-learning-narratives-1)
  * [AI 코드 이야기 Deep Adaptive Clustering 코드분석! - YouTube](https://www.youtube.com/watch?v=Yp9GgiBKzts)

# Quickprop
* [Quickprop: an almost forgotten neural training algorithm](https://www.bonaccorso.eu/2017/09/15/quickprop-an-almost-forgotten-neural-training-algorithm/)

# Reinforcement Learning, RL
* [reinforcement_learning_an_introduction](https://nbviewer.jupyter.org/github/Curt-Park/reinforcement_learning_an_introduction/tree/master/)
* [5 Ways to Get Started with Reinforcement Learning](https://buzzrobot.com/5-ways-to-get-started-with-reinforcement-learning-b96d1989c575)
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbooks.io/rl/content/)
* [Ujava.org reinforcement-learning](http://www.slideshare.net/uspace/ujavaorg-reinforcementlearning)
* [ujava.org Reinforcement Learning (2nd)](http://www.slideshare.net/uspace/ujavaorg-reinforcement-learning-2nd)
* [ujava.org workshop : Reinforcement Learning with Thompson Sampling](http://www.slideshare.net/uspace/ujavaorg-workshop-reinforcement-learning-with-thompson-sampling)
* [Frame Skipping and Pre-Processing for Deep Q-Networks on Atari 2600 Games](https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/)
* [github.com/LeeGyeongTak/Q_Network](https://github.com/LeeGyeongTak/Q_Network)
* [Guest Post (Part I): Demystifying Deep Reinforcement Learning](http://www.nervanasys.com/demystifying-deep-reinforcement-learning/)
  * [딥 강화학습 쉽게 이해하기](http://ddanggle.github.io/ml/ai/cs/2016/09/24/demystifyingDL.html)
* [Deep Learning in a Nutshell: Reinforcement Learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-reinforcement-learning/)
* [Bayesian Programming and Learning for Multi-Player Video Games Application to RTS AI](http://emotion.inrialpes.fr/people/synnaeve/phdthesis/phdthesis.html)
  * [Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks](http://arxiv.org/abs/1609.02993)
  * 스타크래프트 같은 실시간 전략 (RTS) 게임은 체스나 바둑과는 다르게 제한된 자원(미네랄, 가스 등)과 불확실한 정보 (보이지 않는 상대방의 플레이 등) 속에서 의사결정을 해야하는 어려움이 존재
  * 이 논문에서는 “참/거짓”으로 표현되는 boolean logic이 아닌 베이지언 모델링으로 이런 정보의 불확실함(uncertainty)를 처리
* [Building a Deep Neural Network to play FIFA 18](https://towardsdatascience.com/building-a-deep-neural-network-to-play-fifa-18-dce54d45e675)
* [Using Deep Learning to improve FIFA 18 graphics](https://towardsdatascience.com/using-deep-learning-to-improve-fifa-18-graphics-529ec44ea37e)
* [Deep Learning in a Nutshell: Reinforcement Learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-reinforcement-learning/)
* [강화 학습 기초 Reinforcement Learning an introduction](http://www.slideshare.net/carpedm20/reinforcement-learning-an-introduction-64037079)
* [An introduction to Reinforcement Learning(https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419)
* [LEARNING REINFORCEMENT LEARNING (WITH CODE, EXERCISES AND SOLUTIONS)](http://www.wildml.com/2016/10/learning-reinforcement-learning/)
* [Reinforcement Learning 101 (in 15 minutes)](https://www.facebook.com/SKTBrain/posts/311444575893030)
* [멀티 암드 밴딧(Multi-Armed Bandits)](https://brunch.co.kr/@chris-song/62)
* [Bandit 101](https://www.facebook.com/SKTBrain/posts/313678162336338) Multi-Armed Bandit (MAB) 입문자료
* [Multi-armed Bandits](https://www.slideshare.net/DongMinLee32/multiarmed-bandits)
* [톰슨 샘플링 for Bandits](https://brunch.co.kr/@chris-song/66)
* [Nathan Epstein - Reinforcement Learning in Python](https://www.youtube.com/watch?v=rTMa04TZ_MY)
* [Lecture 10 Reinforcement Learning I](https://www.youtube.com/watch?v=IXuHxkpO5E8)
* [Reinforcement learning with unsupervised auxiliary tasks](https://deepmind.com/bSandbox/reinforcement-learning-unsupervised-auxiliary-tasks/)
* [Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)
* [Simple Reinforcement Learning in Tensorflow: Part 1 - Two-armed Bandit](https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149)
* [Simple Reinforcement Learning with Tensorflow Part 1.5: Contextual Bandits](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-1-5-contextual-bandits-bff01d1aad9c)
* [Simple Reinforcement Learning with Tensorflow: Part 2 - Policy-based Agents](https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-2-ded33892c724)
* [Simple Reinforcement Learning with Tensorflow: Part 3 - Model-Based RL](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-3-model-based-rl-9a6fe0cce99)
* [Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks and Beyond](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df)
* [Simple Reinforcement Learning with Tensorflow Part 5: Visualizing an Agent’s Thoughts and Actions](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-5-visualizing-an-agents-thoughts-and-actions-4f27b134bb2a)
* [Simple Reinforcement Learning with Tensorflow Part 6: Partial Observability and Deep Recurrent Q-Networks](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-6-partial-observability-and-deep-recurrent-q-68463e9aeefc)
* [Simple Reinforcement Learning with Tensorflow Part 7: Action-Selection Strategies for Exploration](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-7-action-selection-strategies-for-exploration-d3a97b7cceaf)
* [Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2)
* [Bridging Cognitive Science and Reinforcement Learning Part 1: Enactivism](https://medium.com/@awjuliani/bridging-cognitive-science-and-reinforcement-learning-part-1-enactivism-601af34ef122)
* [Deep Reinforcement Learning - author: David Silver, Department of Computer Science, University College London](http://videolectures.net/rldm2015_silver_reinforcement_learning/)
  * [Tutorial: Deep Reinforcement Learning - David Silver, Google DeepMind](http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf)
* [Quantum Boltzman Machines for Deep Reinforcement Learning](https://theinformationageblog.wordpress.com/2017/01/20/quantum-boltzman-machines-for-deep-reinforcement-learning/)
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * [모두를위한RL강좌](https://www.youtube.com/playlist?list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG)
  * [모두를 위한 딥러닝 - Deep Reinforcement Learning](https://www.inflearn.com/course/reinforcement-learning/)
  * [모두를 위한 딥러닝 시즌 2](https://deeplearningzerotoall.github.io/season2/)
  * [kimhun_rl_windows - I follow the lecture (https://hunkim.github.io/ml/) on windows version](https://github.com/nalsil/kimhun_rl_windows)
* [Deep Learning: A Free Mini-Course](https://www.youtube.com/playlist?list=PLBtyBPTlyC7tnpPDkp_E2JgIgIQSbugJL)
* [Reinforcement learning](https://www.youtube.com/playlist?list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT)
* [Tutorial: Introduction to Reinforcement Learning with Function Approximation](https://www.youtube.com/watch?v=ggqnxyjaKe4)
  * [Introduction to Reinforcement Learning with Function Approximation](http://media.nips.cc/Conferences/2015/tutorialslides/SuttonIntroRL-nips-2015-tutorial.pdf)
* [DeepHack.RL](http://rl.deephack.me/)
  * [DeepHack.RL (2017)](https://www.youtube.com/playlist?list=PLt1IfGj6-_-efXDATIw4JI92DjMrVed3P)
* [Building a deep learning DOOM bot](https://www.codelitt.com/blog/doom-ai/)
  * [ViZDoom is a Doom-based AI research platform for reinforcement learning from raw visual information](http://vizdoom.cs.put.edu.pl/)
    * [Tutorial](http://vizdoom.cs.put.edu.pl/tutorial)
  * [ViZDoom - Doom-based AI Research Platform for Reinforcement Learning from Raw Visual Information)](https://github.com/mwydmuch/ViZDoom)
  * [Windows에서 VizDoom 설치하기](http://ishuca.tistory.com/401)
* [ishuca.tistory.com/tag/강화학습](http://ishuca.tistory.com/tag/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5)
* [Deep Reinforcement Learning Pieter abbeel](http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/?q=Pieter+abbeel)
* [Deep Reinforcement Learning: An Overview](https://arxiv.org/abs/1701.07274)
* [강화학습 튜토리알 - 인공 신경망으로 '퐁' 게임을 학습시키자 (Andrej Karpathy 포스트 번역)](http://keunwoochoi.blogspot.com/2016/06/andrej-karpathy.html)
* [pong dqn on colab](https://colab.research.google.com/github/wonseokjung/ai_supermario/blob/master/4_pong_dqn%20(1).ipynb)
* [Playing Atari with Deep Reinforcement Learning](https://speakerdeck.com/jacksongl/playing-atari-with-deep-reinforcement-learning)
* [Solved atari games](https://entropicai.blogspot.com/)
* [Minimal and Clean Reinforcement Learning Examples](https://github.com/rlcode/reinforcement-learning)
* [한국어 Safe Multi-Agent Reinforcement Learning for Autonomous Driving](https://www.slideshare.net/KihoSuh/safe-multiagent-reinforcement-learning-for-autonomouse-driving)
* [Multi-Agent 강화학습 시리즈](https://blog.naver.com/jk96491)
* [Multi-Agent 강화학습 시리즈 1 - COMA : 네이버블로그](https://blog.naver.com/jk96491/222018277094)
* [Multi-Agent 강화학습 시리즈 2 - QMIX : 네이버블로그](https://blog.naver.com/jk96491/222018882435)
* [Multi-Agent 강화학습 시리즈 3 - LIIR : 네이버블로그](https://blog.naver.com/jk96491/222021147197)
* [Multi-Agent 강화학습 시리즈 4 - MAAC : 네이버블로그](https://blog.naver.com/jk96491/222027266122)
* [Multi-Agent 강화학습 시리즈 5 - SEAC : 네이버블로그](https://blog.naver.com/jk96491/222038114436)
* [Multi-Agent 강화학습 시리즈 6 - G2ANet : 네이버블로그](https://blog.naver.com/jk96491/222049181603)
* [Multi-Agent 강화학습 시리즈 7 - AI-QMIX : 네이버블로그](https://blog.naver.com/jk96491/222071545782)
* [Multi-Agent 강화학습 시리즈 8 - ROMA : 네이버블로그](https://blog.naver.com/jk96491/222147514914)
* [Multi-Agent 강화학습 시리즈 9 - RODE : 네이버블로그](https://blog.naver.com/jk96491/222169569578)
* [Multi-Agent 강화학습 시리즈 10 - DOP : 네이버블로그](https://blog.naver.com/jk96491/222271152952)
* [Multi-Agent 강화학습 시리즈 11 - Graph MIX : 네이버블로그](https://blog.naver.com/jk96491/222379325821)
* [Multi-Agent 강화학습 시리즈 12 - CDS : 네이버블로그](https://blog.naver.com/jk96491/222539100660)
* [PredatorPrey: Unity로 멀티 에이전트 강화학습(MARL) 수행하기 위한 프레임 워크 제공](https://github.com/jk96491/PredatorPrey)
* [Reinforcement Learning – Policy](http://web.stanford.edu/class/cs234/slides/cs234_guest_lecture_policy_gradients.pdf)
* [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
* [Jessica Forde An Introduction to Reinforcement Learning PyCon 2017](https://www.youtube.com/watch?v=k1UuTyW2uFc)
* [PLE: A Reinforcement Learning Environment](http://pygame-learning-environment.readthedocs.io)
* [카카오AI리포트 프리뷰 무적 알파고를 만든 비결은?](https://brunch.co.kr/@kakao-it/68)
* [NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING](https://openreview.net/pdf?id=r1Ue8Hcxg)
  * [한국어 Neural Architecture Search with Reinforcement Learning](https://www.slideshare.net/KihoSuh/neural-architecture-search-with-reinforcement-learning-76883153)
  * [review](https://www.facebook.com/groups/modulabs/permalink/1361230430608803)
* [IGC 엔씨소프트 이경종 - 강화 학습을 이용한 NPC AI 구현](https://www.slideshare.net/ssuser052dd11/igc-npc-ai)
* [카카오AI리포트 알파고를 탄생시킨 강화학습의 비밀](https://brunch.co.kr/@kakao-it/73)
* [Tic-Tac-Toe-Machine-Leaning-Using-Reinforcement-Learning](https://github.com/jamesq9/Tic-Tac-Toe-Machine-Learning-Using-Reinforcement-Learning)
* [김정주: 파이썬으로 나만의 강화학습 환경 만들기](https://www.youtube.com/watch?v=chVLag1NIAQ)
  * [파이썬으로 나만의 강화학습 만들기](https://www.slideshare.net/ssuser163469/ss-78685946)
* [알아두면 쓸데있는 신기한 강화학습 NAVER 2017](https://www.slideshare.net/carpedm20/naver-2017)
  * [알아두면 쓸데있는 신기한 강화학습](https://www.youtube.com/watch?v=NGGO0zdzhVQ)
* [Reinforcement learning environments with musculoskeletal models http://opensim.stanford.edu ](https://github.com/stanfordnmbl/osim-rl)
* [Jessica Forde An Introduction to Reinforcement Learning PyCon 2017](https://www.youtube.com/watch?v=k1Uos.stat('.')
* [DeepRLHacks](https://github.com/williamFalcon/DeepRLHacks/blob/master/README.md)
* [RLCode와 A3C 쉽고 깊게 이해하기](https://www.slideshare.net/WoongwonLee/rlcode-a3c)
  * [RLCode와 A3C 쉽고 깊게 이해하기 - YouTube](https://www.youtube.com/watch?v=gINks-YCTBs)
* [5 Ways to Get Started Reinforcement Learning](https://buzzrobot.com/5-ways-to-get-started-with-reinforcement-learning-b96d1989c57HA with 5)
* [Deep RL Bootcamp](https://self.google.com/view/deep-rl-bootcamp/lectures)
* [강화학습 퍼마리오 part 1selfhttps://brunch.co.kr/@kakao-it/144)
* [강화학습으로 풀어보는 슈퍼마리오 part 2](https://brunch.co.kr/@kakao-it/161)
* [인공지능 슈퍼마리오의 거의 모든 것( Pycon 2018 정원석)](https://www.slideshare.net/wonseokjung2/pycon-2018-110420140)
* [A.I Supermario with Reinforcement Learning - 1, 강화학습으로 인공지능 슈퍼마리오 만들기 튜토리얼 1](https://www.youtube.com/watch?v=ydCrd9cDLsU)
  * [강화학습으로 인공지능 슈퍼마리오 만들기 강의 1편](https://wonseokjung.github.io//reinforcementlearning/update/Supermario1/)
  * [A.I_Supermario 강화학습을 이용한 슈퍼마리오 만들기 튜토리얼](https://github.com/wonseokjung/ai_supermario)
* [슈퍼마리오에 모두를 위한 RL 수업의 딥러닝 코드 붙이기](http://jinman190.blogspot.com/2017/10/rl.html)
* [supermario dqn on colab](https://colab.research.google.com/github/wonseokjung/ai_supermario/blob/master/2_supermario_dqn.ipynb)
* [하스스톤 강화학습 환경 개발기](https://www.slideshare.net/utilforever/ndc-2019)
* [장진만쌤의 Sung Kim 교수님의 모두의 RL 수업을 보고 나서 따라 하기](http://chlehrb.tistory.com/78) 07.03 현재 설치까지 진행
* [Reinforce-2 Dynamic Programming, Policy Iteration, Value Iteration](https://drive.google.com/file/d/0B9Eqem6No7GvOG5iSVN1MzdndEU/view)
* [Neural Architecture Search with Reinforcement Learning](https://www.slideshare.net/KihoSuh/neural-architecture-search-with-reinforcement-learning-76883153) 한국어
* [Evolving Stable Strategies](http://blog.otoro.net/2017/11/12/evolving-stable-strategies/)
  * [ESTool](https://github.com/hardmaru/estool/blob/master/README.md)
* [Doing Deep Reinforcement learning with PPO](https://www.slideshare.net/ssuser517c25/doing-deep-reinforcement-learning-with-ppo-82483715)
* [The pycolab game engine](https://github.com/deepmind/pycolab)
* [Neural Map - Structured Memory for Deep RL](http://www.cs.cmu.edu/~rsalakhu/NIPS2017_StructureMemoryForDeepRL.pdf)
* [확률적 바람이 부는 격자 세계로 익히는 강화학습](https://blog.naver.com/kwonpub/221167111861)
* [강화학습 좀 더 이해해보자](https://blog.naver.com/kwonpub/221167878734)
* [Thinking out loud: hierarchical and interpretable multi-task reinforcement learning](https://einstein.ai/research/hierarchical-reinforcement-learning) hierarchical policy network
* [Learning to Compose Skills](https://himanshusahni.github.io/2017/12/26/reusability-in-ai.html)
* [논문 요약 - Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning](http://keunwoochoi.blogspot.com/2017/12/deep-neuroevolution-genetic-algorithms.html)
* [Genetic Algorithms + Neural Networks = Best of Both Worlds](https://towardsdatascience.com/gas-and-nns-6a41f1e8146d)
* [MM framework for RL](https://www.slideshare.net/sungyubkim75/mm-framework-for-rl)
* [Guided policy search](https://www.slideshare.net/jaehyeonBahk/guided-policy-search)
* [Practical_RL: Reinforcement learning for seq2seq (pytorch, tensorflow, theano)](https://www.techleer.com/articles/460-practical_rl-reinforcement-learning-for-seq2seq-pytorch-tensorflow-theano/)
* [Intuitive RL: Intro to Advantage-Actor-Critic (A2C)](https://medium.com/@rudygilman/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752)
* [Learning to Optimize with Reinforcement Learning](http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/)
* [Introduction to Learning to Trade with Reinforcement Learning](http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/)
* [Deep Reinforcement Learning Doesn't Work Yet](https://www.alexirpan.com/2018/02/14/rl-hard.html)
* [Inverse Reinforcement Learning pt. I](https://thinkingwires.com/posts/2018-02-13-irl-tutorial-1.html)
* [Inverse Reinforcement Learning](https://www.youtube.com/watch?v=0q30_gDlrwk)
* [정리 Algorithms for Inverse Reinforcement Learning](https://curt-park.github.io/2019-05-05/algorithms-for-irl/)
* [강화학습과 가상화폐](https://wonseokjung.github.io//crypto_rl/update/cryptoandRL_1/)
* [April Edition: Reinforcement Learning](https://towardsdatascience.com/april-edition-reinforcement-learning-e82cfba4d9c2)
* [Reinforcement Learning](https://www.youtube.com/channel/UCZvMhJ3EaNvpacdlMmm3VKA/feed)
* [Anticipatory Asynchronous Advantage Actor-Critic(A4C)](http://dongminlee.tistory.com/)
* [TDM: From Model-Free to Model-Based Deep Reinforcement Learning](http://bair.berkeley.edu/blog/2018/04/26/tdm/)
* [RL Basics: 1. Markov Process](https://brunch.co.kr/@chris-song/77)
* [Ruslan Salakhutdinov - Neural Map: Structured Memory for Deep Reinforcement Learning](https://www.youtube.com/watch?v=Uj9cPQXaWrw)
* [안.전.제.일. 강화학습!](https://www.slideshare.net/DongMinLee32/ss-103395612)
* [Rl from scratch part1](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part1)
* [Rl from scratch part2](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part2)
* [Rl from scratch part3](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part3)
* [Rl from scratch part4](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part4)
* [Rl from scratch part5](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part5)
* [Rl from scratch part6](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part6)
* [Rl from scratch part7](https://www.slideshare.net/ShinwooPark3/rl-from-scratch-part7)
* [Reinforcement learning’s foundational flaw](https://thegradient.pub/why-rl-is-flawed/)
* [Reinforcement Learning for Stock Prediction](https://www.youtube.com/watch?v=05NqKJ0v7EE)
* [분산 강화학습(Distributed Prioritized Experience Replay) 구현](https://www.slideshare.net/ssuser163469/distributed-prioritized-experience-replay)
* [Deep Reinforcement Learning Tutorial](https://github.com/awjuliani/oreilly-rl-tutorial)
* [Safe Reinforcement Learning](https://www.slideshare.net/DongMinLee32/safe-reinforcement-learning)
* [Reinforcement Learning - A Simple Python Example and a Step Closer to AI with Assisted Q-Learning](https://amunategui.github.io/reinforcement-learning/index.html)
* [RL](Rlhttps://www.slideshare.net/wonseokjung2/rl-112055345)
* Reinforcement Learning: a comprehensive introduction
  * [Part 0](https://www.lpalmieri.com/posts/rl-introduction-00/)
  * [Part 1](https://www.lpalmieri.com/posts/rl-introduction-01/)
  * [Part 2](https://www.lpalmieri.com/posts/rl-introduction-02/)
* Faster Reinforcement Learning via Transfer
  * [blog](https://wonseokjung.github.io/reinforcementlearning/update/FasterRLviatransfer/)
  * [slide](https://speakerdeck.com/wonseokjung/faster-reinforcement-learning-via-transfer)
  * [youtube](https://www.youtube.com/watch?v=zt06BkGbCb8)
* [**Deep Reinforcement Learning Course**](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/)
* [Neural Architecture Search with Reinforcement Learning](https://www.slideshare.net/KihoSuh/neural-architecture-search-with-reinforcement-learning-76883153)
* [**강화학습(Reinforcement Learning)으로 접근하는 E-commerce Dynamic Pricing 논문리뷰**](https://hoondongkim.blogspot.com/2018/10/reinforcement-learning-e-commerce.html)
* [DeepMimic - Motion imitation with deep reinforcement learning](https://github.com/xbpeng/DeepMimic)
* [Open sourcing TRFL: a library of reinforcement learning building blocks](https://deepmind.com/blog/trfl/)
* [Deep Learning and Reinforcement Learning Summer School, Toronto 2018](http://videolectures.net/DLRLsummerschool2018_toronto)
* [About Deep Reinforcement Learning based on CS294](https://github.com/wonseokjung/RLXDL)
* [Horizon: The first open source reinforcement learning platform for large-scale products and services](https://code.fb.com/ml-applications/horizon/)
* [Reinforcement Learning in NIPS 2018](https://medium.com/@yuxili/reinforcement-learning-in-nips-2018-967ab53ab211)
* [강화학습 이론 및 실습](https://speakerdeck.com/wonseokjung/reinforcement-learning-a2711ce7-83db-4c31-8ea3-ad5db0e1a9a9)
* [The Fantasy Football AI framework](https://github.com/njustesen/ffai) based on Open AI Gym
* [A (Long) Peek into Reinforcement Learning](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html)
* [The End of Open AI Competitions](https://towardsdatascience.com/the-end-of-open-ai-competitions-ff33c9c69846)
* [Reinforcement Learning Applications](https://medium.com/@yuxili/rl-applications-73ef685c07eb)
* [Structural implementation of RL key algorithms https://www.medipixel.io ](https://github.com/medipixel/rl_algorithms)
* [Reinforcement Learning with Python](https://towardsdatascience.com/reinforcement-learning-with-python-8ef0242a2fa2)
* [Learning to Paint - A painting AI that can reproduce paintings stroke by stroke using deep reinforcement learning](https://github.com/hzwer/LearningToPaint)
* [쉽게구현하는 강화학습 1화 Policy Gradient - REINFORCE와 Actor-Critic 구현하기!](https://www.youtube.com/watch?v=12pXaP8KPbE)
  * [minimalRL](https://github.com/seungeunrho/minimalRL)
* [Reinforcement Learning as Probabilistic Inference](https://colab.research.google.com/drive/1VkoRfg_thJuRyWlZXFNvPcRrviRlxO9I) ipynb
* [On Choosing a Deep Reinforcement Learning Library](https://medium.com/data-from-the-trenches/choosing-a-deep-reinforcement-learning-library-890fb0307092)
* [The Arcade Learning Environment](https://github.com/mgbellemare/Arcade-Learning-Environment)
* [The Reinforcement Learning Toybox](https://github.com/KDL-umass/Toybox)
* [How do we make Real World Reinforcement Learning revolution?](https://slideslive.com/38916906/how-do-we-make-real-world-reinforcement-learning-revolution)
* [Reinforcement Learning in Recommender Systems: Some Challenges](https://slideslive.com/38916907/reinforcement-learning-in-recommender-systems-some-challenges)
* [강화학습기초(MDP, Monte-Carlo, Time-difference, sarsa, q-learning) 파트1](https://www.slideshare.net/LeejinJeong/mdp-montecarlo-timedifference-sarsa-qlearning-1)
* [강화학습 기초 2(Deep sarsa, Deep Q-learning, DQN)](https://www.slideshare.net/LeejinJeong/deep-sarsa-deep-qlearning-dqn-102870420)
* [Reinforcement Learning](https://teamdable.github.io/techblog/Reinforcement-Learning) 기초
* [Prologue](https://sumniya.tistory.com/1)
* [Deep Reinforcement Learning, Summer 2019 (Samsung)](https://github.com/dongminlee94/Samsung-DRL-Code)
* [인공지능, 머신러닝은 아는데⋯심층 강화학습은 무엇? - 한빛출판네트워크](https://www.hanbit.co.kr/channel/category/category_view.html?cms_code=CMS1612832708) DRL
* [How to study Reinforcement Learning](https://github.com/reinforcement-learning-kr/how_to_study_rl/wiki)
* [2019-OSS-Summer-RL](https://github.com/utilForever/2019-OSS-Summer-RL)
* [Reinforcement learning for everyone](https://www.slideshare.net/taeyounglee1447/reinforcement-learning-for-everyone)
* [RLKorea Unity ML-agents Tutorial Project](https://github.com/reinforcement-learning-kr/Unity_ML_Agents)
* [Stable Baselines RL tutorial - JNRR19](https://github.com/araffin/rl-tutorial-jnrr19)
* [RL Bootcamp](https://github.com/reinforcement-learning-kr/rl_bootcamp)
* [Scalable Efficient Deep-RL - A more efficient way to scale up reinforcement learning algorithms](https://medium.com/towards-artificial-intelligence/scalable-efficient-deep-rl-ea67c0a5f4b2)
  * [SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference. Implements IMPALA and R2D2 algorithms in TF2 with SEED's architecture](https://github.com/google-research/seed_rl)
* [Reinforcement Learning: Past, Present and Future Perspectives](https://www.notion.so/Reinforcement-Learning-Past-Present-and-Future-Perspectives-fcde7f7eee34416a8bc849911d912a41)
* [Behavior Cloning](https://jsideas.net/BC/)
* [강화학습을 공부하는 분들에게 도움이 되는 Gym Gazebo 설정하기](https://pinkwink.kr/1269)
* [비행슈팅게임에 강화학습 적용하기 1](https://blog.naver.com/jk96491/221841840402)
* [비행슈팅게임에 강화학습 적용하기 2](https://blog.naver.com/jk96491/221841888305)
* [비행슈팅게임에 강화학습 적용하기 3](https://blog.naver.com/jk96491/221841962715)
* [비행슈팅게임에 강화학습 적용하기 4(完)](https://blog.naver.com/jk96491/221842016652)
* [Introduction-of-Reinforcement-Learning](https://github.com/LoveRL/Introduction-of-Reinforcement-Learning)
* [Deep Reinforcement Learning in TensorFlow2](https://github.com/marload/deep-rl-tf2)
* [A Simple Industrial Example: Real-Time Bidding](https://rl-book.com/learn/value_methods/bidding/) 광고
* [2020 나 혼자 RL한다 - YouTube](https://www.youtube.com/playlist?list=PL758EWSZu9DbUVYgS23gj5M-yxjdS2FKD)
* [Reinforcement Learning meets the real-world:Industrial RL applications](https://tv.naver.com/v/16969158)
* [강화학습으로 더 재미있는 게임 만들기](https://tech.devsisters.com/posts/crp-puzzle-bot/)
* [어렵지만 도전할 가치 있는 '강화학습 알고리즘' 직접 실험하기 - ITWorld Korea](https://www.itworld.co.kr/news/183779)
* [Algorithm_For_RL: studying algorithm for RL](https://github.com/LeejwUniverse/Algorithm_For_RL)
* [강화학습 환경 개발 (넥슨 옥찬호) - YouTube](https://www.youtube.com/watch?v=PuVLgXhEBpQ)
* [android_env](https://github.com/deepmind/android_env)
* [HSC2021-AlphaSolar](https://github.com/Yeachan-Heo/HSC2021-AlphaSolar)
* [3줄 Survey RL for CO](https://bellman.tistory.com/36)
* [강화학습 팁 모음](https://ropiens.tistory.com/132)
* [강화학습 팁 모음(2) - reward function 작성 요령](https://ropiens.tistory.com/139)
* [Deep Reinforcement Learning is a waste of time](http://www.jtoy.net/blog/deep-reinforcement-learning-is-a-waste-of-time.html)
* [Training a Reinforcement Learning Agent to Play Soccer - YouTube](https://www.youtube.com/watch?v=ht4kJsZluVU)
* [강화학습, 산업의 난제에 도전하다! - ASIC 반도체 설계 (Floorplan) 자동화](https://tv.naver.com/v/23650123)
  * [주문형 반도체 (ASIC) Floorplan 자동화 - Part I | MakinaRocks Tech Blog](https://makinarocks.github.io/ASIC-Floorplan-Automation-Part-1/)
  * [주문형 반도체 (ASIC) Floorplan 자동화 - Part II | MakinaRocks Tech Blog](https://makinarocks.github.io/ASIC-Floorplan-Automation-Part-2/)
* [강화학습의 변천사 – TensorMSA](https://hugrypiggykim.com/2021/12/22/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%9D%98-%EB%B3%80%EC%B2%9C%EC%82%AC/)
* [Physics Simulator w/ Robot Dog - YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDenVbxP4LXYZoGbjfgP-Y5i)
* [Reinforcement Learning with Stable Baselines 3 - YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDf0O2DWwLZBfJeYY-JOeZB1)
* [NDC22 강화학습 알고리즘으로 구현한 '사람 같은' 적 AI](https://thisisgame.com/webzine/gameevent/nboard/227/?n=151020)
* [async_deep_reinforce - Asynchronous deep reinforcement learning](https://github.com/miyosuda/async_deep_reinforce)
* [async-rl-tensorflow - Asynchronous Methods for Deep Reinforcement Learning](https://github.com/devsisters/async-rl-tensorflow)
* [Bomberland | Coder One](https://www.gocoder.one/bomberland)
* [brain_agent: Brain Agent for Large-Scale and Multi-Task Agent Learning](https://github.com/kakaobrain/brain_agent)
* [coach - Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms https://nervanasystems.github.io/coach ](https://github.com/NervanaSystems/coach#running-coach-dashboard-visualization)
* [Dopamine - a research framework for fast prototyping of reinforcement learning algorithms](https://github.com/google/dopamine)
  * [Google-Dopamine-Kr](https://github.com/yebgi83/Google-Dopamine-Kr)
* [ELF - An End-To-End, Lightweight and Flexible Platform for Game Research](https://github.com/facebookresearch/ELF)
* [Holodeck - a high-fidelity simulator for reinforcement learning built on top of Unreal Engine 4](https://github.com/byu-pccl/holodeck)
  * [Introducing Holodeck](https://pcc.cs.byu.edu/2018/10/04/introducing-holodeck/)
* [irelia - Korean Janggi AI using q learning](https://github.com/jireh-father/irelia)
* [JORLDY: Repository for Open Source Reinforcement Learning Framework JORLDY](https://github.com/kakaoenterprise/JORLDY)
  * [INSIDE THE LAB ⎪ EP03. if (JORLDY) - YouTube](https://www.youtube.com/watch?v=-xpJZswrDFw)
* [MAME RL Algorithm Trainig Toolkit - A Python toolkit used to train reinforcement learning algorithms against arcade games](https://github.com/M-J-Murray/MAMEToolkit)
* [Mava: A new Open-Source Framework for Multi-Agent Reinforcement Learning | InstaDeep - Decision-Making AI For The Enterprise](https://www.instadeep.com/2021/07/mava-a-new-framework-for-distributed-multi-agent-reinforcement-learning/)
* MuJoCo [DeepMind MuJoCo Multi-Agent Soccer Environment](https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/soccer)
* [Psychlab](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/psychlab)
  * [Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents](https://arxiv.org/abs/1801.08116)
  * [Open-sourcing Psychlab](https://deepmind.com/blog/open-sourcing-psychlab/)
  * [Psychlab 'visual search' task in DeepMind Lab](https://www.youtube.com/watch?v=54AS3a6niPo)
* [RL_BASIC](https://github.com/kkugosu/RL_BASIC)
* [rliable: Open-source library for reliable evaluation on reinforcement learning and machine learning benchmarks. See NeurIPS 2021 oral for details](https://github.com/google-research/rliable)
* [rllab - a framework for developing and evaluating reinforcement learning algorithms](https://github.com/rll/rllab)
* [RLlib: Scalable Reinforcement Learning](https://ray.readthedocs.io/en/latest/rllib.html)
* [Soft Actor Critic—Deep Reinforcement Learning with Real-World Robots](https://bair.berkeley.edu/blog/2018/12/14/sac)
  * tensorflow, pytorch 둘 다 공개
* [TMTrackNN — generating TrackMania tracks with neural networks](https://medium.com/@donadigo/tmtracknn-generating-trackmania-tracks-with-neural-networks-146db058e7cb)
* [Unity-ML-Agents: Unity 강화학습 알고리즘 및 게임 환경을 제공합니다](https://github.com/jk96491/Unity-ML-Agents)
* [TetrisXQ - Difficult and annoying Tetris implemented by Reinforcement Lrarning](https://github.com/junghyun397/TetrisXQ)

## RL Deep Q Learning DQL
* [Deep Q-Learning (Space Invaders)](http://maciejjaskowski.github.io/2016/03/09/space-invaders.html)
* [Using Deep Q-Network to Learn How To Play Flappy Bird](https://github.com/DeepLearningProjects/DeepLearningFlappyBird)
* [**Deep Reinforcement Learning**](http://andersonjo.github.io/artificial-intelligence/2017/06/03/Deep-Reinforcement-Learning/)
  * [Deep Q-Learning with Pytorch](https://github.com/AndersonJo/dqn-pytorch)
* [Hello DeepQ](http://koaning.io/hello-deepq.html)
* [Deep Q Learning with Keras and Gym](https://keon.io/deep-q-learning)
* [Q-learning Test](http://computingkoreanlab.com/app/jAI/jQLearning/)
* [DQN Adventure: from Zero to State of the Art](https://github.com/higgsfield/RL-Adventure)
* [An introduction to Deep Q-Learning: let’s play Doom](https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8)
* [강화학습 Q-Learning 중 Q-Table(Tabular Methods) - 1편](http://passi0n.tistory.com/86)
* [Dqn break](https://www.slideshare.net/ssuserd20cab/dqn-break)
* [Diving deeper into Reinforcement Learning with Q-Learning](https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe)
* [Improvements in Deep Q Learning: Dueling Double DQN, Prioritized Experience Replay, and fixed Q-targets](https://medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682)
* [Reinforcement Learning and DQN, learning to play from pixels](https://rubenfiszel.github.io/posts/rl4j/2016-09-08-DQN-Learning-to-play-from-pixels-step-by-step.html)
* [DQN 3.0](https://github.com/deepmind/dqn)
* [github.com/LeeGyeongTak/DQN](https://github.com/LeeGyeongTak/DQN)
* [강화학습 기초부터 DQN까지 (Reinforcement Learning from Basics to DQN)](https://www.slideshare.net/CurtPark1/dqn-reinforcement-learning-from-basics-to-dqn)
* [Introduction to Various Reinforcement Learning Algorithms. Part I (Q-Learning, SARSA, DQN, DDPG)](https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287)
* [DQN을 알아보자 - Playing Atari with Deep Reinforcement Learning](https://wonseokjung.github.io//rl_paper/update/RL-PP-DQN/)
* [Playing Text-adventure Games with an AI](https://medium.com/@rajammanabrolu/kg-dqn-57d06004022)
* [DRL Value-based Methods - DQN](https://parksurk.github.io/deep/reinfocement/learning/drlnd_2-4_value_based_methods-post/)
* [Teach an Agent Play a Game Using Q-Learning in Numpy](https://towardsdatascience.com/using-q-learning-in-numpy-to-teach-an-agent-to-play-a-game-4fee32eb922a)
* [DQN_HER.ipynb at master · HERIUN/RLstudy](https://github.com/HERIUN/RLstudy/blob/master/DQN_HER.ipynb)
  * BitFlip환경에서 DQN+HER 구현
  * [rl-paper-study/210412 - Hindsight Experience Replay, M. Andrychowicz et al, 2017.pdf at master · utilForever/rl-paper-study](https://github.com/utilForever/rl-paper-study/blob/master/4th/210412%20-%20Hindsight%20Experience%20Replay%2C%20M.%20Andrychowicz%20et%20al%2C%202017.pdf)

## RL MOOC, Lectures
* [List Of Free Deep Learning Courses Online](https://www.marktechpost.com/2018/11/17/list-of-free-deep-learning-courses-online)
* [강화학습의 기초 이론](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
* [Angdrew Ng youtube playlists](https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists)
* [Berkeley CS 294: Deep Reinforcement Learning, Spring 2017](http://rll.berkeley.edu/deeprlcourse/)
  * [CS 294: Deep Reinforcement Learning —(1) Introduction and course overview](https://medium.com/@peteryun/rl-cs-294-deep-reinforcement-learning-introduction-and-course-overview-c7d9cb550ced)
  * [CS294: Deep RL Start!](https://tensorflow.blog/2017/01/23/cs294-deep-rl-start/)
    * [CS294-112 Deep Reinforcement Learning Sp17](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX)
* [CS234: Reinforcement Learning](http://web.stanford.edu/class/cs234)
  * [CS234: Reinforcement Learning | Winter 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)
* [CS885 Lecture 14c: Trust Region Methods](https://www.youtube.com/watch?v=qaOKZkeutqE)
* [Deep Learning and Reinforcement Learning Summer School 2018](https://dlrlsummerschool.ca)
  * [Deep Learning and Reinforcement Learning Summer School, Toronto 2018](http://videolectures.net/DLRLsummerschool2018_toronto/)
* [Deep Reinforcement Learning](http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/)
* [Deep Reinforcement Learning and Control](https://katefvision.github.io/)
* [DS-GA 1008 딥러닝 · 딥러닝](https://atcold.github.io/pytorch-Deep-Learning/ko/)
* [MIT 6.S094: Deep Learning for Self-Driving Cars (Lecture 2), 2017](http://selfdrivingcars.mit.edu/)
* [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)
  * [Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course](https://github.com/dennybritz/reinforcement-learning)
  * [Reinforcement Learning: An Introduction](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction) Python code for Sutton & Barto's book
* [School of AI : AI for Business](https://www.edwith.org/schoolofai)
* [School of AI : Deep Learning Live Coding](https://www.edwith.org/introdeep)
* [Spinning Up in Deep RL](https://blog.openai.com/spinning-up-in-deep-rl)
* [Stanford Andrew Ng CS229 Lecture 16, 2008](https://www.youtube.com/watch?v=RtxI449ZjSc)
* [Temporal-Difference Learning](https://wonseokjung.github.io/reinforcementlearning/update/RL-TD_new/)
  * [1](https://wonseokjung.github.io/reinforcementlearning/update/RL-TD1/)
  * [2](https://wonseokjung.github.io/reinforcementlearning/update/RL-TD2/)
* [theschool.ai](https://www.theschool.ai)
* [UCL, David Silver, Reinforcement Learning, 2015](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
* [Reinforcement Learning for Engineers, Part 4: The Walking Robot Problem](https://www.youtube.com/watch?v=Wypc1a-1ZYA)
* [RL Course by David Silver - Lecture 1: Introduction to Reinforcement Learning](https://www.youtube.com/watch?v=2pWv7GOvuf0)

## RL StarCraft II
* [Introduction and Collecting Minerals - p.1](https://pythonprogramming.net/starcraft-ii-ai-python-sc2-tutorial/)
  * [Introduction and Collecting Minerals - tutorial p.1](https://www.youtube.com/watch?v=v3LJ6VvpfgI)
* [Workers and Pylons - p.2](https://pythonprogramming.net/workers-pylons-starcraft-ii-ai-python-sc2-tutorial/?completed=/starcraft-ii-ai-python-sc2-tutorial/)
  * [Workers and Pylons - tutorial p.2](https://www.youtube.com/watch?v=5U2WdZxJhEE)
* [Geysers and Expanding - p.3](https://pythonprogramming.net/geysers-expanding-starcraft-ii-ai-python-sc2-tutorial/)
  * [Geysers and Expanding - tutorial p.3](https://www.youtube.com/watch?v=OxC74ojgV-Y)
* [Building an AI Army - p.4](https://pythonprogramming.net/building-army-starcraft-ii-ai-python-sc2-tutorial/)
  * [Building an AI Army - tutorial p.4](https://www.youtube.com/watch?v=mG0W-etXqBY)
* [Commanding your AI Army - p.5](https://pythonprogramming.net/commanding-army-starcraft-ii-ai-python-sc2-tutorial/)
* [Defeating Hard AI - p.6](https://pythonprogramming.net/hard-ai-defeat-starcraft-ii-ai-python-sc2-tutorial/)
* [Deep Learning with SC2 Intro - p.7](https://pythonprogramming.net/deep-learning-starcraft-ii-ai-python-sc2-tutorial/)
* [Scouting and more Visual inputs - p.8](https://pythonprogramming.net/scouting-visual-input-starcraft-ii-ai-python-sc2-tutorial/)
* [Building our training data - p.9](https://pythonprogramming.net/building-neural-network-training-data-starcraft-ii-ai-python-sc2-tutorial/)
* [Building Neural Network Model - p.10](https://pythonprogramming.net/building-neural-network-starcraft-ii-ai-python-sc2-tutorial/)
* [Training Neural Network Model - p.11](https://pythonprogramming.net/training-neural-network-starcraft-ii-ai-python-sc2-tutorial/)
* [Using Neural Network Model - p.12](https://pythonprogramming.net/using-neural-network-starcraft-ii-ai-python-sc2-tutorial/)
* [Version 2 Changes - p.13](https://pythonprogramming.net/version-2-starcraft-ii-ai-python-sc2-tutorial/)
* [Improving Scouting - p.14](https://pythonprogramming.net/better-scouting-starcraft-ii-ai-python-sc2-tutorial/)
* [Adding Choices - p.15](https://pythonprogramming.net/more-choices-starcraft-ii-ai-python-sc2-tutorial/)
* [Visualization Changes - p.16](https://pythonprogramming.net/visual-changes-starcraft-ii-ai-python-sc2-tutorial/)
* [More Training and Findings - p.17](https://pythonprogramming.net/stage2-training-starcraft-ii-ai-python-sc2-tutorial/)
* [스타크래프트2 강화학습(StarCraft II Reinforcement Learning)](https://www.slideshare.net/sjhshy/2-starcraft-ii-reinforcement-learning-80779324)
* 스타2 강화학습 튜토리얼
  * [1편](https://brunch.co.kr/@chris-song/44)
  * [2편](https://brunch.co.kr/@chris-song/48)
  * [3편](https://brunch.co.kr/@chris-song/53)
* [StarCraft II RL Tutorial 1 - Deepmind's StarCraft II RL Environment](http://chris-chris.ai/2017/08/30/pysc2-tutorial1/)
* [StarCraft II RL Tutorial 2 - Deepmind's pysc2: Observations](http://chris-chris.ai/2017/11/06/pysc2-tutorial2/)
* [SSCAIT Student StarCraft AI Tournament & Ladder](https://sscaitournament.com/)
* [TStarBots Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game](https://chagmgang.github.io/starcraft_ii_rl/2018/10/15/TStarBots-Defeating-the-Cheating-Level-Builtin-AI-in-StarCraft-II-in-the-Full-Game.html)
* [한국어 Multiagent Bidirectional- Coordinated Nets for Learning to Play StarCraft Combat Games](https://www.slideshare.net/KihoSuh/multiagent-bidirectional-coordinated-nets-for-learning-to-play-starcraft-combat-games)
* [번역 StarCraft2 A New Challenge for Reinforcement Learning 스타크래프트2 강화학습](https://losskatsu.github.io/papertranslation/sc2le/)
* [SMAC(Starcraft Multi-Agent Challenge) 1 - 환경 소개](https://blog.naver.com/jk96491/222060677009)
* AlphaCode
  * [Competitive programming with AlphaCode | DeepMind](https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode)
    * 바둑을 두는 AlphaGo를 만들었던 DeepMind에서 프로그램을 작성하는 AlphaCode 공개
    * 알고리즘 문제 풀이 사이트인 Codeforces와 협력해서 최근 문제 10개를 기준으로 실험한 결과 상위 54% 랭크
    * 상위에 랭크된 것은 아니지만 의미 있는 결과이고 AlphaCode는 알고리즘 문제를 입력으로 받아서 출력으로 프로그램 작성
    * 사용된 데이터 세트는 [GitHub CodeContests](https://github.com/deepmind/code_contests) 저장소에 공개되어 있고 [AlphaCode Attention Visualizatio](https://alphacode.deepmind.com/)에서 처리되는 과정 확인 가능
* AlphaFold
  * [AlphaFold reveals the structure of the protein universe](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe)
    * 데이터베이스를 만들기 시작한지 단 1년만에 2억개의 단백질 구조 데이터베이스 오픈. 50년간 인류가 실험적으로 밝혀낸 단백질 구조 갯수인 약 20만개 보다 1000배 많은 숫자
* [AlphaStar: Mastering the Real-Time Strategy Game StarCraft II](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/)
  * [AI가 스타크래프트2를 정복한 원리(알파스타)](https://www.youtube.com/watch?v=GciYOMIJ2Eo)
  * [AlphaStar: Mastering the Game of StarCraft II](https://slideslive.com/38916905/alphastar-mastering-the-game-of-starcraft-ii)
  * [AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning](https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning)
* [alpha-zero-general: A clean implementation based on AlphaZero for any game in any framework + tutorial + Othello/Gobang/TicTacToe/Connect4 and more](https://github.com/suragnair/alpha-zero-general)
* [gym-starcraft](https://github.com/alibaba/gym-starcraft/blob/master/README.md)
  * [Reinforcement Learning: Introduction to Monte Carlo Learning using the OpenAI Gym Toolkit](https://medium.com/analytics-vidhya/reinforcement-learning-introduction-to-monte-carlo-learning-using-the-openai-gym-toolkit-4efef9375648)
* [Keras_CNN_PPO_StarCraft](https://github.com/jangikim2/Reinforcement-Learning/tree/master/Keras_CNN_PPO_StarCraft)
* [pysc2: StarCraft II Learning Environment](https://github.com/deepmind/pysc2)
* [pySC2 mini-games](https://github.com/SoyGema/pySC2_minigames)
* [Reaver: StarCraft II Deep Reinforcement Learning Agent](https://github.com/inoryy/reaver-pysc2)
* [sc2-korean-level](https://chris-chris.gitbook.io/sc2-korean-level/untitled)
* [SMAC: 스타크래프트2 멀티 에이전트 강화학습 챌린지](https://github.com/jk96491/SMAC)
* [tleague_projpage](https://github.com/tencent-ailab/tleague_projpage)

# Semantic Sementation
* [A 2017 Guide to Semantic Segmentation with Deep Learning](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review)
* [LinkNet - Feature Forwarding: Exploiting Encoder Representations for Efficient Semantic Segmentation](https://codeac29.github.io/projects/linknet/index.html)
* [Semantic Segmentation using Fully Convolutional Networks over the years](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html)

# Spark
* [DeepSpark: Spark-Based Deep Learning Supporting Asynchronous Updates and Caffe Compatibility](http://hgpu.org/?p=15511)
* [yahoo/CaffeOnSpark](https://github.com/yahoo/CaffeOnSpark)
* [SparkNet: Training Deep Networks in Spark](http://arxiv.org/abs/1511.06051)
* [spark-summit.org/2016/schedule](https://spark-summit.org/2016/schedule/)
  * Large-Scale Deep Learning with TensorFlow (Jeff Dean)
    * [slide](http://www.slideshare.net/JenAman/large-scale-deep-learning-with-tensorflow)
    * [video](https://youtu.be/XYwIDn00PAo)
  * [AI: The New Electricity (Andrew Ng)](https://youtu.be/4eJhcxfYR4I)
  * Large Scale Multimedia Data Intelligence And Analysis On Spark (Baidu)
    * [slide](http://www.slideshare.net/JenAman/large-scale-multimedia-data-intelligence-and-analysis-on-spark)
    * [video](https://youtu.be/LrtdyCWphvs)
  * Scaling Machine Learning To Billions Of Parameters (Yahoo)
    * [slide](http://www.slideshare.net/JenAman/scaling-machine-learning-to-billions-of-parameters)
    * [video](https://youtu.be/l_1S7W_l2cI)
  * CaffeOnSpark: Deep Learning On Spark Cluster (Yahoo)
    * [slide](http://www.slideshare.net/JenAman/caffeonspark-deep-learning-on-spark-cluster)
    * [video](https://youtu.be/Mn7QEdUFSnQ)
  * Scalable Deep Learning in Baidu
    * [slide](http://www.slideshare.net/JenAman/scalable-deep-learning-platform-on-spark-in-baidu)
    * [video](https://youtu.be/n9yZNmC20pc)

# Tutorial
* [입문자를 위한 딥러닝 튜토리얼](http://courseshare.co.kr/course/39?pageType=Intro)
* [테리의 딥러닝 토크](https://www.youtube.com/playlist?list=PL0oFI08O71gKEXITQ7OG2SCCXkrtid7Fq)
  * [Deep learning (Machine learning) tutorial for beginners](https://www.slideshare.net/TerryTaewoongUm/deep-learning-machine-learning-tutorial-for-beginners)
  * [#3.1. 구글 클라우드(gcloud)로 딥러닝 시작하기](https://www.youtube.com/watch?v=d4mz9YIf6Gc)
* [쉽게 풀어쓴 딥러닝(Deep Learning)의 거의 모든 것](http://t-robotics.blogspot.kr/2015/05/deep-learning.html)
  * [#36. 딥러닝의 실제적용, 튜토리얼과 무엇이 다른가? ](http://t-robotics.blogspot.com/2018/09/36.html)
* [딥러닝 기본 원리의 이해](https://www.slideshare.net/HeeWonPark11/ss-80653977)
* [완전쉬운 딥러닝](https://docs.google.com/document/d/11A7207YsYcKU7F3uq117pNGRGIReEP88__gZmflIXrs/edit)
  * [완전쉬운 딥러닝 동영상 원고](http://kr.deductiontheory.com/2017/03/blog-post_3.html)
  * [Super Easy Deep Learning](https://www.youtube.com/watch?v=8NkZohHnxck)
* [자습해도 모르겠던 딥러닝, 머리속에 인스톨 시켜드립니다](https://www.slideshare.net/yongho/ss-79607172)
* [구글, 유다시티에 딥러닝 강의 무료 공개](http://www.bloter.net/archives/248374)
* [헬로 딥러닝 : 쉽고도 명확하게 이해하는 딥러닝](https://www.youtube.com/playlist?list=PLefQdA1SdkhsO4yGqIFAWcG6vr211di1j)
* [모두를 위한 딥러닝 강좌](http://www.se.or.kr/m/post/161)
  * [**기본적인 머신러닝과 딥러닝 강의**](http://hunkim.github.io/ml/)
  * [TensorFlow-Tutorials](https://github.com/hunkim/TensorFlow-Tutorials)
  * [TensorFlow Basic Tutorial Labs](https://github.com/hunkim/DeepLearningZeroToAll)
  * [Lec 00 - Machine/Deep learning 수업의 개요와 일정](https://www.youtube.com/watch?v=BS6O0zOGX4E)
  * [lec11-1 ConvNet의 Conv 레이어 만들기](https://www.youtube.com/watch?v=Em63mknbtWo)
  * [lab11: ConvNet을 TensorFlow로 구현하자 (MNIST 99%)](https://www.youtube.com/watch?v=6KlkiKyjEu0)
  * [lec12: NN의 꽃 RNN 이야기](https://www.youtube.com/watch?v=-SHPG_KMUkQ)
  * [lab12: TensorFlow에서 RNN 구현하기](https://www.youtube.com/watch?v=A8wJYfDUYCk)
* [자바로 Mnist 구현하고 스프링웹서버붙이기](https://www.slideshare.net/meadunhansa/mnist)
* [모두를 위한 딥러닝 강좌](http://www.se.or.kr/161)
* [C++로 배우는 딥러닝](http://blog.naver.com/atelierjpro/220697890605)
  * [C++로 배우는 딥러닝](https://www.youtube.com/playlist?list=PLNfg4W25Tapy5hIBmFZgT5coii1HUX6BD)
  * [딥러닝 4-3. 프로그래머를 위한 경사 하강법 The Gradient Descent Method for Programmers](http://blog.naver.com/atelierjpro/220755873110)
  * [딥러닝 4-4. 프로그래머를 위한 연쇄 미분 Chain Rule](http://m.blog.naver.com/atelierjpro/220760659825)
  * [딥러닝 4.4 - 연쇄 미분 ChainRule](https://www.youtube.com/watch?v=g3nhLjYRT5I)
  * [딥러닝 6. Fully Connected Neural Network](http://blog.naver.com/atelierjpro/220773276384)
  * [딥러닝 7. Implementing FCNN](http://blog.naver.com/atelierjpro/220774988242)
* [딥러닝 용어 정리](http://docs.likejazz.com/deep-learning-glossary/)
* [완전쉬운 딥러닝](http://kr.deductiontheory.com/2017/01/blog-post.html)
* [수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요](http://bcho.tistory.com/1140)
* [수학포기자를 위한 딥러닝-#2 - 선형회귀분석을 통한 머신러닝의 기본 개념 이해](http://bcho.tistory.com/1139)
* [수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자](http://bcho.tistory.com/1141)
* [수학포기자를 위한 딥러닝-#4 로지스틱 회귀를 이용한 분류 모델](http://bcho.tistory.com/1142)
* [수학포기자를 위한 딥러닝과 텐서플로우의 이해](http://bcho.tistory.com/1208)
* [How-to-learn-Deep-Learning/README_kr.md](https://github.com/Huffon/How-to-learn-Deep-Learning/blob/master/README_kr.md)
* [딥러닝/데이터사이언스를 위한 파이썬 입문 - 마이캠퍼스](https://github.com/mycampus-io/python-for-deep-learning)
* [러닝 딥러닝](https://www.youtube.com/playlist?list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc)
* [딥러닝 강의 자료 - 패스트캠퍼스의 비전공자를 위한 데이터 사이언스 스쿨에서 진행한 한국어 딥러닝 강의 자료](https://github.com/nmhkahn/deep_learning_tutorial)
* [딥러닝 교육 자료 (Deep Learning Lecture)](http://hugrypiggykim.com/2017/08/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B5%90%EC%9C%A1-%EC%9E%90%EB%A3%8C-deep-learning-lecture/)
* [신경망에 대해 알아야 할 모든 것](http://blog.funhnc.com/entry/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EC%95%BC-%ED%95%A0-%EB%AA%A8%EB%93%A0-%EA%B2%83)
* [도대체 선형이 뭘까?](https://www.youtube.com/watch?v=ZkoSFB0AchE)
* [Deep Learning 완전 쉽게 이해하기 for nonprogrammer - Kowana's tech](https://www.kowanas.com/tech/2021/01/03/deep-learning)
* [Deep Learning for Beginners](http://randomekek.github.io/deep/deeplearning.html)
* [5 Best Deep Learning in Python videos for a Beginner](https://www.techleer.com/articles/416-5-best-deep-learning-in-python-videos-for-a-beginner)
* [Deep Learning — a gentle dive](https://becominghuman.ai/deep-learning-a-gentle-dive-92054e39bd8)
* [A Beginner’s Guide to Deep Neural Networks](http://googleresearch.blogspot.kr/2015/09/a-beginners-guide-to-deep-neural.html)
* [A Guide to Production Level Deep Learning](https://github.com/alirezadir/Production-Level-Deep-Learning)
* [A “weird” introduction to Deep Learning](https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0)
* [A Gentle Introduction to Deep Learning - Singapore Python User Group](https://www.youtube.com/watch?v=wr8GDhtPWVo)
* [Newbie’s guide to Deep Learning](https://towardsdatascience.com/newbies-guide-to-deep-learning-6bf601c5a98e)
* [Deep Learning for Beginners](http://randomekek.github.io/deep/deeplearning.html)
* [Welcome to the Deep Learning Tutorial!](http://deeplearning.stanford.edu/tutorial/)
* [ISBA 2015 Morning Tutorial: Deep Learning (March 23, 2015)](https://www.youtube.com/watch?v=gCwYO7zVJs0)
* [tutorial, implementations](https://github.com/dsindex/blog/wiki/%5Bdeep-learning%5D-tutorial,-implementations)
* [Tutorial on Deep Learning](https://simons.berkeley.edu/talks/tutorial-deep-learning)
* [A Primer on Deep Learning](https://opendatascience.com/blog/change-a-primer-on-deep-learning/)
* [Building Safe A.I.  A Tutorial for Encrypted Deep Learning](https://iamtrask.github.io/2017/03/17/safe-ai)
* [tutorial, implementations](https://github.com/dsindex/blog/wiki/%5Bdeep-learning%5D-tutorial,-implementations)
* [GitHub Special: Data Scientists to Follow & Best Tutorials on GitHub](http://www.analyticsvidhya.com/blog/2015/07/github-special-data-scientists-to-follow-best-tutorials/)
* [Deep learning tutorials (2nd ed.)](https://github.com/sjchoi86/dl_tutorials)
* [Deep Learning Tutorial 4th](https://github.com/sjchoi86/dl_tutorials_4th)
* [Deep Learning Tutorial](https://github.com/sjchoi86/dl_tutorials_10weeks)
* [Deep Learning for Everyone – and (Almost) Free](http://www.datasciencecentral.com/profiles/blogs/deep-learning-for-everyone-and-almost-free)
* [Deep learning tutorials](https://github.com/sjchoi86/dl-workshop)
* [비 전공자를 위한 딥러닝 개념 구조 - 딥러닝 생각보다 쉽다 - YouTube](https://www.youtube.com/watch?v=yF5MNNpswZ0)
* [인공지능, 기계학습 그리고 딥러닝](https://www.slideshare.net/JinwonLee9/ss-70446412)
* [딥러닝 강의 1편 6시간 완성 - 카이스트 AI박사 - 컴퓨터 비전 인식모델 개발 - YouTube](https://www.youtube.com/watch?v=Adi0Iasehj8)
